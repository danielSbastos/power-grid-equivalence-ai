{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a47ddfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-02 11:04:09.092241: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-02 11:04:09.092265: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86d48a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = pd.read_csv(\"data/input_data_nn.csv\", sep=\";\")\n",
    "output_df = pd.read_csv(\"data/output_data_nn.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7f905e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([input_df, output_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb340ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = output_df.columns.tolist() + input_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "530a5e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    " 'pot_reativa_inj_barramento11',\n",
    "# 'pot_reativa_inj_barramento12',\n",
    "# 'pot_reativa_inj_barramento24',\n",
    " 'pot_ativa_inj_barramento11',\n",
    "# 'pot_ativa_inj_barramento12',\n",
    "# 'pot_ativa_inj_barramento24',    \n",
    " 'tensao_barramento11',\n",
    "# 'tensao_barramento12',\n",
    "#  'tensao_barramento24',\n",
    "  'carga_subrede_138kv',\n",
    "  'pot_eolica_subrede_138kv',\n",
    "  'pot_solar_subrede_138kv',\n",
    "#  'status_1_gerador_subrede_230kv',\n",
    "#  'status_2_gerador_subrede_230kv',\n",
    "#  'status_3_gerador_subrede_230kv',\n",
    "#  'status_4_gerador_subrede_230kv',\n",
    "#  'status_5_gerador_subrede_230kv',\n",
    "#  'status_6_gerador_subrede_230kv',\n",
    "#  'status_7_gerador_subrede_230kv',\n",
    "#  'status_8_gerador_subrede_230kv',\n",
    "#  'status_9_gerador_subrede_230kv',\n",
    "#  'status_10_gerador_subrede_230kv',\n",
    "#  'status_11_gerador_subrede_230kv',\n",
    "#  'status_12_gerador_subrede_230kv',\n",
    "#  'status_13_gerador_subrede_230kv',\n",
    "#  'status_14_gerador_subrede_230kv',\n",
    "#  'status_15_gerador_subrede_230kv',\n",
    "#  'status_16_gerador_subrede_230kv',\n",
    "#  'status_17_gerador_subrede_230kv',\n",
    "#  'status_18_gerador_subrede_230kv',\n",
    "#  'status_1_linha_subrede_230kv',\n",
    "#  'status_2_linha_subrede_230kv',\n",
    "#  'status_3_linha_subrede_230kv',\n",
    "#  'status_4_linha_subrede_230kv',\n",
    "#  'status_5_linha_subrede_230kv',\n",
    "#  'status_6_linha_subrede_230kv',\n",
    "#  'status_7_linha_subrede_230kv',\n",
    "#  'status_8_linha_subrede_230kv',\n",
    "#  'status_9_linha_subrede_230kv',\n",
    "#  'status_10_linha_subrede_230kv',\n",
    "#  'status_11_linha_subrede_230kv',\n",
    "#  'status_12_linha_subrede_230kv',\n",
    "#  'status_13_linha_subrede_230kv',\n",
    "#  'status_14_linha_subrede_230kv',\n",
    "#  'status_15_linha_subrede_230kv',\n",
    "#  'status_16_linha_subrede_230kv',\n",
    "#  'status_17_linha_subrede_230kv',\n",
    "#  'status_18_linha_subrede_230kv',\n",
    "#  'status_19_linha_subrede_230kv',\n",
    "#  'status_20_linha_subrede_230kv',\n",
    "#  'status_21_linha_subrede_230kv'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8700cb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "608470fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6132, 6)\n",
      "(2628, 6)\n"
     ]
    }
   ],
   "source": [
    "test_split=round(len(df)*0.30)\n",
    "df_for_training=df[:-test_split]\n",
    "df_for_testing=df[-test_split:]\n",
    "print(df_for_training.shape)\n",
    "print(df_for_testing.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f16fcad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.83165917e-01, 2.23414479e-01, 8.85093517e-01, 5.55819477e-01,\n",
       "        6.32287509e-01, 0.00000000e+00],\n",
       "       [6.90066994e-01, 1.40612011e-02, 5.79535979e-01, 2.89786223e-01,\n",
       "        6.33417710e-01, 0.00000000e+00],\n",
       "       [6.77965974e-01, 5.20553071e-02, 5.93556780e-01, 2.61282660e-01,\n",
       "        5.70590233e-01, 0.00000000e+00],\n",
       "       ...,\n",
       "       [5.72407611e-01, 1.80782404e-01, 5.90426301e-01, 5.79572446e-01,\n",
       "        7.65566568e-01, 3.37452422e-01],\n",
       "       [3.82452734e-01, 1.69935018e-01, 8.04570513e-06, 6.74584323e-01,\n",
       "        8.99627950e-01, 3.11403605e-01],\n",
       "       [3.79769801e-01, 1.71499171e-01, 8.02700704e-06, 6.79334916e-01,\n",
       "        9.01468828e-01, 3.43657936e-01]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "df_for_training_scaled = scaler.fit_transform(df_for_training)\n",
    "df_for_testing_scaled=scaler.transform(df_for_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1ef363a",
   "metadata": {},
   "outputs": [],
   "source": [
    "days = 30 * 1\n",
    "max_idx_pred = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "576352c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-02 11:04:12.253914: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-08-02 11:04:12.253958: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-08-02 11:04:12.253993: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (schlickmann): /proc/driver/nvidia/version does not exist\n",
      "2022-08-02 11:04:12.255131: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "624a4dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX Shape--  (5412, 720, 6)\n",
      "trainY Shape--  (5412, 1)\n",
      "testX Shape--  (1908, 720, 6)\n",
      "testY Shape--  (1908, 1)\n"
     ]
    }
   ],
   "source": [
    "def createXY(dataset, max_idx_pred, n_past):\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    for i in range(n_past, len(dataset)):\n",
    "            dataX.append(dataset[i - n_past:i, 0:dataset.shape[1]])\n",
    "            dataY.append(dataset[i, 0:max_idx_pred])\n",
    "    return np.array(dataX),np.array(dataY)\n",
    "\n",
    "trainX,trainY=createXY(df_for_training_scaled, max_idx_pred, 24 * days)\n",
    "testX,testY=createXY(df_for_testing_scaled, max_idx_pred, 24 * days)\n",
    "\n",
    "print(\"trainX Shape-- \",trainX.shape)\n",
    "print(\"trainY Shape-- \",trainY.shape)\n",
    "print(\"testX Shape-- \",testX.shape)\n",
    "print(\"testY Shape-- \",testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da03941d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.1100\n",
      "Epoch 1: val_loss improved from inf to 0.09913, saving model to mae_50_15_1.h5\n",
      "339/339 [==============================] - 202s 589ms/step - loss: 0.1100 - val_loss: 0.0991\n",
      "Epoch 2/50\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.0884\n",
      "Epoch 2: val_loss improved from 0.09913 to 0.08362, saving model to mae_50_15_1.h5\n",
      "339/339 [==============================] - 191s 563ms/step - loss: 0.0884 - val_loss: 0.0836\n",
      "Epoch 3/50\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.0783\n",
      "Epoch 3: val_loss improved from 0.08362 to 0.07852, saving model to mae_50_15_1.h5\n",
      "339/339 [==============================] - 201s 594ms/step - loss: 0.0783 - val_loss: 0.0785\n",
      "Epoch 4/50\n",
      " 29/339 [=>............................] - ETA: 3:00 - loss: 0.0756"
     ]
    }
   ],
   "source": [
    "def build_model(callbacks):    \n",
    "    grid_model = Sequential()\n",
    "    grid_model.add(LSTM(50, return_sequences = True, input_shape=(24 * days, trainX.shape[-1])))\n",
    "    grid_model.add(LSTM(50))\n",
    "    grid_model.add(Dropout(0.2))\n",
    "    #grid_model.add(LSTM(70, return_sequences = True))\n",
    "    #grid_model.add(Dropout(0.2))\n",
    "    #grid_model.add(LSTM(50))\n",
    "    #grid_model.add(Dropout(0.2))\n",
    "    grid_model.add(Dense(max_idx_pred))\n",
    "\n",
    "    grid_model.compile(loss = 'mae',optimizer = 'adam')\n",
    "    grid_model.fit(trainX,trainY, batch_size = 16, epochs = 50, callbacks=callbacks, validation_data = (testX, testY))\n",
    "    \n",
    "    return grid_model\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=15)\n",
    "mc = ModelCheckpoint('mae_50_15_1.h5', monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "\n",
    "model = build_model([es, mc])\n",
    "\n",
    "prediction=model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2bc5c58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(index):\n",
    "    plt.plot(originals[:,index], color = 'red', label = 'Real')\n",
    "    plt.plot(pred[:,index], color = 'blue', label = 'Predicted')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return sqrt(mean_squared_error(originals[:,index], pred[:,index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3597a9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform(arrs):\n",
    "    zeros_padding = np.zeros(testX.shape[-1] - (max_idx_pred))\n",
    "    arrs_copies = list(map(lambda arr: np.concatenate((arr, zeros_padding)), arrs))\n",
    "    return scaler.inverse_transform(np.reshape(arrs_copies, (len(arrs), testX.shape[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f4e327f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = inverse_transform(prediction)\n",
    "originals = inverse_transform(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "448b8736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred tensao_barramento11: [1.01334414 0.99277805 0.99481454 ... 1.01292363 0.9870933  0.94952426]\n",
      "original tensao_barramento11: [1.00269358 1.00453829 1.00513947 ... 1.0019635  0.95127084 0.95126964]\n",
      "\n",
      "pred tensao_barramento12: [1.01235144 0.99268041 0.99489139 ... 1.01326569 0.98885    0.94981958]\n",
      "original tensao_barramento12: [0.99990073 1.00272539 1.00364593 ... 1.00335917 0.95157989 0.95158083]\n",
      "\n",
      "pred tensao_barramento24: [1.00026255 0.97675341 0.97980152 ... 1.00912616 0.98568991 0.9514155 ]\n",
      "original tensao_barramento24: [0.98334365 0.98592246 0.98566991 ... 1.00685737 0.95000062 0.95000064]\n",
      "\n",
      "pred tensao_barramento24: [1.00026255 0.97675341 0.97980152 ... 1.00912616 0.98568991 0.9514155 ]\n",
      "original tensao_barramento24: [0.98334365 0.98592246 0.98566991 ... 1.00685737 0.95000062 0.95000064]\n",
      "\n",
      "pred pot_ativa_inj_barramento11: [77.61293781 60.00705901 49.46027855 ... 85.50988677 61.05178586\n",
      " 53.62100092]\n",
      "original pot_ativa_inj_barramento11: [66.24799586 54.39864737 48.00403871 ... 72.60335738 57.87360805\n",
      " 56.83372024]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"pred 0: \" + str(pred[:,0]))\n",
    "print(\"original 0: \" + str(originals[:,0]))\n",
    "print()\n",
    "print(\"pred 1: \" + str(pred[:,1]))\n",
    "print(\"original 1: \" + str(originals[:,1]))\n",
    "print()\n",
    "print(\"pred 2: \" + str(pred[:,2]))\n",
    "print(\"original 2: \" + str(originals[:,2]))\n",
    "print()\n",
    "print(\"pred 3: \" + str(pred[:,2]))\n",
    "print(\"original 3: \" + str(originals[:,2]))\n",
    "print()\n",
    "print(\"pred 4: \" + str(pred[:,3]))\n",
    "print(\"original 4: \" + str(originals[:,3]))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6216a637",
   "metadata": {},
   "source": [
    "## Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "693bea0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10384/1044546172.py:13: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  grid_model = KerasRegressor(build_fn=build_model,verbose=1,validation_data=(testX,testY))\n"
     ]
    }
   ],
   "source": [
    "def build_model(optimizer):\n",
    "    grid_model = Sequential()\n",
    "    grid_model.add(LSTM(50,return_sequences=True,input_shape=(30,51)))\n",
    "    grid_model.add(LSTM(50))\n",
    "    grid_model.add(Dropout(0.2))\n",
    "    grid_model.add(Dense(1))\n",
    "\n",
    "    grid_model.compile(loss = 'mse',optimizer = optimizer)\n",
    "    # {'batch_size': 16, 'epochs': 10, 'optimizer': 'adam'}\n",
    "    grid_model.fit(trainX,trainY, batch_size =  16, epochs = 10,validation_data=(testX, testY))\n",
    "    \n",
    "    return grid_model\n",
    "\n",
    "grid_model = KerasRegressor(build_fn=build_model,verbose=1,validation_data=(testX,testY))\n",
    "\n",
    "parameters = {'batch_size' : [16,20],\n",
    "              'epochs' : [8,10],\n",
    "              'optimizer' : ['adam','Adadelta'] }\n",
    "\n",
    "grid_search  = GridSearchCV(estimator = grid_model,\n",
    "                            param_grid = parameters,\n",
    "                            cv = 2)\n",
    "\n",
    "\n",
    "grid_search = grid_search.fit(trainX,trainY)\n",
    "grid_search.best_params_\n",
    "my_model=grid_search.best_estimator_.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "b2569bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_copies_array = np.repeat(prediction, 25, axis=1)\n",
    "prediction_copies_array_m = list(map(lambda pred: (pred.tolist() * 25) + [pred.tolist()[0]], prediction))\n",
    "pred = scaler.inverse_transform(np.reshape(prediction_copies_array_m,(len(prediction),51)))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5759092",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7967/479307926.py:12: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  grid_model = KerasRegressor(build_fn=build_model_cv,verbose=1,validation_data=(testX,testY))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "188/188 [==============================] - 25s 123ms/step - loss: 0.0305 - val_loss: 0.0203\n",
      "Epoch 2/8\n",
      "188/188 [==============================] - 24s 130ms/step - loss: 0.0139 - val_loss: 0.0158\n",
      "Epoch 3/8\n",
      "188/188 [==============================] - 24s 130ms/step - loss: 0.0107 - val_loss: 0.0110\n",
      "Epoch 4/8\n",
      "188/188 [==============================] - 23s 122ms/step - loss: 0.0087 - val_loss: 0.0106\n",
      "Epoch 5/8\n",
      "188/188 [==============================] - 22s 119ms/step - loss: 0.0078 - val_loss: 0.0091\n",
      "Epoch 6/8\n",
      "188/188 [==============================] - 23s 121ms/step - loss: 0.0068 - val_loss: 0.0071\n",
      "Epoch 7/8\n",
      "188/188 [==============================] - 23s 123ms/step - loss: 0.0066 - val_loss: 0.0079\n",
      "Epoch 8/8\n",
      "188/188 [==============================] - 23s 124ms/step - loss: 0.0059 - val_loss: 0.0074\n",
      "188/188 [==============================] - 6s 34ms/step - loss: 0.0076\n",
      "Epoch 1/8\n",
      "188/188 [==============================] - 25s 119ms/step - loss: 0.0267 - val_loss: 0.0194\n",
      "Epoch 2/8\n",
      "188/188 [==============================] - 23s 122ms/step - loss: 0.0152 - val_loss: 0.0132\n",
      "Epoch 3/8\n",
      "188/188 [==============================] - 23s 120ms/step - loss: 0.0118 - val_loss: 0.0095\n",
      "Epoch 4/8\n",
      "188/188 [==============================] - 23s 121ms/step - loss: 0.0093 - val_loss: 0.0068\n",
      "Epoch 5/8\n",
      "188/188 [==============================] - 23s 120ms/step - loss: 0.0078 - val_loss: 0.0070\n",
      "Epoch 6/8\n",
      "188/188 [==============================] - 23s 120ms/step - loss: 0.0071 - val_loss: 0.0063\n",
      "Epoch 7/8\n",
      "188/188 [==============================] - 23s 120ms/step - loss: 0.0068 - val_loss: 0.0065\n",
      "Epoch 8/8\n",
      "188/188 [==============================] - 23s 121ms/step - loss: 0.0064 - val_loss: 0.0063\n",
      "188/188 [==============================] - 4s 24ms/step - loss: 0.0066\n",
      "Epoch 1/8\n",
      "188/188 [==============================] - 25s 124ms/step - loss: 0.2172 - val_loss: 0.2082\n",
      "Epoch 2/8\n",
      "188/188 [==============================] - 23s 123ms/step - loss: 0.1984 - val_loss: 0.1894\n",
      "Epoch 3/8\n",
      "188/188 [==============================] - 23s 124ms/step - loss: 0.1802 - val_loss: 0.1711\n",
      "Epoch 4/8\n",
      "188/188 [==============================] - 22s 115ms/step - loss: 0.1623 - val_loss: 0.1538\n",
      "Epoch 5/8\n",
      "188/188 [==============================] - 20s 108ms/step - loss: 0.1463 - val_loss: 0.1378\n",
      "Epoch 6/8\n",
      "188/188 [==============================] - 22s 117ms/step - loss: 0.1308 - val_loss: 0.1232\n",
      "Epoch 7/8\n",
      "188/188 [==============================] - 21s 110ms/step - loss: 0.1166 - val_loss: 0.1102\n",
      "Epoch 8/8\n",
      "188/188 [==============================] - 23s 122ms/step - loss: 0.1049 - val_loss: 0.0989\n",
      "188/188 [==============================] - 4s 21ms/step - loss: 0.0639\n",
      "Epoch 1/8\n",
      "188/188 [==============================] - 23s 110ms/step - loss: 0.1141 - val_loss: 0.1561\n",
      "Epoch 2/8\n",
      "188/188 [==============================] - 20s 107ms/step - loss: 0.1055 - val_loss: 0.1443\n",
      "Epoch 3/8\n",
      "188/188 [==============================] - 22s 115ms/step - loss: 0.0966 - val_loss: 0.1328\n",
      "Epoch 4/8\n",
      "188/188 [==============================] - 21s 110ms/step - loss: 0.0883 - val_loss: 0.1218\n",
      "Epoch 5/8\n",
      "188/188 [==============================] - 21s 113ms/step - loss: 0.0791 - val_loss: 0.1116\n",
      "Epoch 6/8\n",
      "188/188 [==============================] - 20s 107ms/step - loss: 0.0724 - val_loss: 0.1023\n",
      "Epoch 7/8\n",
      "188/188 [==============================] - 21s 111ms/step - loss: 0.0659 - val_loss: 0.0939\n",
      "Epoch 8/8\n",
      "188/188 [==============================] - 21s 113ms/step - loss: 0.0612 - val_loss: 0.0865\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.0832\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 26s 126ms/step - loss: 0.0282 - val_loss: 0.0183\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 23s 123ms/step - loss: 0.0136 - val_loss: 0.0123\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 24s 129ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 22s 116ms/step - loss: 0.0088 - val_loss: 0.0091\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 21s 112ms/step - loss: 0.0077 - val_loss: 0.0083\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 20s 109ms/step - loss: 0.0071 - val_loss: 0.0074\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 20s 108ms/step - loss: 0.0062 - val_loss: 0.0067\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 20s 109ms/step - loss: 0.0060 - val_loss: 0.0062\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 21s 109ms/step - loss: 0.0059 - val_loss: 0.0065\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 20s 108ms/step - loss: 0.0056 - val_loss: 0.0064\n",
      "188/188 [==============================] - 4s 21ms/step - loss: 0.0065\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 23s 110ms/step - loss: 0.0269 - val_loss: 0.0184\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 20s 106ms/step - loss: 0.0153 - val_loss: 0.0123\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 20s 109ms/step - loss: 0.0120 - val_loss: 0.0092\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 20s 106ms/step - loss: 0.0095 - val_loss: 0.0072\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 20s 109ms/step - loss: 0.0079 - val_loss: 0.0061\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 20s 108ms/step - loss: 0.0071 - val_loss: 0.0059\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 20s 106ms/step - loss: 0.0067 - val_loss: 0.0058\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 20s 106ms/step - loss: 0.0062 - val_loss: 0.0077\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 20s 107ms/step - loss: 0.0062 - val_loss: 0.0052\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 20s 105ms/step - loss: 0.0062 - val_loss: 0.0055\n",
      "188/188 [==============================] - 4s 20ms/step - loss: 0.0058\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 23s 113ms/step - loss: 0.2491 - val_loss: 0.2435\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 20s 105ms/step - loss: 0.2307 - val_loss: 0.2253\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 20s 108ms/step - loss: 0.2112 - val_loss: 0.2078\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 20s 105ms/step - loss: 0.1931 - val_loss: 0.1908\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 20s 105ms/step - loss: 0.1772 - val_loss: 0.1747\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 20s 105ms/step - loss: 0.1611 - val_loss: 0.1594\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 20s 105ms/step - loss: 0.1460 - val_loss: 0.1451\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 20s 107ms/step - loss: 0.1324 - val_loss: 0.1320\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 20s 106ms/step - loss: 0.1200 - val_loss: 0.1199\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 22s 119ms/step - loss: 0.1082 - val_loss: 0.1090\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 0.0649\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 27s 134ms/step - loss: 0.1473 - val_loss: 0.1876\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 25s 131ms/step - loss: 0.1292 - val_loss: 0.1673\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 25s 133ms/step - loss: 0.1142 - val_loss: 0.1485\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 25s 133ms/step - loss: 0.1003 - val_loss: 0.1316\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 25s 134ms/step - loss: 0.0871 - val_loss: 0.1166\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 25s 132ms/step - loss: 0.0763 - val_loss: 0.1037\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 25s 132ms/step - loss: 0.0667 - val_loss: 0.0927\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 25s 132ms/step - loss: 0.0610 - val_loss: 0.0839\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 25s 131ms/step - loss: 0.0565 - val_loss: 0.0767\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 24s 130ms/step - loss: 0.0510 - val_loss: 0.0712\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 0.0664\n",
      "Epoch 1/8\n",
      "151/151 [==============================] - 24s 140ms/step - loss: 0.0368 - val_loss: 0.0206\n",
      "Epoch 2/8\n",
      "151/151 [==============================] - 20s 133ms/step - loss: 0.0162 - val_loss: 0.0161\n",
      "Epoch 3/8\n",
      "151/151 [==============================] - 20s 133ms/step - loss: 0.0123 - val_loss: 0.0144\n",
      "Epoch 4/8\n",
      "151/151 [==============================] - 20s 133ms/step - loss: 0.0103 - val_loss: 0.0113\n",
      "Epoch 5/8\n",
      "151/151 [==============================] - 20s 134ms/step - loss: 0.0089 - val_loss: 0.0093\n",
      "Epoch 6/8\n",
      "151/151 [==============================] - 21s 136ms/step - loss: 0.0081 - val_loss: 0.0101\n",
      "Epoch 7/8\n",
      "151/151 [==============================] - 21s 136ms/step - loss: 0.0073 - val_loss: 0.0082\n",
      "Epoch 8/8\n",
      "151/151 [==============================] - 20s 135ms/step - loss: 0.0069 - val_loss: 0.0077\n",
      "151/151 [==============================] - 4s 25ms/step - loss: 0.0080\n",
      "Epoch 1/8\n",
      "151/151 [==============================] - 24s 141ms/step - loss: 0.0264 - val_loss: 0.0188\n",
      "Epoch 2/8\n",
      "151/151 [==============================] - 20s 133ms/step - loss: 0.0158 - val_loss: 0.0160\n",
      "Epoch 3/8\n",
      "151/151 [==============================] - 21s 136ms/step - loss: 0.0124 - val_loss: 0.0096\n",
      "Epoch 4/8\n",
      "151/151 [==============================] - 20s 135ms/step - loss: 0.0096 - val_loss: 0.0082\n",
      "Epoch 5/8\n",
      "151/151 [==============================] - 21s 136ms/step - loss: 0.0079 - val_loss: 0.0076\n",
      "Epoch 6/8\n",
      "151/151 [==============================] - 21s 137ms/step - loss: 0.0073 - val_loss: 0.0066\n",
      "Epoch 7/8\n",
      "151/151 [==============================] - 20s 136ms/step - loss: 0.0068 - val_loss: 0.0060\n",
      "Epoch 8/8\n",
      "151/151 [==============================] - 20s 136ms/step - loss: 0.0065 - val_loss: 0.0056\n",
      "151/151 [==============================] - 4s 24ms/step - loss: 0.0060\n",
      "Epoch 1/8\n",
      "151/151 [==============================] - 4277s 28s/step - loss: 0.2133 - val_loss: 0.2051\n",
      "Epoch 2/8\n",
      "151/151 [==============================] - 10s 67ms/step - loss: 0.1964 - val_loss: 0.1902\n",
      "Epoch 3/8\n",
      "151/151 [==============================] - 11s 70ms/step - loss: 0.1811 - val_loss: 0.1755\n",
      "Epoch 4/8\n",
      "151/151 [==============================] - 10s 65ms/step - loss: 0.1669 - val_loss: 0.1615\n",
      "Epoch 5/8\n",
      "151/151 [==============================] - 10s 66ms/step - loss: 0.1522 - val_loss: 0.1481\n",
      "Epoch 6/8\n",
      "151/151 [==============================] - 10s 64ms/step - loss: 0.1393 - val_loss: 0.1354\n",
      "Epoch 7/8\n",
      "151/151 [==============================] - 10s 64ms/step - loss: 0.1275 - val_loss: 0.1236\n",
      "Epoch 8/8\n",
      "151/151 [==============================] - 10s 64ms/step - loss: 0.1159 - val_loss: 0.1128\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 0.0698\n",
      "Epoch 1/8\n",
      "151/151 [==============================] - 12s 65ms/step - loss: 0.0718 - val_loss: 0.1030\n",
      "Epoch 2/8\n",
      "151/151 [==============================] - 10s 64ms/step - loss: 0.0658 - val_loss: 0.0952\n",
      "Epoch 3/8\n",
      "151/151 [==============================] - 10s 64ms/step - loss: 0.0612 - val_loss: 0.0883\n",
      "Epoch 4/8\n",
      "151/151 [==============================] - 10s 64ms/step - loss: 0.0567 - val_loss: 0.0821\n",
      "Epoch 5/8\n",
      "151/151 [==============================] - 10s 64ms/step - loss: 0.0537 - val_loss: 0.0769\n",
      "Epoch 6/8\n",
      "151/151 [==============================] - 10s 63ms/step - loss: 0.0510 - val_loss: 0.0727\n",
      "Epoch 7/8\n",
      "151/151 [==============================] - 10s 64ms/step - loss: 0.0483 - val_loss: 0.0691\n",
      "Epoch 8/8\n",
      "151/151 [==============================] - 10s 64ms/step - loss: 0.0473 - val_loss: 0.0663\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 0.0613\n",
      "Epoch 1/10\n",
      "151/151 [==============================] - 12s 65ms/step - loss: 0.0333 - val_loss: 0.0244\n",
      "Epoch 2/10\n",
      "151/151 [==============================] - 10s 65ms/step - loss: 0.0166 - val_loss: 0.0140\n",
      "Epoch 3/10\n",
      "151/151 [==============================] - 10s 65ms/step - loss: 0.0117 - val_loss: 0.0108\n",
      "Epoch 4/10\n",
      "151/151 [==============================] - 10s 66ms/step - loss: 0.0097 - val_loss: 0.0102\n",
      "Epoch 5/10\n",
      "151/151 [==============================] - 10s 65ms/step - loss: 0.0081 - val_loss: 0.0091\n",
      "Epoch 6/10\n",
      "151/151 [==============================] - 10s 65ms/step - loss: 0.0075 - val_loss: 0.0076\n",
      "Epoch 7/10\n",
      "151/151 [==============================] - 10s 65ms/step - loss: 0.0070 - val_loss: 0.0071\n",
      "Epoch 8/10\n",
      "151/151 [==============================] - 10s 65ms/step - loss: 0.0065 - val_loss: 0.0072\n",
      "Epoch 9/10\n",
      "151/151 [==============================] - 10s 65ms/step - loss: 0.0065 - val_loss: 0.0064\n",
      "Epoch 10/10\n",
      "151/151 [==============================] - 10s 68ms/step - loss: 0.0062 - val_loss: 0.0062\n",
      "151/151 [==============================] - 2s 14ms/step - loss: 0.0066\n",
      "Epoch 1/10\n",
      "151/151 [==============================] - 12s 66ms/step - loss: 0.0300 - val_loss: 0.0244\n",
      "Epoch 2/10\n",
      "151/151 [==============================] - 10s 69ms/step - loss: 0.0167 - val_loss: 0.0138\n",
      "Epoch 3/10\n",
      "151/151 [==============================] - 10s 64ms/step - loss: 0.0124 - val_loss: 0.0097\n",
      "Epoch 4/10\n",
      "151/151 [==============================] - 10s 67ms/step - loss: 0.0101 - val_loss: 0.0077\n",
      "Epoch 5/10\n",
      "151/151 [==============================] - 10s 67ms/step - loss: 0.0081 - val_loss: 0.0065\n",
      "Epoch 6/10\n",
      "151/151 [==============================] - 10s 69ms/step - loss: 0.0072 - val_loss: 0.0086\n",
      "Epoch 7/10\n",
      "151/151 [==============================] - 11s 71ms/step - loss: 0.0067 - val_loss: 0.0056\n",
      "Epoch 8/10\n",
      "151/151 [==============================] - 10s 67ms/step - loss: 0.0064 - val_loss: 0.0056\n",
      "Epoch 9/10\n",
      "151/151 [==============================] - 10s 65ms/step - loss: 0.0060 - val_loss: 0.0054\n",
      "Epoch 10/10\n",
      "151/151 [==============================] - 10s 68ms/step - loss: 0.0060 - val_loss: 0.0059\n",
      "151/151 [==============================] - 2s 14ms/step - loss: 0.0061\n",
      "Epoch 1/10\n",
      "151/151 [==============================] - 13s 71ms/step - loss: 0.2489 - val_loss: 0.2347\n",
      "Epoch 2/10\n",
      "151/151 [==============================] - 11s 72ms/step - loss: 0.2352 - val_loss: 0.2214\n",
      "Epoch 3/10\n",
      "151/151 [==============================] - 10s 68ms/step - loss: 0.2214 - val_loss: 0.2079\n",
      "Epoch 4/10\n",
      "151/151 [==============================] - 10s 67ms/step - loss: 0.2077 - val_loss: 0.1945\n",
      "Epoch 5/10\n",
      "151/151 [==============================] - 10s 66ms/step - loss: 0.1924 - val_loss: 0.1814\n",
      "Epoch 6/10\n",
      "151/151 [==============================] - 10s 66ms/step - loss: 0.1800 - val_loss: 0.1685\n",
      "Epoch 7/10\n",
      "151/151 [==============================] - 10s 67ms/step - loss: 0.1665 - val_loss: 0.1561\n",
      "Epoch 8/10\n",
      "151/151 [==============================] - 10s 66ms/step - loss: 0.1532 - val_loss: 0.1442\n",
      "Epoch 9/10\n",
      "151/151 [==============================] - 10s 65ms/step - loss: 0.1425 - val_loss: 0.1327\n",
      "Epoch 10/10\n",
      "151/151 [==============================] - 10s 66ms/step - loss: 0.1304 - val_loss: 0.1219\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 0.0795\n",
      "Epoch 1/10\n",
      "151/151 [==============================] - 13s 70ms/step - loss: 0.0893 - val_loss: 0.1277\n",
      "Epoch 2/10\n",
      "151/151 [==============================] - 11s 74ms/step - loss: 0.0834 - val_loss: 0.1184\n",
      "Epoch 3/10\n",
      "151/151 [==============================] - 10s 67ms/step - loss: 0.0768 - val_loss: 0.1096\n",
      "Epoch 4/10\n",
      "151/151 [==============================] - 10s 67ms/step - loss: 0.0708 - val_loss: 0.1016\n",
      "Epoch 5/10\n",
      "151/151 [==============================] - 10s 67ms/step - loss: 0.0651 - val_loss: 0.0943\n",
      "Epoch 6/10\n",
      "151/151 [==============================] - 11s 72ms/step - loss: 0.0602 - val_loss: 0.0878\n",
      "Epoch 7/10\n",
      "151/151 [==============================] - 10s 67ms/step - loss: 0.0559 - val_loss: 0.0821\n",
      "Epoch 8/10\n",
      "151/151 [==============================] - 10s 68ms/step - loss: 0.0535 - val_loss: 0.0772\n",
      "Epoch 9/10\n",
      "151/151 [==============================] - 10s 67ms/step - loss: 0.0503 - val_loss: 0.0731\n",
      "Epoch 10/10\n",
      "151/151 [==============================] - 10s 67ms/step - loss: 0.0478 - val_loss: 0.0695\n",
      "151/151 [==============================] - 2s 14ms/step - loss: 0.0669\n",
      "Epoch 1/10\n",
      "376/376 [==============================] - 27s 66ms/step - loss: 0.0236 - val_loss: 0.0141\n",
      "Epoch 2/10\n",
      "376/376 [==============================] - 24s 63ms/step - loss: 0.0112 - val_loss: 0.0080\n",
      "Epoch 3/10\n",
      "376/376 [==============================] - 25s 67ms/step - loss: 0.0081 - val_loss: 0.0061\n",
      "Epoch 4/10\n",
      "376/376 [==============================] - 25s 65ms/step - loss: 0.0070 - val_loss: 0.0056\n",
      "Epoch 5/10\n",
      "376/376 [==============================] - 24s 64ms/step - loss: 0.0063 - val_loss: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "376/376 [==============================] - 23s 61ms/step - loss: 0.0060 - val_loss: 0.0051\n",
      "Epoch 7/10\n",
      "376/376 [==============================] - 23s 62ms/step - loss: 0.0056 - val_loss: 0.0052\n",
      "Epoch 8/10\n",
      "376/376 [==============================] - 23s 62ms/step - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 9/10\n",
      "376/376 [==============================] - 23s 62ms/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 10/10\n",
      "376/376 [==============================] - 23s 62ms/step - loss: 0.0051 - val_loss: 0.0046\n"
     ]
    }
   ],
   "source": [
    "def build_model_cv(optimizer):\n",
    "    grid_model = Sequential()\n",
    "    grid_model.add(LSTM(50,return_sequences=True,input_shape=(24 * days, trainX.shape[-1])))\n",
    "    #grid_model.add(LSTM(50))\n",
    "    grid_model.add(Dropout(0.2))\n",
    "    grid_model.add(Dense(max_idx_pred))\n",
    "\n",
    "    grid_model.compile(loss = 'mse',optimizer = optimizer)\n",
    "    \n",
    "    return grid_model\n",
    "\n",
    "grid_model = KerasRegressor(build_fn=build_model_cv,verbose=1,validation_data=(testX,testY))\n",
    "\n",
    "parameters = {'batch_size' : [16,20],\n",
    "              'epochs' : [8,10],\n",
    "              'optimizer' : ['adam','Adadelta'] }\n",
    "\n",
    "grid_search  = GridSearchCV(estimator = grid_model,\n",
    "                            param_grid = parameters,\n",
    "                            cv = 2)\n",
    "\n",
    "grid_search = grid_search.fit(trainX,trainY)\n",
    "grid_search.best_params_\n",
    "my_model=grid_search.best_estimator_.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "273336e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 16, 'epochs': 10, 'optimizer': 'adam'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
