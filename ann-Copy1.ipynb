{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3a36966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from itertools import combinations \n",
    "from numpy import savetxt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2fb26b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b90d31a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "{} &       mean &        std &        min &         max \\\\\n",
      "\\midrule\n",
      "tensao\\_barramento11          &   0.996569 &   0.021639 &   0.952364 &    1.034885 \\\\\n",
      "tensao\\_barramento12          &   0.997564 &   0.021008 &   0.953941 &    1.032754 \\\\\n",
      "tensao\\_barramento24          &   0.993244 &   0.021868 &   0.950000 &    1.022086 \\\\\n",
      "pot\\_ativa\\_inj\\_barramento11   &  44.794038 &  32.318890 & -27.531718 &  159.904392 \\\\\n",
      "pot\\_ativa\\_inj\\_barramento12   &  65.017462 &  46.834371 & -45.061452 &  233.978721 \\\\\n",
      "pot\\_ativa\\_inj\\_barramento24   &  98.531922 &  53.707492 & -29.154621 &  261.648979 \\\\\n",
      "pot\\_reativa\\_inj\\_barramento11 & -15.602551 &  11.060453 & -34.601205 &   16.029554 \\\\\n",
      "pot\\_reativa\\_inj\\_barramento12 &  -3.119726 &  15.983727 & -30.758948 &   47.883536 \\\\\n",
      "pot\\_reativa\\_inj\\_barramento24 &  25.755603 &  10.808798 &  -0.197103 &   57.932657 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8534/3754926297.py:5: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(output_df.describe().loc[['mean', 'std', 'min', 'max']].transpose().to_latex())\n"
     ]
    }
   ],
   "source": [
    "input_df = pd.read_csv(\"data/input_data_nn.csv\", sep=\";\")\n",
    "output_df = pd.read_csv(\"data/output_data_nn.csv\", sep=\";\")\n",
    "df = pd.concat([input_df, output_df], axis=1)\n",
    "#df = df.loc[~(df==0).all(axis=1)].reset_index()\n",
    "print(output_df.describe().loc[['mean', 'std', 'min', 'max']].transpose().to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cc1ee28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "{} &       mean &        std &         min &         max \\\\\n",
      "\\midrule\n",
      "tensao\\_barramento11          &   0.930757 &   0.245329 &    0.000000 &    1.037192 \\\\\n",
      "tensao\\_barramento12          &   0.932674 &   0.245811 &    0.000000 &    1.040975 \\\\\n",
      "tensao\\_barramento24          &   0.928119 &   0.244779 &    0.000000 &    1.050000 \\\\\n",
      "pot\\_ativa\\_inj\\_barramento11   &  61.921753 &  74.191413 & -141.873767 &  465.782920 \\\\\n",
      "pot\\_ativa\\_inj\\_barramento12   &  91.009106 &  60.936221 &  -82.386932 &  466.262804 \\\\\n",
      "pot\\_ativa\\_inj\\_barramento24   &  69.871945 &  52.058470 &  -26.491069 &  273.246314 \\\\\n",
      "pot\\_reativa\\_inj\\_barramento11 &  -0.993731 &  21.132315 &  -45.583309 &   81.584726 \\\\\n",
      "pot\\_reativa\\_inj\\_barramento12 &   2.929570 &  19.695334 &  -39.121608 &   70.183933 \\\\\n",
      "pot\\_reativa\\_inj\\_barramento24 &  19.667142 &  11.887073 &   -4.390776 &   68.135129 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8534/4054846208.py:5: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(output_df.describe().loc[['mean', 'std', 'min', 'max']].transpose().to_latex())\n"
     ]
    }
   ],
   "source": [
    "input_df = pd.read_csv(\"data/input_data_nn_138.csv\", sep=\";\")\n",
    "output_df = pd.read_csv(\"data/output_data_nn_138.csv\", sep=\";\")\n",
    "df = pd.concat([input_df, output_df], axis=1)\n",
    "df = df.loc[~(df==0).all(axis=1)].reset_index()\n",
    "print(output_df.describe().loc[['mean', 'std', 'min', 'max']].transpose().to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f3306a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f65408f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(x, y, augmenter = None):\n",
    "    x, augmenter = _add_interactions(x, augmenter)\n",
    "    return x, y, augmenter, x.columns\n",
    "\n",
    "def _add_interactions(df, augmenter):\n",
    "    combos = list(combinations(list(df.columns), 2))\n",
    "    colnames = list(df.columns) + ['_'.join(x) for x in combos]\n",
    "\n",
    "    if augmenter:\n",
    "        df = augmenter.transform(df)\n",
    "    else:\n",
    "        augmenter = PolynomialFeatures(interaction_only=True, include_bias=False)\n",
    "        df = augmenter.fit_transform(df)\n",
    "\n",
    "    df = pd.DataFrame(df)\n",
    "    df.columns = colnames\n",
    "    \n",
    "    noint_indicies = [i for i, x in enumerate(list((df == 0).all())) if x]\n",
    "    df = df.drop(df.columns[noint_indicies], axis=1)\n",
    "    \n",
    "    return df, augmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b39c80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_main(df, idx, idx2, ids_to_pred):    \n",
    "    cols = input_df.columns.tolist() \n",
    "    new_df = df.copy()\n",
    "    cols_output = [\n",
    "        'tensao_barramento11', 'tensao_barramento12', 'tensao_barramento24',\n",
    "        'pot_ativa_inj_barramento11', 'pot_ativa_inj_barramento12', 'pot_ativa_inj_barramento24',\n",
    "        'pot_reativa_inj_barramento11', 'pot_reativa_inj_barramento12', 'pot_reativa_inj_barramento24'\n",
    "    ]\n",
    "    predicted_df = pd.DataFrame(columns=cols_output, index=ids_to_pred)\n",
    "    \n",
    "    cols_pred = ['tensao_barramento11']\n",
    "    model_id = 'tensao_11'\n",
    "    tensao_11_df, predicted_tensao_11 = run(new_df, cols, cols_pred, model_id, idx, ids_to_pred, update_test=True)\n",
    "    predicted_df[cols_pred] = predicted_tensao_11\n",
    "    \n",
    "    cols_pred = ['tensao_barramento12']\n",
    "    model_id = 'tensao_12'\n",
    "    tensao_12_df, predicted_tensao_12 = run(new_df, cols, cols_pred, model_id, idx, ids_to_pred, update_test=True)\n",
    "    predicted_df[cols_pred] = predicted_tensao_12  \n",
    "        \n",
    "    cols_pred = ['tensao_barramento24']\n",
    "    model_id = 'tensao_24'\n",
    "    tensao_24_df, predicted_tensao_24 = run(new_df, cols, cols_pred, model_id, idx, ids_to_pred, update_test=True)\n",
    "    predicted_df[cols_pred] = predicted_tensao_24\n",
    "    \n",
    "    cols_pred = [\n",
    "        'pot_ativa_inj_barramento11'\n",
    "    ]\n",
    "    model_id = 'ativa_11'\n",
    "    ativa_df, predicted_ativa = run(new_df, cols, cols_pred, model_id, idx, ids_to_pred, update_test=True)\n",
    "    predicted_df[cols_pred] = predicted_ativa\n",
    "    \n",
    "    cols_pred = [\n",
    "        'pot_ativa_inj_barramento12'\n",
    "    ]\n",
    "    model_id = 'ativa_12'\n",
    "    ativa_df, predicted_ativa = run(new_df, cols, cols_pred, model_id, idx, ids_to_pred, update_test=True)\n",
    "    predicted_df[cols_pred] = predicted_ativa\n",
    "\n",
    "    cols_pred = [\n",
    "        'pot_ativa_inj_barramento24'\n",
    "    ]\n",
    "    model_id = 'ativa_24'\n",
    "    ativa_df, predicted_ativa = run(new_df, cols, cols_pred, model_id, idx, ids_to_pred, update_test=True)\n",
    "    predicted_df[cols_pred] = predicted_ativa\n",
    "    \n",
    "    \n",
    "    cols_pred = [\n",
    "        'pot_reativa_inj_barramento11'\n",
    "    ]\n",
    "    model_id = 'reativa_11'\n",
    "    ativa_df, predicted_ativa = run(new_df, cols, cols_pred, model_id, idx, ids_to_pred, update_test=True)\n",
    "    predicted_df[cols_pred] = predicted_ativa\n",
    "    \n",
    "    cols_pred = [\n",
    "        'pot_reativa_inj_barramento12'\n",
    "    ]\n",
    "    model_id = 'reativa_12'\n",
    "    ativa_df, predicted_ativa = run(new_df, cols, cols_pred, model_id, idx, ids_to_pred, update_test=True)\n",
    "    predicted_df[cols_pred] = predicted_ativa\n",
    "\n",
    "    cols_pred = [\n",
    "        'pot_reativa_inj_barramento24'\n",
    "    ]\n",
    "    model_id = 'reativa_24'\n",
    "    ativa_df, predicted_ativa = run(new_df, cols, cols_pred, model_id, idx, ids_to_pred, update_test=True)\n",
    "    predicted_df[cols_pred] = predicted_ativa\n",
    "    \n",
    "    \n",
    "    predicted_df.to_csv(f'new-results/{idx}-{idx2}.csv')\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5b88e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(df, cols, cols_pred, model_id, idx, ids_to_pred, update_test = False):    \n",
    "    _df = df[cols + cols_pred]\n",
    "    \n",
    "    X, Y = _df[cols], _df[cols_pred]\n",
    "    #X, Y, _, x_cols, = augment(X, Y)\n",
    "    _df_augm = pd.concat([X, Y],  axis=1)\n",
    "\n",
    "    df_for_testing = _df_augm.loc[ids_to_pred]\n",
    "    df_for_training = _df_augm.loc[~_df_augm.index.isin(ids_to_pred)]\n",
    "    \n",
    "    df_for_training = df_for_training.sample(frac=1)\n",
    "    \n",
    "    trainX, trainY = df_for_training.drop(cols_pred, axis=1), df_for_training[cols_pred]\n",
    "    testX, testY = df_for_testing.drop(cols_pred, axis=1), df_for_testing[cols_pred]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    trainX = scaler.fit_transform(trainX)\n",
    "    testX = scaler.transform(testX)\n",
    "    \n",
    "    print(f\" ========== MODEL {model_id} {idx} ============\")\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=10)\n",
    "    mc = ModelCheckpoint(f\"models-new/ann-{model_id}-{idx}.h5\", monitor='val_loss', mode='min', save_best_only=True, verbose=0)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(trainX.shape[1],)))\n",
    "    model.add(Dense(trainX.shape[-1], activation = 'relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(trainX.shape[-1], activation = 'relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(len(cols_pred)))\n",
    "\n",
    "    model.compile(loss = 'mae', optimizer = 'adam')\n",
    "    model.fit(\n",
    "        trainX, trainY,\n",
    "        batch_size = 30, epochs = 20,\n",
    "        callbacks = [es, mc],\n",
    "        validation_data = (testX, testY),\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    _predictions = model.predict(testX) \n",
    "    \n",
    "    rmse = sqrt(mean_squared_error(testY, _predictions))\n",
    "    print(f\"Col: {cols_pred[i]} - RMSE: {rmse}\")\n",
    "    results.append(rmse)\n",
    "    \n",
    "#     if update_test:\n",
    "#         df_for_testing[cols_pred] = _predictions\n",
    "\n",
    "    return pd.concat([df_for_training, df_for_testing]), _predictions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a52dac08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ========== MODEL tensao_11 0 ============\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7faa027b9af0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7faa027b9af0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5645/5645 [==============================] - ETA: 0s - loss: 0.0380WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fa9ef8dddc0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fa9ef8dddc0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5645/5645 [==============================] - 10s 2ms/step - loss: 0.0380 - val_loss: 0.0052\n",
      "Epoch 2/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 3/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 4/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 5/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 6/20\n",
      "5645/5645 [==============================] - 12s 2ms/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 7/20\n",
      "5645/5645 [==============================] - 11s 2ms/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 8/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 9/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 10/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 11/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 12/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 13/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 14/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 15/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 16/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 17/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 18/20\n",
      "5645/5645 [==============================] - 8s 2ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 19/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 20/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa9ef8dd700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa9ef8dd700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2647/2647 [==============================] - 2s 680us/step\n",
      "Col: tensao_barramento11 - RMSE: 0.004608901562946634\n",
      " ========== MODEL tensao_12 0 ============\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fa9edff2af0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fa9edff2af0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5639/5645 [============================>.] - ETA: 0s - loss: 0.0385WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fa9ef9024c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fa9ef9024c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 0.0385 - val_loss: 0.0057\n",
      "Epoch 2/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0054 - val_loss: 0.0034\n",
      "Epoch 3/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 0.0043 - val_loss: 0.0033\n",
      "Epoch 4/20\n",
      "5645/5645 [==============================] - 8s 2ms/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 5/20\n",
      "5645/5645 [==============================] - 10s 2ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 6/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 7/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 8/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 9/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 10/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 11/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 12/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 13/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0036 - val_loss: 0.0027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 15/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 16/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 0.0036 - val_loss: 0.0026\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa9ef902160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa9ef902160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2647/2647 [==============================] - 2s 681us/step\n",
      "Col: tensao_barramento12 - RMSE: 0.004909407171230402\n",
      " ========== MODEL tensao_24 0 ============\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7faa0274c820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7faa0274c820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5639/5645 [============================>.] - ETA: 0s - loss: 0.0391WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7faa02deb700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7faa02deb700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5645/5645 [==============================] - 10s 2ms/step - loss: 0.0390 - val_loss: 0.0053\n",
      "Epoch 2/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 0.0056 - val_loss: 0.0035\n",
      "Epoch 3/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 4/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 5/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 6/20\n",
      "5645/5645 [==============================] - 8s 2ms/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 7/20\n",
      "5645/5645 [==============================] - 10s 2ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 8/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 9/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 10/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 11/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 12/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 13/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 14/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 15/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 16/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 17/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 18/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 19/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 20/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0037 - val_loss: 0.0022\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7faa02debdc0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7faa02debdc0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2647/2647 [==============================] - 2s 645us/step\n",
      "Col: tensao_barramento24 - RMSE: 0.004585029086826697\n",
      " ========== MODEL ativa_11 0 ============\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7faa02da6700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7faa02da6700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5634/5645 [============================>.] - ETA: 0s - loss: 10.9617WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7faa02debc10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7faa02debc10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5645/5645 [==============================] - 9s 1ms/step - loss: 10.9558 - val_loss: 2.8444\n",
      "Epoch 2/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 7.3907 - val_loss: 2.5667\n",
      "Epoch 3/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 7.1320 - val_loss: 2.4279\n",
      "Epoch 4/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.9496 - val_loss: 2.4972\n",
      "Epoch 5/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.8434 - val_loss: 2.1773\n",
      "Epoch 6/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.7703 - val_loss: 2.5792\n",
      "Epoch 7/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.6800 - val_loss: 2.9088\n",
      "Epoch 8/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.6426 - val_loss: 2.0141\n",
      "Epoch 9/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.5507 - val_loss: 2.4403\n",
      "Epoch 10/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.4842 - val_loss: 2.0705\n",
      "Epoch 11/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.4343 - val_loss: 2.8382\n",
      "Epoch 12/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.4148 - val_loss: 1.9968\n",
      "Epoch 13/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.3528 - val_loss: 2.6974\n",
      "Epoch 14/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.2998 - val_loss: 3.0579\n",
      "Epoch 15/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.2747 - val_loss: 2.3136\n",
      "Epoch 16/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.2246 - val_loss: 3.7215\n",
      "Epoch 17/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.1847 - val_loss: 2.9086\n",
      "Epoch 18/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.1500 - val_loss: 2.6691\n",
      "Epoch 19/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.1368 - val_loss: 2.4698\n",
      "Epoch 20/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.0693 - val_loss: 3.1065\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa9ef8dd310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa9ef8dd310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2647/2647 [==============================] - 2s 655us/step\n",
      "Col: pot_ativa_inj_barramento11 - RMSE: 5.171993170569417\n",
      " ========== MODEL ativa_12 0 ============\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7faa02e4f940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7faa02e4f940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5620/5645 [============================>.] - ETA: 0s - loss: 11.2855WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fa9f09b21f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fa9f09b21f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 11.2719 - val_loss: 3.1392\n",
      "Epoch 2/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 7.9680 - val_loss: 3.5450\n",
      "Epoch 3/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 7.5206 - val_loss: 2.6172\n",
      "Epoch 4/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 7.2944 - val_loss: 2.1381\n",
      "Epoch 5/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 7.1759 - val_loss: 2.6801\n",
      "Epoch 6/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 7.0437 - val_loss: 2.3709\n",
      "Epoch 7/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 6.9966 - val_loss: 2.3017\n",
      "Epoch 8/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.8978 - val_loss: 2.0429\n",
      "Epoch 9/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.8301 - val_loss: 2.0926\n",
      "Epoch 10/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.6996 - val_loss: 1.8830\n",
      "Epoch 11/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.6589 - val_loss: 1.9898\n",
      "Epoch 12/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.5991 - val_loss: 2.4803\n",
      "Epoch 13/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.5181 - val_loss: 1.9967\n",
      "Epoch 14/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.4629 - val_loss: 1.8005\n",
      "Epoch 15/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.3678 - val_loss: 1.8340\n",
      "Epoch 16/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.3132 - val_loss: 1.7150\n",
      "Epoch 17/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.2716 - val_loss: 1.6836\n",
      "Epoch 18/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.2410 - val_loss: 2.0901\n",
      "Epoch 19/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.1716 - val_loss: 2.1367\n",
      "Epoch 20/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.0933 - val_loss: 1.7494\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa9ef1063a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa9ef1063a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2647/2647 [==============================] - 2s 638us/step\n",
      "Col: pot_ativa_inj_barramento12 - RMSE: 3.471655169919584\n",
      " ========== MODEL ativa_24 0 ============\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fa9f09e6040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fa9f09e6040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5619/5645 [============================>.] - ETA: 0s - loss: 9.1406WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fa9dc5c4310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fa9dc5c4310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 9.1299 - val_loss: 2.8684\n",
      "Epoch 2/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.5463 - val_loss: 2.3073\n",
      "Epoch 3/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.3446 - val_loss: 2.4324\n",
      "Epoch 4/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.1915 - val_loss: 2.4248\n",
      "Epoch 5/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.0816 - val_loss: 2.3673\n",
      "Epoch 6/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 5.9964 - val_loss: 3.4907\n",
      "Epoch 7/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 5.9371 - val_loss: 2.2024\n",
      "Epoch 8/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 5.8635 - val_loss: 3.4150\n",
      "Epoch 9/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 5.7722 - val_loss: 2.6847\n",
      "Epoch 10/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 5.7325 - val_loss: 2.2822\n",
      "Epoch 11/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 5.6786 - val_loss: 2.7986\n",
      "Epoch 12/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 5.6173 - val_loss: 2.8103\n",
      "Epoch 13/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 5.5657 - val_loss: 2.1078\n",
      "Epoch 14/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 5.5136 - val_loss: 2.3651\n",
      "Epoch 15/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 5.4813 - val_loss: 2.5946\n",
      "Epoch 16/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 5.4201 - val_loss: 2.0026\n",
      "Epoch 17/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 5.3455 - val_loss: 2.3907\n",
      "Epoch 18/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 5.3171 - val_loss: 2.6176\n",
      "Epoch 19/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 5.2549 - val_loss: 2.0301\n",
      "Epoch 20/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 5.2418 - val_loss: 2.2030\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa9ee9d3310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa9ee9d3310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2647/2647 [==============================] - 2s 652us/step\n",
      "Col: pot_ativa_inj_barramento24 - RMSE: 5.020392253067463\n",
      " ========== MODEL reativa_11 0 ============\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7faa1ed0b0d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7faa1ed0b0d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5606/5645 [============================>.] - ETA: 0s - loss: 8.2591WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7faa1ef42280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7faa1ef42280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 8.2418 - val_loss: 4.1806\n",
      "Epoch 2/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 4.9453 - val_loss: 3.1169\n",
      "Epoch 3/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 4.3297 - val_loss: 2.9928\n",
      "Epoch 4/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 4.0183 - val_loss: 2.8769\n",
      "Epoch 5/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.8466 - val_loss: 2.7666\n",
      "Epoch 6/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.7332 - val_loss: 2.7239\n",
      "Epoch 7/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.6474 - val_loss: 2.6052\n",
      "Epoch 8/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.5919 - val_loss: 2.7611\n",
      "Epoch 9/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.5332 - val_loss: 2.6382\n",
      "Epoch 10/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.5213 - val_loss: 2.8921\n",
      "Epoch 11/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.4749 - val_loss: 2.6171\n",
      "Epoch 12/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.4339 - val_loss: 2.7460\n",
      "Epoch 13/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.4212 - val_loss: 2.6637\n",
      "Epoch 14/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.4192 - val_loss: 2.6335\n",
      "Epoch 15/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.3671 - val_loss: 2.4849\n",
      "Epoch 16/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.3608 - val_loss: 2.5611\n",
      "Epoch 17/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.3423 - val_loss: 2.7206\n",
      "Epoch 18/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.3201 - val_loss: 2.6526\n",
      "Epoch 19/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.2957 - val_loss: 2.6767\n",
      "Epoch 20/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.2782 - val_loss: 2.6749\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7faa1eeb2040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7faa1eeb2040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2647/2647 [==============================] - 2s 637us/step\n",
      "Col: pot_reativa_inj_barramento11 - RMSE: 4.9159378719954665\n",
      " ========== MODEL reativa_12 0 ============\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fa9ed9350d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fa9ed9350d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5633/5645 [============================>.] - ETA: 0s - loss: 6.9143WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7faa1eec38b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7faa1eec38b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.9107 - val_loss: 3.5058\n",
      "Epoch 2/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 4.1858 - val_loss: 2.7570\n",
      "Epoch 3/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.7135 - val_loss: 2.4898\n",
      "Epoch 4/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.4754 - val_loss: 2.4118\n",
      "Epoch 5/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.3505 - val_loss: 2.3085\n",
      "Epoch 6/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.2709 - val_loss: 2.3032\n",
      "Epoch 7/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.2000 - val_loss: 2.2648\n",
      "Epoch 8/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.1517 - val_loss: 2.1352\n",
      "Epoch 9/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.1056 - val_loss: 2.1766\n",
      "Epoch 10/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.0722 - val_loss: 2.1006\n",
      "Epoch 11/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.0475 - val_loss: 2.0826\n",
      "Epoch 12/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.0139 - val_loss: 2.0993\n",
      "Epoch 13/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.9895 - val_loss: 2.0512\n",
      "Epoch 14/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.9760 - val_loss: 2.0332\n",
      "Epoch 15/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.9422 - val_loss: 2.0563\n",
      "Epoch 16/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.9209 - val_loss: 2.0833\n",
      "Epoch 17/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.9202 - val_loss: 2.0498\n",
      "Epoch 18/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.9047 - val_loss: 2.1159\n",
      "Epoch 19/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.8830 - val_loss: 2.0594\n",
      "Epoch 20/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.8655 - val_loss: 2.1363\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa9ed97f1f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa9ed97f1f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2647/2647 [==============================] - 2s 644us/step\n",
      "Col: pot_reativa_inj_barramento12 - RMSE: 3.897521539599893\n",
      " ========== MODEL reativa_24 0 ============\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fa9ef048040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fa9ef048040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5625/5645 [============================>.] - ETA: 0s - loss: 3.9097WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fa9f0992d30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fa9f0992d30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.9070 - val_loss: 2.1429\n",
      "Epoch 2/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.8535 - val_loss: 1.7483\n",
      "Epoch 3/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.5340 - val_loss: 1.5917\n",
      "Epoch 4/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.3598 - val_loss: 1.4700\n",
      "Epoch 5/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.2444 - val_loss: 1.4308\n",
      "Epoch 6/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.1502 - val_loss: 1.2838\n",
      "Epoch 7/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.0907 - val_loss: 1.2868\n",
      "Epoch 8/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.0246 - val_loss: 1.2140\n",
      "Epoch 9/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 1.9827 - val_loss: 1.2629\n",
      "Epoch 10/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 1.9255 - val_loss: 1.2149\n",
      "Epoch 11/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 1.8948 - val_loss: 1.1880\n",
      "Epoch 12/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 1.8564 - val_loss: 1.2197\n",
      "Epoch 13/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 1.8286 - val_loss: 1.1677\n",
      "Epoch 14/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 1.8006 - val_loss: 1.2533\n",
      "Epoch 15/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 1.7709 - val_loss: 1.1644\n",
      "Epoch 16/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 1.7403 - val_loss: 1.1094\n",
      "Epoch 17/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 1.7200 - val_loss: 1.1022\n",
      "Epoch 18/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 1.6947 - val_loss: 1.2128\n",
      "Epoch 19/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 1.6819 - val_loss: 1.1267\n",
      "Epoch 20/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 1.6569 - val_loss: 1.0967\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa9ed94cca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa9ed94cca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2647/2647 [==============================] - 2s 636us/step\n",
      "Col: pot_reativa_inj_barramento24 - RMSE: 1.8867576461046827\n",
      " ========== MODEL tensao_11 0 ============\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fa9ef069b80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fa9ef069b80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5643/5645 [============================>.] - ETA: 0s - loss: 0.0376WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fa9ef19aa60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fa9ef19aa60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0376 - val_loss: 0.0055\n",
      "Epoch 2/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0053 - val_loss: 0.0034\n",
      "Epoch 3/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 4/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 5/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 6/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 7/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 8/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 9/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 10/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 11/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 12/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 13/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 14/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 15/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 16/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 17/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 18/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 19/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 20/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0038 - val_loss: 0.0023\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7faa028bbee0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7faa028bbee0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2647/2647 [==============================] - 2s 624us/step\n",
      "Col: tensao_barramento11 - RMSE: 0.004739207653028754\n",
      " ========== MODEL tensao_12 0 ============\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7faa028bb280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7faa028bb280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5626/5645 [============================>.] - ETA: 0s - loss: 0.0371WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7faa0bd6f280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7faa0bd6f280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0370 - val_loss: 0.0060\n",
      "Epoch 2/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 3/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 4/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 5/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 6/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 7/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 8/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 9/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 10/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0037 - val_loss: 0.0022\n",
      "Epoch 11/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0037 - val_loss: 0.0022\n",
      "Epoch 12/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 13/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 14/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 15/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 16/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 17/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 18/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 19/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 20/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0036 - val_loss: 0.0024\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa9ee0ab160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa9ee0ab160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2647/2647 [==============================] - 2s 637us/step\n",
      "Col: tensao_barramento12 - RMSE: 0.004718390655920942\n",
      " ========== MODEL tensao_24 0 ============\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fa9ee0abaf0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fa9ee0abaf0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5621/5645 [============================>.] - ETA: 0s - loss: 0.0391WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fa9ee18d5e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fa9ee18d5e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0389 - val_loss: 0.0057\n",
      "Epoch 2/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0056 - val_loss: 0.0037\n",
      "Epoch 3/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0045 - val_loss: 0.0031\n",
      "Epoch 4/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 5/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 6/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 7/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 8/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 9/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 10/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 11/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 12/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 13/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 14/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0039 - val_loss: 0.0023\n",
      "Epoch 15/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 16/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 17/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 18/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0039 - val_loss: 0.0029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 20/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7faa026ae670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7faa026ae670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2647/2647 [==============================] - 2s 632us/step\n",
      "Col: tensao_barramento24 - RMSE: 0.0047302685032966675\n",
      " ========== MODEL ativa_11 0 ============\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7faa026aef70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7faa026aef70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5639/5645 [============================>.] - ETA: 0s - loss: 11.1624WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7faa026ae310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7faa026ae310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5645/5645 [==============================] - 9s 1ms/step - loss: 11.1589 - val_loss: 3.5953\n",
      "Epoch 2/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 7.4468 - val_loss: 2.7395\n",
      "Epoch 3/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 7.1290 - val_loss: 2.4125\n",
      "Epoch 4/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.9642 - val_loss: 2.6024\n",
      "Epoch 5/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.8295 - val_loss: 3.1668\n",
      "Epoch 6/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.7549 - val_loss: 2.8281\n",
      "Epoch 7/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.6846 - val_loss: 2.0257\n",
      "Epoch 8/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.6161 - val_loss: 2.1021\n",
      "Epoch 9/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.5503 - val_loss: 3.2688\n",
      "Epoch 10/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.5179 - val_loss: 2.0286\n",
      "Epoch 11/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.4814 - val_loss: 2.0491\n",
      "Epoch 12/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.4448 - val_loss: 2.1218\n",
      "Epoch 13/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.3757 - val_loss: 2.3803\n",
      "Epoch 14/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.3554 - val_loss: 2.0147\n",
      "Epoch 15/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.3080 - val_loss: 1.9692\n",
      "Epoch 16/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.2826 - val_loss: 2.8273\n",
      "Epoch 17/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.2058 - val_loss: 2.1612\n",
      "Epoch 18/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.1597 - val_loss: 3.9444\n",
      "Epoch 19/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.1338 - val_loss: 2.1918\n",
      "Epoch 20/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.1103 - val_loss: 3.4534\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa9ef19aca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa9ef19aca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2647/2647 [==============================] - 2s 620us/step\n",
      "Col: pot_ativa_inj_barramento11 - RMSE: 5.479977686887121\n",
      " ========== MODEL ativa_12 0 ============\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fa9ed94c040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fa9ed94c040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5604/5645 [============================>.] - ETA: 0s - loss: 11.5174WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fa9ed94c790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fa9ed94c790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 11.4931 - val_loss: 2.7569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 8.1146 - val_loss: 2.4334\n",
      "Epoch 3/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 7.7511 - val_loss: 2.7750\n",
      "Epoch 4/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 7.5147 - val_loss: 2.6156\n",
      "Epoch 5/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 7.3392 - val_loss: 2.7441\n",
      "Epoch 6/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 7.1814 - val_loss: 2.2493\n",
      "Epoch 7/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 7.1242 - val_loss: 3.4903\n",
      "Epoch 8/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 7.0231 - val_loss: 1.9061\n",
      "Epoch 9/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.9384 - val_loss: 2.7719\n",
      "Epoch 10/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.8337 - val_loss: 2.5158\n",
      "Epoch 11/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.7839 - val_loss: 1.7779\n",
      "Epoch 12/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.6729 - val_loss: 1.7427\n",
      "Epoch 13/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.6151 - val_loss: 1.8711\n",
      "Epoch 14/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.5722 - val_loss: 1.9629\n",
      "Epoch 15/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.5063 - val_loss: 1.8839\n",
      "Epoch 16/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.4152 - val_loss: 1.8327\n",
      "Epoch 17/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.3626 - val_loss: 1.9242\n",
      "Epoch 18/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.3067 - val_loss: 2.6052\n",
      "Epoch 19/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.2541 - val_loss: 1.6542\n",
      "Epoch 20/20\n",
      "5645/5645 [==============================] - 8s 2ms/step - loss: 6.1692 - val_loss: 1.7829\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa9ef048310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa9ef048310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2647/2647 [==============================] - 2s 640us/step\n",
      "Col: pot_ativa_inj_barramento12 - RMSE: 3.4830424114800698\n",
      " ========== MODEL ativa_24 0 ============\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fa9ef048d30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fa9ef048d30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5619/5645 [============================>.] - ETA: 0s - loss: 9.0477WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7faa1eec39d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7faa1eec39d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5645/5645 [==============================] - 11s 2ms/step - loss: 9.0368 - val_loss: 2.9730\n",
      "Epoch 2/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 6.5670 - val_loss: 3.4326\n",
      "Epoch 3/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 6.3496 - val_loss: 2.3366\n",
      "Epoch 4/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 6.1902 - val_loss: 2.3733\n",
      "Epoch 5/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 6.0814 - val_loss: 2.5909\n",
      "Epoch 6/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 5.9679 - val_loss: 2.2285\n",
      "Epoch 7/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 5.9008 - val_loss: 2.4231\n",
      "Epoch 8/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 5.8351 - val_loss: 2.3420\n",
      "Epoch 9/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 5.7855 - val_loss: 2.6052\n",
      "Epoch 10/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 5.7020 - val_loss: 2.6576\n",
      "Epoch 11/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 5.6511 - val_loss: 2.7589\n",
      "Epoch 12/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 5.5882 - val_loss: 2.4257\n",
      "Epoch 13/20\n",
      "5645/5645 [==============================] - 10s 2ms/step - loss: 5.5589 - val_loss: 2.2354\n",
      "Epoch 14/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 5.5193 - val_loss: 2.3137\n",
      "Epoch 15/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 5.4363 - val_loss: 2.3307\n",
      "Epoch 16/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 5.3838 - val_loss: 1.9577\n",
      "Epoch 17/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 5.3442 - val_loss: 1.9333\n",
      "Epoch 18/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 5.2824 - val_loss: 2.2776\n",
      "Epoch 19/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 5.2484 - val_loss: 2.1342\n",
      "Epoch 20/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 5.2082 - val_loss: 2.2066\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa9ed935040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa9ed935040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2647/2647 [==============================] - 2s 714us/step\n",
      "Col: pot_ativa_inj_barramento24 - RMSE: 4.905119477223769\n",
      " ========== MODEL reativa_11 0 ============\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7faa1ef42ca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7faa1ef42ca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5630/5645 [============================>.] - ETA: 0s - loss: 8.0404WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7faa1ef428b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7faa1ef428b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 8.0346 - val_loss: 4.0345\n",
      "Epoch 2/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 4.8502 - val_loss: 3.3659\n",
      "Epoch 3/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 4.2785 - val_loss: 2.9318\n",
      "Epoch 4/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 4.0054 - val_loss: 2.7523\n",
      "Epoch 5/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 3.8355 - val_loss: 2.7520\n",
      "Epoch 6/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 3.7337 - val_loss: 2.6256\n",
      "Epoch 7/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 3.6636 - val_loss: 2.7054\n",
      "Epoch 8/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 3.6080 - val_loss: 2.5694\n",
      "Epoch 9/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 3.5689 - val_loss: 2.5027\n",
      "Epoch 10/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 3.5307 - val_loss: 2.5966\n",
      "Epoch 11/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 3.4873 - val_loss: 2.6205\n",
      "Epoch 12/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 3.4679 - val_loss: 2.7743\n",
      "Epoch 13/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 3.4480 - val_loss: 2.7080\n",
      "Epoch 14/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 3.4054 - val_loss: 2.5401\n",
      "Epoch 15/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 3.3886 - val_loss: 2.4961\n",
      "Epoch 16/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 3.3652 - val_loss: 2.5581\n",
      "Epoch 17/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 3.3367 - val_loss: 2.5460\n",
      "Epoch 18/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 3.3187 - val_loss: 2.5441\n",
      "Epoch 19/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 3.3117 - val_loss: 2.4201\n",
      "Epoch 20/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 3.3072 - val_loss: 2.4937\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7faa1eed29d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7faa1eed29d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2647/2647 [==============================] - 2s 678us/step\n",
      "Col: pot_reativa_inj_barramento11 - RMSE: 4.956862539092317\n",
      " ========== MODEL reativa_12 0 ============\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fa9ee9d3430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fa9ee9d3430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5635/5645 [============================>.] - ETA: 0s - loss: 7.0839WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fa9dc5c4f70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fa9dc5c4f70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 7.0800 - val_loss: 3.6115\n",
      "Epoch 2/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 4.2956 - val_loss: 2.8421\n",
      "Epoch 3/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 3.8266 - val_loss: 2.6158\n",
      "Epoch 4/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 3.5624 - val_loss: 2.5381\n",
      "Epoch 5/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 3.4067 - val_loss: 2.4740\n",
      "Epoch 6/20\n",
      "5645/5645 [==============================] - 10s 2ms/step - loss: 3.2925 - val_loss: 2.4336\n",
      "Epoch 7/20\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 3.2233 - val_loss: 2.4885\n",
      "Epoch 8/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.1727 - val_loss: 2.3791\n",
      "Epoch 9/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.1236 - val_loss: 2.3880\n",
      "Epoch 10/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.0968 - val_loss: 2.3440\n",
      "Epoch 11/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.0752 - val_loss: 2.2419\n",
      "Epoch 12/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.0390 - val_loss: 2.2868\n",
      "Epoch 13/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.0171 - val_loss: 2.2299\n",
      "Epoch 14/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.9961 - val_loss: 2.2168\n",
      "Epoch 15/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.9668 - val_loss: 2.1789\n",
      "Epoch 16/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.9394 - val_loss: 2.1703\n",
      "Epoch 17/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.9126 - val_loss: 2.2292\n",
      "Epoch 18/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.8915 - val_loss: 2.0573\n",
      "Epoch 19/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.8681 - val_loss: 2.2450\n",
      "Epoch 20/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.8488 - val_loss: 2.0971\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa9ee9d31f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa9ee9d31f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2647/2647 [==============================] - 2s 664us/step\n",
      "Col: pot_reativa_inj_barramento12 - RMSE: 4.073559574859347\n",
      " ========== MODEL reativa_24 0 ============\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fa9ef106550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fa9ef106550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5635/5645 [============================>.] - ETA: 0s - loss: 3.9413WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fa9f09b2ee0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fa9f09b2ee0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 3.9397 - val_loss: 2.1077\n",
      "Epoch 2/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.8332 - val_loss: 1.8611\n",
      "Epoch 3/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.5359 - val_loss: 1.5985\n",
      "Epoch 4/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.3573 - val_loss: 1.6040\n",
      "Epoch 5/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.2483 - val_loss: 1.3804\n",
      "Epoch 6/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.1745 - val_loss: 1.4000\n",
      "Epoch 7/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.1066 - val_loss: 1.3205\n",
      "Epoch 8/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.0512 - val_loss: 1.2158\n",
      "Epoch 9/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.0060 - val_loss: 1.2371\n",
      "Epoch 10/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 1.9706 - val_loss: 1.3196\n",
      "Epoch 11/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 1.9407 - val_loss: 1.1701\n",
      "Epoch 12/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 1.9152 - val_loss: 1.1473\n",
      "Epoch 13/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 1.8786 - val_loss: 1.1386\n",
      "Epoch 14/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 1.8483 - val_loss: 1.1754\n",
      "Epoch 15/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 1.8273 - val_loss: 1.1533\n",
      "Epoch 16/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 1.8040 - val_loss: 1.1688\n",
      "Epoch 17/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 1.7819 - val_loss: 1.1124\n",
      "Epoch 18/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 1.7700 - val_loss: 1.0966\n",
      "Epoch 19/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 1.7488 - val_loss: 1.1221\n",
      "Epoch 20/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 1.7381 - val_loss: 1.1933\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7faa02e4f820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7faa02e4f820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2647/2647 [==============================] - 2s 641us/step\n",
      "Col: pot_reativa_inj_barramento24 - RMSE: 2.006733264777949\n",
      " ========== MODEL tensao_11 0 ============\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7faa027b9e50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7faa027b9e50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5620/5645 [============================>.] - ETA: 0s - loss: 0.0399WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fa9ef8dd700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fa9ef8dd700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5645/5645 [==============================] - 9s 1ms/step - loss: 0.0397 - val_loss: 0.0061\n",
      "Epoch 2/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0052 - val_loss: 0.0037\n",
      "Epoch 3/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 4/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 5/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 6/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 7/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 8/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 9/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 10/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 11/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 12/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 13/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 14/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 15/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 16/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 17/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 18/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 19/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 20/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0035 - val_loss: 0.0020\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7faa02deb160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7faa02deb160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2647/2647 [==============================] - 2s 652us/step\n",
      "Col: tensao_barramento11 - RMSE: 0.004570590871011484\n",
      " ========== MODEL tensao_12 0 ============\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7faa02da6670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7faa02da6670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5638/5645 [============================>.] - ETA: 0s - loss: 0.0382WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7faa028c9af0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7faa028c9af0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5645/5645 [==============================] - 9s 1ms/step - loss: 0.0382 - val_loss: 0.0055\n",
      "Epoch 2/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 3/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 4/20\n",
      "5645/5645 [==============================] - 8s 2ms/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 5/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 6/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 7/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 8/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 9/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 10/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 11/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 12/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 13/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 14/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 15/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 16/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 17/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 18/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0034 - val_loss: 0.0027\n",
      "Epoch 19/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 20/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0034 - val_loss: 0.0026\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa9ef18eaf0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa9ef18eaf0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2647/2647 [==============================] - 2s 661us/step\n",
      "Col: tensao_barramento12 - RMSE: 0.004610895403479053\n",
      " ========== MODEL tensao_24 0 ============\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7faa027b4040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7faa027b4040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5610/5645 [============================>.] - ETA: 0s - loss: 0.0387WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7faa027b49d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7faa027b49d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5645/5645 [==============================] - 9s 1ms/step - loss: 0.0385 - val_loss: 0.0054\n",
      "Epoch 2/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0055 - val_loss: 0.0035\n",
      "Epoch 3/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 4/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 5/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 6/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 7/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 8/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 9/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 10/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 11/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 12/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 13/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 14/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 15/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 16/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 17/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 18/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 19/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 20/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa9ef18e700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa9ef18e700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2647/2647 [==============================] - 2s 667us/step\n",
      "Col: tensao_barramento24 - RMSE: 0.004820943860968082\n",
      " ========== MODEL ativa_11 0 ============\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7faa02deb5e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7faa02deb5e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5608/5645 [============================>.] - ETA: 0s - loss: 11.4439WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7faa027b90d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7faa027b90d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 11.4190 - val_loss: 3.2698\n",
      "Epoch 2/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 7.5815 - val_loss: 2.6874\n",
      "Epoch 3/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 7.2734 - val_loss: 2.8765\n",
      "Epoch 4/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 7.1363 - val_loss: 3.1998\n",
      "Epoch 5/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 7.0239 - val_loss: 3.4504\n",
      "Epoch 6/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.9195 - val_loss: 3.0743\n",
      "Epoch 7/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.8317 - val_loss: 2.3704\n",
      "Epoch 8/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.7157 - val_loss: 2.3463\n",
      "Epoch 9/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.6477 - val_loss: 3.6961\n",
      "Epoch 10/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.5650 - val_loss: 3.0339\n",
      "Epoch 11/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.5110 - val_loss: 3.1900\n",
      "Epoch 12/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.4341 - val_loss: 3.7773\n",
      "Epoch 13/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.3747 - val_loss: 2.7382\n",
      "Epoch 14/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.3295 - val_loss: 2.7514\n",
      "Epoch 15/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.3091 - val_loss: 4.1490\n",
      "Epoch 16/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.2298 - val_loss: 3.1341\n",
      "Epoch 17/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.2096 - val_loss: 4.5168\n",
      "Epoch 18/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.1674 - val_loss: 3.3983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7faa02e4f160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7faa02e4f160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2647/2647 [==============================] - 2s 661us/step\n",
      "Col: pot_ativa_inj_barramento11 - RMSE: 5.958338649901098\n",
      " ========== MODEL ativa_12 0 ============\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fa9ef1064c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fa9ef1064c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5632/5645 [============================>.] - ETA: 0s - loss: 11.6055WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fa9f09e6310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fa9f09e6310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5645/5645 [==============================] - 9s 1ms/step - loss: 11.5990 - val_loss: 2.4860\n",
      "Epoch 2/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 8.2624 - val_loss: 2.8191\n",
      "Epoch 3/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 7.8845 - val_loss: 2.1177\n",
      "Epoch 4/20\n",
      "5645/5645 [==============================] - 8s 2ms/step - loss: 7.6147 - val_loss: 3.0624\n",
      "Epoch 5/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 7.4724 - val_loss: 2.0471\n",
      "Epoch 6/20\n",
      "5645/5645 [==============================] - 8s 2ms/step - loss: 7.3233 - val_loss: 2.4024\n",
      "Epoch 7/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 7.2288 - val_loss: 2.3794\n",
      "Epoch 8/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 7.1212 - val_loss: 2.9613\n",
      "Epoch 9/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 7.0363 - val_loss: 2.2025\n",
      "Epoch 10/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.9329 - val_loss: 2.1563\n",
      "Epoch 11/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.8736 - val_loss: 1.8635\n",
      "Epoch 12/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.8220 - val_loss: 2.3588\n",
      "Epoch 13/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.7262 - val_loss: 2.1454\n",
      "Epoch 14/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.6529 - val_loss: 1.7147\n",
      "Epoch 15/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.5538 - val_loss: 2.5157\n",
      "Epoch 16/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.5060 - val_loss: 2.5160\n",
      "Epoch 17/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.4107 - val_loss: 1.8297\n",
      "Epoch 18/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.3677 - val_loss: 1.8663\n",
      "Epoch 19/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.3075 - val_loss: 1.8058\n",
      "Epoch 20/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.2188 - val_loss: 1.7748\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa9ee9d3430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa9ee9d3430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2647/2647 [==============================] - 2s 645us/step\n",
      "Col: pot_ativa_inj_barramento12 - RMSE: 3.384510107978667\n",
      " ========== MODEL ativa_24 0 ============\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7faa1eed2d30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7faa1eed2d30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5643/5645 [============================>.] - ETA: 0s - loss: 8.7792WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7faa1eed2550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7faa1eed2550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5645/5645 [==============================] - 9s 1ms/step - loss: 8.7787 - val_loss: 2.7220\n",
      "Epoch 2/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.4200 - val_loss: 3.1188\n",
      "Epoch 3/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.1348 - val_loss: 2.5244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 6.0067 - val_loss: 2.3011\n",
      "Epoch 5/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 5.8987 - val_loss: 2.4761\n",
      "Epoch 6/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 5.7988 - val_loss: 2.0427\n",
      "Epoch 7/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 5.7642 - val_loss: 2.2831\n",
      "Epoch 8/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 5.6897 - val_loss: 2.3025\n",
      "Epoch 9/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 5.6147 - val_loss: 2.2298\n",
      "Epoch 10/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 5.5748 - val_loss: 2.3565\n",
      "Epoch 11/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 5.5307 - val_loss: 2.2534\n",
      "Epoch 12/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 5.4917 - val_loss: 2.1557\n",
      "Epoch 13/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 5.4276 - val_loss: 2.3340\n",
      "Epoch 14/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 5.4003 - val_loss: 2.2303\n",
      "Epoch 15/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 5.3441 - val_loss: 2.5008\n",
      "Epoch 16/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 5.3110 - val_loss: 2.3779\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7faa1ef42e50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7faa1ef42e50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2647/2647 [==============================] - 2s 668us/step\n",
      "Col: pot_ativa_inj_barramento24 - RMSE: 5.17201738958495\n",
      " ========== MODEL reativa_11 0 ============\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7faa1eeb2940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7faa1eeb2940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5620/5645 [============================>.] - ETA: 0s - loss: 8.1569WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7faa1eec30d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7faa1eec30d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5645/5645 [==============================] - 9s 1ms/step - loss: 8.1459 - val_loss: 4.0832\n",
      "Epoch 2/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 4.9030 - val_loss: 3.2943\n",
      "Epoch 3/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 4.2717 - val_loss: 2.9153\n",
      "Epoch 4/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.9751 - val_loss: 2.6680\n",
      "Epoch 5/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.8266 - val_loss: 2.7437\n",
      "Epoch 6/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.7275 - val_loss: 2.6936\n",
      "Epoch 7/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.6682 - val_loss: 2.7558\n",
      "Epoch 8/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.5901 - val_loss: 2.7756\n",
      "Epoch 9/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.5558 - val_loss: 2.6975\n",
      "Epoch 10/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.5391 - val_loss: 2.6567\n",
      "Epoch 11/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.4929 - val_loss: 2.6848\n",
      "Epoch 12/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.4615 - val_loss: 2.5240\n",
      "Epoch 13/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.4467 - val_loss: 2.5377\n",
      "Epoch 14/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.4041 - val_loss: 2.6223\n",
      "Epoch 15/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.4055 - val_loss: 2.5173\n",
      "Epoch 16/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.3786 - val_loss: 2.7876\n",
      "Epoch 17/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.3479 - val_loss: 2.6092\n",
      "Epoch 18/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.3354 - val_loss: 2.5209\n",
      "Epoch 19/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.3135 - val_loss: 2.4070\n",
      "Epoch 20/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.2959 - val_loss: 2.4670\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa9ed97f700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa9ed97f700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2647/2647 [==============================] - 2s 668us/step\n",
      "Col: pot_reativa_inj_barramento11 - RMSE: 4.7763485790316755\n",
      " ========== MODEL reativa_12 0 ============\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fa9ef048310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fa9ef048310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5630/5645 [============================>.] - ETA: 0s - loss: 6.9692WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fa9f0992040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fa9f0992040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5645/5645 [==============================] - 9s 1ms/step - loss: 6.9632 - val_loss: 3.6632\n",
      "Epoch 2/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 4.1827 - val_loss: 2.7321\n",
      "Epoch 3/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.7319 - val_loss: 2.5217\n",
      "Epoch 4/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.5051 - val_loss: 2.6949\n",
      "Epoch 5/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.3889 - val_loss: 2.3344\n",
      "Epoch 6/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.3021 - val_loss: 2.3347\n",
      "Epoch 7/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.2385 - val_loss: 2.2730\n",
      "Epoch 8/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.1697 - val_loss: 2.4288\n",
      "Epoch 9/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.1373 - val_loss: 2.1516\n",
      "Epoch 10/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.1022 - val_loss: 2.2734\n",
      "Epoch 11/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.0708 - val_loss: 2.3367\n",
      "Epoch 12/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.0545 - val_loss: 2.3170\n",
      "Epoch 13/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 3.0172 - val_loss: 2.2885\n",
      "Epoch 14/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.9842 - val_loss: 2.3027\n",
      "Epoch 15/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.9752 - val_loss: 2.1804\n",
      "Epoch 16/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.9436 - val_loss: 2.0525\n",
      "Epoch 17/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.9171 - val_loss: 2.1013\n",
      "Epoch 18/20\n",
      "5645/5645 [==============================] - 8s 2ms/step - loss: 2.9063 - val_loss: 2.0688\n",
      "Epoch 19/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.8916 - val_loss: 2.1447\n",
      "Epoch 20/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.8698 - val_loss: 2.1729\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa9ed94cdc0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa9ed94cdc0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2647/2647 [==============================] - 2s 652us/step\n",
      "Col: pot_reativa_inj_barramento12 - RMSE: 4.131623440078538\n",
      " ========== MODEL reativa_24 0 ============\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fa9ee18d790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fa9ee18d790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5640/5645 [============================>.] - ETA: 0s - loss: 3.9716WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fa9ef069f70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fa9ef069f70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5645/5645 [==============================] - 9s 2ms/step - loss: 3.9707 - val_loss: 2.1375\n",
      "Epoch 2/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.9066 - val_loss: 1.7790\n",
      "Epoch 3/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.6375 - val_loss: 1.5484\n",
      "Epoch 4/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.4476 - val_loss: 1.4905\n",
      "Epoch 5/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.3283 - val_loss: 1.3812\n",
      "Epoch 6/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.2366 - val_loss: 1.4926\n",
      "Epoch 7/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.1671 - val_loss: 1.2919\n",
      "Epoch 8/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.0930 - val_loss: 1.2188\n",
      "Epoch 9/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 2.0284 - val_loss: 1.2365\n",
      "Epoch 10/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 1.9686 - val_loss: 1.1838\n",
      "Epoch 11/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 1.9169 - val_loss: 1.1594\n",
      "Epoch 12/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 1.8701 - val_loss: 1.1234\n",
      "Epoch 13/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 1.8281 - val_loss: 1.1836\n",
      "Epoch 14/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 1.7943 - val_loss: 1.1739\n",
      "Epoch 15/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 1.7661 - val_loss: 1.1126\n",
      "Epoch 16/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 1.7415 - val_loss: 1.0761\n",
      "Epoch 17/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 1.7121 - val_loss: 1.1177\n",
      "Epoch 18/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 1.6923 - val_loss: 1.0352\n",
      "Epoch 19/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 1.6712 - val_loss: 1.0368\n",
      "Epoch 20/20\n",
      "5645/5645 [==============================] - 8s 1ms/step - loss: 1.6538 - val_loss: 1.0542\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa9ef19a310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa9ef19a310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2647/2647 [==============================] - 2s 649us/step\n",
      "Col: pot_reativa_inj_barramento24 - RMSE: 1.891687594827834\n"
     ]
    }
   ],
   "source": [
    "indexes = np.array(df.index.tolist())\n",
    "random.shuffle(indexes)\n",
    "ids_to_pred = np.split(indexes, 3)\n",
    "\n",
    "results_all = []\n",
    "for i in range(1):\n",
    "    results_per_ids = []\n",
    "    for idx2 in range(len(ids_to_pred)):\n",
    "        results = []\n",
    "        run_main(df, i, idx2, ids_to_pred[idx2])\n",
    "        results_per_ids.append(results)\n",
    "        \n",
    "    results_all.append(results_per_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00dd35a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0.12838775949833786,\n",
       "   0.002206688040836951,\n",
       "   0.0012965428007924568,\n",
       "   0.7572943327735299,\n",
       "   4.222648888146835,\n",
       "   6.200195255937593,\n",
       "   0.2681823673780483,\n",
       "   1.0811834587389944,\n",
       "   2.6473829603816634]]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b7dd0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd4f542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512ef330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bb1951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018a452f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb6fe06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f4968a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _result \u001b[38;5;129;01min\u001b[39;00m \u001b[43mresults_all\u001b[49m:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(results_all\u001b[38;5;241m.\u001b[39mindex(_result))\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m fold \u001b[38;5;129;01min\u001b[39;00m _result:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results_all' is not defined"
     ]
    }
   ],
   "source": [
    "for _result in results_all:\n",
    "    print(results_all.index(_result))\n",
    "    for fold in _result:\n",
    "        print(f\"{_result.index(fold)}: {sum(fold)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95513913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: [0.005618806104382909, 0.006374496128408189, 0.005003273984089787, 3.4735610445018055, 5.057355698378199, 3.6107973146928116, 7.466659649968084, 6.293739685672916, 2.4304372324265673]\n",
      "Fold 1: [0.004912833436191945, 0.006315874222206748, 0.0050400543592956865, 5.882427740243566, 3.5072674248462787, 3.786373119903367, 6.751693446504084, 6.168161926473203, 2.822188923073245]\n",
      "Fold 2: [0.004500589408310584, 0.004620877592182861, 0.005015842571451259, 3.953451113791048, 4.887246335988537, 4.617532544758241, 5.595597117037946, 5.241330146546544, 2.5569277207026158]\n",
      "Fold 3: [0.005904257261356303, 0.004717165985727671, 0.005687405161361025, 3.2969980512393264, 5.985023419883928, 3.5217441168282497, 8.310837484354026, 6.692027891640731, 3.3616694706450936]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Fold 0: {results_all[7][0]}\")\n",
    "print(f\"Fold 1: {results_all[4][1]}\")\n",
    "print(f\"Fold 2: {results_all[8][2]}\")\n",
    "print(f\"Fold 3: {results_all[3][3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a14c7dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_7_0 = pd.read_csv('7-0.csv')\n",
    "df_7_0 = df_7_0.rename(columns={\"Unnamed: 0\": \"id\"})\n",
    "\n",
    "df_4_1 = pd.read_csv('4-1.csv')\n",
    "df_4_1 = df_4_1.rename(columns={\"Unnamed: 0\": \"id\"})\n",
    "\n",
    "df_8_2 = pd.read_csv('8-2.csv')\n",
    "df_8_2 = df_8_2.rename(columns={\"Unnamed: 0\": \"id\"})\n",
    "\n",
    "df_3_3 = pd.read_csv('3-3.csv')\n",
    "df_3_3 = df_3_3.rename(columns={\"Unnamed: 0\": \"id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4e586e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best_predicted = pd.concat([df_7_0, df_4_1, df_8_2, df_3_3])\n",
    "df_best_predicted = df_best_predicted.sort_values(by=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf52f546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'tensao_barramento11', 'tensao_barramento12',\n",
       "       'tensao_barramento24', 'pot_ativa_inj_barramento11',\n",
       "       'pot_ativa_inj_barramento12', 'pot_ativa_inj_barramento24',\n",
       "       'pot_reativa_inj_barramento11', 'pot_reativa_inj_barramento12',\n",
       "       'pot_reativa_inj_barramento24'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_best_predicted.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "56c728e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       27.959498\n",
       "1       23.210810\n",
       "2       19.182219\n",
       "3       16.913922\n",
       "4       15.967630\n",
       "          ...    \n",
       "8755    14.528968\n",
       "8756    33.922939\n",
       "8757    27.785688\n",
       "8758    24.356531\n",
       "8759    21.964095\n",
       "Name: pot_reativa_inj_barramento24, Length: 8760, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pot_reativa_inj_barramento24']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5b646e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1296    27.959498\n",
       "1339    23.210810\n",
       "1886    19.182219\n",
       "2123    16.913922\n",
       "502     15.967630\n",
       "          ...    \n",
       "139     14.528968\n",
       "154     33.922939\n",
       "704     27.785688\n",
       "1381    24.356531\n",
       "2078    21.964095\n",
       "Name: pot_reativa_inj_barramento24, Length: 8760, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df_best_predicted['pot_reativa_inj_barramento24']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a319292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE tensao_barramento11: 0.005263612667191903\n",
      "RMSE tensao_barramento12: 0.005570651504552013\n",
      "RMSE tensao_barramento24: 0.005194712520332189\n",
      "RMSE pot_ativa_inj_barramento11: 0.0\n",
      "RMSE pot_ativa_inj_barramento12: 0.0\n",
      "RMSE pot_ativa_inj_barramento24: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"RMSE tensao_barramento11: {sqrt(mean_squared_error(df['tensao_barramento11'], df_best_predicted['tensao_barramento11']))}\")\n",
    "print(f\"RMSE tensao_barramento12: {sqrt(mean_squared_error(df['tensao_barramento12'], df_best_predicted['tensao_barramento12']))}\")\n",
    "print(f\"RMSE tensao_barramento24: {sqrt(mean_squared_error(df['tensao_barramento24'], df_best_predicted['tensao_barramento24']))}\")\n",
    "\n",
    "print(f\"RMSE pot_ativa_inj_barramento11: {sqrt(mean_squared_error(df['pot_ativa_inj_barramento11'], df_best_predicted['pot_ativa_inj_barramento11']))}\")\n",
    "print(f\"RMSE pot_ativa_inj_barramento12: {sqrt(mean_squared_error(df['pot_ativa_inj_barramento12'], df_best_predicted['pot_ativa_inj_barramento12']))}\")\n",
    "print(f\"RMSE pot_ativa_inj_barramento24: {sqrt(mean_squared_error(df['pot_ativa_inj_barramento24'], df_best_predicted['pot_ativa_inj_barramento24']))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "78ee91dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carga_subrede_138kv</th>\n",
       "      <th>pot_eolica_subrede_138kv</th>\n",
       "      <th>pot_solar_subrede_138kv</th>\n",
       "      <th>carga_subrede_230kv</th>\n",
       "      <th>pot_eolica_subrede_230kv</th>\n",
       "      <th>pot_solar_subrede_230kv</th>\n",
       "      <th>status_1_gerador_subrede138kv</th>\n",
       "      <th>status_2_gerador_subrede138kv</th>\n",
       "      <th>status_3_gerador_subrede138kv</th>\n",
       "      <th>status_4_gerador_subrede138kv</th>\n",
       "      <th>...</th>\n",
       "      <th>status_21_linha_subrede_230kv</th>\n",
       "      <th>tensao_barramento11</th>\n",
       "      <th>tensao_barramento12</th>\n",
       "      <th>tensao_barramento24</th>\n",
       "      <th>pot_ativa_inj_barramento11</th>\n",
       "      <th>pot_ativa_inj_barramento12</th>\n",
       "      <th>pot_ativa_inj_barramento24</th>\n",
       "      <th>pot_reativa_inj_barramento11</th>\n",
       "      <th>pot_reativa_inj_barramento12</th>\n",
       "      <th>pot_reativa_inj_barramento24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>1007.809524</td>\n",
       "      <td>401.818085</td>\n",
       "      <td>470.954682</td>\n",
       "      <td>1261.000862</td>\n",
       "      <td>71.944557</td>\n",
       "      <td>121.463748</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.981256</td>\n",
       "      <td>0.984862</td>\n",
       "      <td>0.975793</td>\n",
       "      <td>-58.51831</td>\n",
       "      <td>8.187012</td>\n",
       "      <td>24.743374</td>\n",
       "      <td>2.695873</td>\n",
       "      <td>8.599397</td>\n",
       "      <td>24.234942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     carga_subrede_138kv  pot_eolica_subrede_138kv  pot_solar_subrede_138kv  \\\n",
       "924          1007.809524                401.818085               470.954682   \n",
       "\n",
       "     carga_subrede_230kv  pot_eolica_subrede_230kv  pot_solar_subrede_230kv  \\\n",
       "924          1261.000862                 71.944557               121.463748   \n",
       "\n",
       "     status_1_gerador_subrede138kv  status_2_gerador_subrede138kv  \\\n",
       "924                              1                              1   \n",
       "\n",
       "     status_3_gerador_subrede138kv  status_4_gerador_subrede138kv  ...  \\\n",
       "924                              1                              1  ...   \n",
       "\n",
       "     status_21_linha_subrede_230kv  tensao_barramento11  tensao_barramento12  \\\n",
       "924                              1             0.981256             0.984862   \n",
       "\n",
       "     tensao_barramento24  pot_ativa_inj_barramento11  \\\n",
       "924             0.975793                   -58.51831   \n",
       "\n",
       "     pot_ativa_inj_barramento12  pot_ativa_inj_barramento24  \\\n",
       "924                    8.187012                   24.743374   \n",
       "\n",
       "     pot_reativa_inj_barramento11  pot_reativa_inj_barramento12  \\\n",
       "924                      2.695873                      8.599397   \n",
       "\n",
       "     pot_reativa_inj_barramento24  \n",
       "924                     24.234942  \n",
       "\n",
       "[1 rows x 90 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[[924]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d1065d59",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ========== MODEL tensao_11 0 ============\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.09023, saving model to models-new/ann-tensao_11-0.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.09023 to 0.05260, saving model to models-new/ann-tensao_11-0.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.05260 to 0.02550, saving model to models-new/ann-tensao_11-0.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.02550 to 0.01142, saving model to models-new/ann-tensao_11-0.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.01142 to 0.00536, saving model to models-new/ann-tensao_11-0.h5\n",
      "83/83 [==============================] - 0s 962us/step\n",
      "> \u001b[0;32m/tmp/ipykernel_7672/1406847328.py\u001b[0m(42)\u001b[0;36mrun\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     40 \u001b[0;31m    \u001b[0m_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     41 \u001b[0;31m    \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 42 \u001b[0;31m    \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     43 \u001b[0;31m    \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"RMSE: {rmse}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     44 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> _predictions\n",
      "array([[1.0164385],\n",
      "       [1.0171256],\n",
      "       [0.9599639],\n",
      "       ...,\n",
      "       [1.0027887],\n",
      "       [1.0020775],\n",
      "       [1.0048659]], dtype=float32)\n",
      "ipdb> savetxt('data.csv', _predictions, delimiter=',')\n",
      "ipdb> q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[0;32mIn [49]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m results \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m30\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mrun_main\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36mrun_main\u001b[0;34m(df, idx)\u001b[0m\n\u001b[1;32m     15\u001b[0m cols_pred \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensao_barramento11\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     16\u001b[0m model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensao_11\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 17\u001b[0m tensao_11_df \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcols_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m cols_pred \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensao_barramento12\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     20\u001b[0m model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensao_12\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "Input \u001b[0;32mIn [48]\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(df, cols, cols_pred, model_id, idx, update_test)\u001b[0m\n\u001b[1;32m     40\u001b[0m _predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(testX)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpdb\u001b[39;00m; pdb\u001b[38;5;241m.\u001b[39mset_trace()\n\u001b[0;32m---> 42\u001b[0m rmse \u001b[38;5;241m=\u001b[39m \u001b[43msqrt\u001b[49m(mean_squared_error(testY, _predictions))\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrmse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m c_results \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mget(idx, [])\n",
      "Input \u001b[0;32mIn [48]\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(df, cols, cols_pred, model_id, idx, update_test)\u001b[0m\n\u001b[1;32m     40\u001b[0m _predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(testX)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpdb\u001b[39;00m; pdb\u001b[38;5;241m.\u001b[39mset_trace()\n\u001b[0;32m---> 42\u001b[0m rmse \u001b[38;5;241m=\u001b[39m \u001b[43msqrt\u001b[49m(mean_squared_error(testY, _predictions))\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrmse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m c_results \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mget(idx, [])\n",
      "File \u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/bdb.py:88\u001b[0m, in \u001b[0;36mBdb.trace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;66;03m# None\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mline\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_line\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_call(frame, arg)\n",
      "File \u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/bdb.py:113\u001b[0m, in \u001b[0;36mBdb.dispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_here(frame) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbreak_here(frame):\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_line(frame)\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquitting: \u001b[38;5;28;01mraise\u001b[39;00m BdbQuit\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrace_dispatch\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for i in range(30):\n",
    "    run_main(df, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "822385dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_results = np.array(list(results.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6d9159d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without augmentation and new dataset (MAE)\n",
      "0.0070890919168230425\n",
      "0.007541286872679962\n",
      "0.007523444369988579\n",
      "10.894243509357642\n",
      "9.267402284153766\n",
      "9.371384044918205\n",
      "11.252243935611665\n",
      "9.437299328059101\n",
      "3.8338009920329936\n"
     ]
    }
   ],
   "source": [
    "print(\"Without augmentation and new dataset (MAE)\")\n",
    "for i in range(9):\n",
    "    print(sum(np_results[:, i]) / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "27a761b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With augmentation and new dataset (MAE)\n",
      "0.005665393469191508\n",
      "0.005968114200631143\n",
      "0.006086502990279516\n",
      "4.306654861961782\n",
      "4.929694810852576\n",
      "5.969859277039574\n",
      "8.037082282762213\n",
      "6.949571854237709\n",
      "3.0683251384838686\n"
     ]
    }
   ],
   "source": [
    "print(\"With augmentation and new dataset (MAE)\")\n",
    "for i in range(9):\n",
    "    print(sum(np_results[:, i]) / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a12819c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With augmentation and new dataset with 138kv\n",
      "0.0066337208966503495\n",
      "0.008000043449722296\n",
      "0.007588173150638114\n",
      "4.3975292615658095\n",
      "6.61129412958843\n",
      "7.356855111909887\n",
      "13.70290618834233\n",
      "11.36563117387233\n",
      "3.3401618094366077\n"
     ]
    }
   ],
   "source": [
    "print(\"With augmentation and new dataset with 138kv\")\n",
    "for i in range(9):\n",
    "    print(sum(np_results[:, i]) / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3eb18bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With augmentation and new dataset\n",
      "0.006926622726284169\n",
      "0.007056876000442106\n",
      "0.0065804778545112365\n",
      "5.432553705919982\n",
      "5.59374025258896\n",
      "5.02091411051572\n",
      "10.912814636247882\n",
      "9.373484699735132\n",
      "3.2685546341750764\n"
     ]
    }
   ],
   "source": [
    "print(\"With augmentation and new dataset\")\n",
    "for i in range(9):\n",
    "    print(sum(np_results[:, i]) / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7bf48947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without augmentation and new dataset\n",
      "0.006926622726284169\n",
      "0.007056876000442106\n",
      "0.0065804778545112365\n",
      "5.432553705919982\n",
      "5.59374025258896\n",
      "5.02091411051572\n",
      "10.912814636247882\n",
      "9.373484699735132\n",
      "3.2685546341750764\n"
     ]
    }
   ],
   "source": [
    "print(\"Without augmentation and new dataset\")\n",
    "for i in range(9):\n",
    "    print(sum(np_results[:, i]) / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6137567b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008563264243237792\n",
      "0.008851690008478937\n",
      "0.008759378146553693\n",
      "3.43743832269994\n",
      "4.166979929936218\n",
      "6.164294312250694\n",
      "5.174641738938345\n",
      "5.538004377575238\n",
      "3.710841119860305\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    print(sum(np_results[:, i]) / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "587f88bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0177697726419364\n",
      "0.017474690752547213\n",
      "0.01802198466043586\n",
      "37.83911595853088\n",
      "47.1200942223504\n",
      "55.18394663436637\n",
      "12.37940462639021\n",
      "16.0528277028151\n",
      "9.767292352196808\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    print(sum(np_results[:, i]) / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c4c5ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010302829257462714\n",
      "0.009528249833838341\n",
      "0.009607028976536487\n",
      "2.7364607725701724\n",
      "6.54437777406716\n",
      "11.961217698318539\n",
      "6.324785552014249\n",
      "6.815439932590181\n",
      "4.192799714407331\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    print(sum(np_results[:, i]) / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb092a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58.12975947284735"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df['pot_reativa_inj_barramento24']) - min(df['pot_reativa_inj_barramento24'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea173e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.642483761916"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df['pot_reativa_inj_barramento12']) - min(df['pot_reativa_inj_barramento12'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d22bb3fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.6307587013866"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df['pot_reativa_inj_barramento11']) - min(df['pot_reativa_inj_barramento11'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "6e3c8c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([input_df, output_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "01ee070f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, model_selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6ba84914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(data):\n",
    "    figure(figsize = (15, 6), dpi = 80)\n",
    "    plt.plot(data, label = 'Real')\n",
    "    #plt.plot(pred, color = 'blue', label = 'Predicted')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08c5316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "270700d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ========== MODEL tensao_12 ============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-19 11:38:01.824417: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-08-19 11:38:01.824457: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-08-19 11:38:01.824484: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (schlickmann): /proc/driver/nvidia/version does not exist\n",
      "2022-08-19 11:38:01.825490: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.2858\n",
      "Epoch 1: val_loss improved from inf to 0.17861, saving model to models/ann-tensao_12.h5\n",
      "614/614 [==============================] - 25s 40ms/step - loss: 0.2857 - val_loss: 0.1786\n",
      "Epoch 2/20\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.1822\n",
      "Epoch 2: val_loss did not improve from 0.17861\n",
      "614/614 [==============================] - 24s 39ms/step - loss: 0.1822 - val_loss: 0.1906\n",
      "Epoch 3/20\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.1655\n",
      "Epoch 3: val_loss improved from 0.17861 to 0.13944, saving model to models/ann-tensao_12.h5\n",
      "614/614 [==============================] - 24s 40ms/step - loss: 0.1654 - val_loss: 0.1394\n",
      "Epoch 4/20\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.1540\n",
      "Epoch 4: val_loss improved from 0.13944 to 0.13924, saving model to models/ann-tensao_12.h5\n",
      "614/614 [==============================] - 21s 34ms/step - loss: 0.1540 - val_loss: 0.1392\n",
      "Epoch 5/20\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.1467\n",
      "Epoch 5: val_loss improved from 0.13924 to 0.12109, saving model to models/ann-tensao_12.h5\n",
      "614/614 [==============================] - 25s 41ms/step - loss: 0.1466 - val_loss: 0.1211\n",
      "Epoch 6/20\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.1333\n",
      "Epoch 6: val_loss improved from 0.12109 to 0.10986, saving model to models/ann-tensao_12.h5\n",
      "614/614 [==============================] - 24s 39ms/step - loss: 0.1333 - val_loss: 0.1099\n",
      "Epoch 7/20\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.1307\n",
      "Epoch 7: val_loss improved from 0.10986 to 0.08814, saving model to models/ann-tensao_12.h5\n",
      "614/614 [==============================] - 24s 39ms/step - loss: 0.1307 - val_loss: 0.0881\n",
      "Epoch 8/20\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.1221\n",
      "Epoch 8: val_loss did not improve from 0.08814\n",
      "614/614 [==============================] - 24s 39ms/step - loss: 0.1221 - val_loss: 0.1086\n",
      "Epoch 9/20\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.1132\n",
      "Epoch 9: val_loss did not improve from 0.08814\n",
      "614/614 [==============================] - 25s 40ms/step - loss: 0.1132 - val_loss: 0.1191\n",
      "Epoch 10/20\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.1172\n",
      "Epoch 10: val_loss did not improve from 0.08814\n",
      "614/614 [==============================] - 24s 39ms/step - loss: 0.1174 - val_loss: 0.0939\n",
      "Epoch 11/20\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.1206\n",
      "Epoch 11: val_loss did not improve from 0.08814\n",
      "614/614 [==============================] - 25s 40ms/step - loss: 0.1206 - val_loss: 0.1081\n",
      "Epoch 12/20\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.1066\n",
      "Epoch 12: val_loss did not improve from 0.08814\n",
      "614/614 [==============================] - 22s 35ms/step - loss: 0.1066 - val_loss: 0.1302\n",
      "Epoch 13/20\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.1042\n",
      "Epoch 13: val_loss did not improve from 0.08814\n",
      "614/614 [==============================] - 24s 39ms/step - loss: 0.1042 - val_loss: 0.1043\n",
      "Epoch 14/20\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.1032\n",
      "Epoch 14: val_loss did not improve from 0.08814\n",
      "614/614 [==============================] - 24s 39ms/step - loss: 0.1032 - val_loss: 0.0990\n",
      "Epoch 15/20\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0971\n",
      "Epoch 15: val_loss did not improve from 0.08814\n",
      "614/614 [==============================] - 24s 39ms/step - loss: 0.0971 - val_loss: 0.0904\n",
      "Epoch 16/20\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.1012\n",
      "Epoch 16: val_loss did not improve from 0.08814\n",
      "614/614 [==============================] - 25s 41ms/step - loss: 0.1012 - val_loss: 0.1022\n",
      "Epoch 17/20\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.0926\n",
      "Epoch 17: val_loss did not improve from 0.08814\n",
      "614/614 [==============================] - 25s 40ms/step - loss: 0.0926 - val_loss: 0.1063\n",
      "Epoch 17: early stopping\n",
      "83/83 [==============================] - 1s 9ms/step\n",
      "RMSE: 0.0014616258270620291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66249/2835460861.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_for_testing[cols_pred[0]] = predictions[:,-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ========== MODEL tensao_11 ============\n",
      "Epoch 1/20\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.2649\n",
      "Epoch 1: val_loss improved from inf to 0.18844, saving model to models/ann-tensao_11.h5\n",
      "614/614 [==============================] - 25s 39ms/step - loss: 0.2649 - val_loss: 0.1884\n",
      "Epoch 2/20\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.1875\n",
      "Epoch 2: val_loss improved from 0.18844 to 0.18284, saving model to models/ann-tensao_11.h5\n",
      "614/614 [==============================] - 21s 34ms/step - loss: 0.1874 - val_loss: 0.1828\n",
      "Epoch 3/20\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.1544\n",
      "Epoch 3: val_loss improved from 0.18284 to 0.16195, saving model to models/ann-tensao_11.h5\n",
      "614/614 [==============================] - 21s 35ms/step - loss: 0.1544 - val_loss: 0.1620\n",
      "Epoch 4/20\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.1481\n",
      "Epoch 4: val_loss improved from 0.16195 to 0.10331, saving model to models/ann-tensao_11.h5\n",
      "614/614 [==============================] - 20s 32ms/step - loss: 0.1480 - val_loss: 0.1033\n",
      "Epoch 5/20\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.1304\n",
      "Epoch 5: val_loss improved from 0.10331 to 0.09827, saving model to models/ann-tensao_11.h5\n",
      "614/614 [==============================] - 21s 34ms/step - loss: 0.1304 - val_loss: 0.0983\n",
      "Epoch 6/20\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.1244\n",
      "Epoch 6: val_loss did not improve from 0.09827\n",
      "614/614 [==============================] - 20s 32ms/step - loss: 0.1243 - val_loss: 0.1212\n",
      "Epoch 7/20\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.1257\n",
      "Epoch 7: val_loss improved from 0.09827 to 0.09533, saving model to models/ann-tensao_11.h5\n",
      "614/614 [==============================] - 19s 32ms/step - loss: 0.1257 - val_loss: 0.0953\n",
      "Epoch 8/20\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.1248\n",
      "Epoch 8: val_loss improved from 0.09533 to 0.09193, saving model to models/ann-tensao_11.h5\n",
      "614/614 [==============================] - 21s 34ms/step - loss: 0.1247 - val_loss: 0.0919\n",
      "Epoch 9/20\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.1167\n",
      "Epoch 9: val_loss improved from 0.09193 to 0.09085, saving model to models/ann-tensao_11.h5\n",
      "614/614 [==============================] - 20s 32ms/step - loss: 0.1166 - val_loss: 0.0908\n",
      "Epoch 10/20\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.1133\n",
      "Epoch 10: val_loss did not improve from 0.09085\n",
      "614/614 [==============================] - 28s 46ms/step - loss: 0.1133 - val_loss: 0.1006\n",
      "Epoch 11/20\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.1052\n",
      "Epoch 11: val_loss improved from 0.09085 to 0.06882, saving model to models/ann-tensao_11.h5\n",
      "614/614 [==============================] - 23s 37ms/step - loss: 0.1052 - val_loss: 0.0688\n",
      "Epoch 12/20\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.1070\n",
      "Epoch 12: val_loss did not improve from 0.06882\n",
      "614/614 [==============================] - 19s 31ms/step - loss: 0.1070 - val_loss: 0.0824\n",
      "Epoch 13/20\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0998\n",
      "Epoch 13: val_loss did not improve from 0.06882\n",
      "614/614 [==============================] - 19s 32ms/step - loss: 0.0998 - val_loss: 0.0724\n",
      "Epoch 14/20\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.0934\n",
      "Epoch 14: val_loss did not improve from 0.06882\n",
      "614/614 [==============================] - 18s 30ms/step - loss: 0.0934 - val_loss: 0.0989\n",
      "Epoch 15/20\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.0976\n",
      "Epoch 15: val_loss improved from 0.06882 to 0.05757, saving model to models/ann-tensao_11.h5\n",
      "614/614 [==============================] - 21s 34ms/step - loss: 0.0976 - val_loss: 0.0576\n",
      "Epoch 16/20\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0887\n",
      "Epoch 16: val_loss did not improve from 0.05757\n",
      "614/614 [==============================] - 20s 32ms/step - loss: 0.0886 - val_loss: 0.0737\n",
      "Epoch 17/20\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0907\n",
      "Epoch 17: val_loss did not improve from 0.05757\n",
      "614/614 [==============================] - 26s 42ms/step - loss: 0.0907 - val_loss: 0.0691\n",
      "Epoch 18/20\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0880\n",
      "Epoch 18: val_loss did not improve from 0.05757\n",
      "614/614 [==============================] - 24s 39ms/step - loss: 0.0880 - val_loss: 0.0708\n",
      "Epoch 19/20\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0885\n",
      "Epoch 19: val_loss did not improve from 0.05757\n",
      "614/614 [==============================] - 22s 36ms/step - loss: 0.0885 - val_loss: 0.0871\n",
      "Epoch 20/20\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0826\n",
      "Epoch 20: val_loss did not improve from 0.05757\n",
      "614/614 [==============================] - 21s 34ms/step - loss: 0.0826 - val_loss: 0.1003\n",
      "83/83 [==============================] - 1s 7ms/step\n",
      "RMSE: 0.001462005370731984\n",
      " ========== MODEL tensao_24 ============\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66249/2835460861.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_for_testing[cols_pred[0]] = predictions[:,-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614/614 [==============================] - ETA: 0s - loss: 0.2799\n",
      "Epoch 1: val_loss improved from inf to 0.13066, saving model to models/ann-tensao_24.h5\n",
      "614/614 [==============================] - 20s 32ms/step - loss: 0.2799 - val_loss: 0.1307\n",
      "Epoch 2/20\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.1675\n",
      "Epoch 2: val_loss improved from 0.13066 to 0.12800, saving model to models/ann-tensao_24.h5\n",
      "614/614 [==============================] - 21s 35ms/step - loss: 0.1675 - val_loss: 0.1280\n",
      "Epoch 3/20\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.1388\n",
      "Epoch 3: val_loss improved from 0.12800 to 0.10169, saving model to models/ann-tensao_24.h5\n",
      "614/614 [==============================] - 19s 30ms/step - loss: 0.1387 - val_loss: 0.1017\n",
      "Epoch 4/20\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.1279\n",
      "Epoch 4: val_loss did not improve from 0.10169\n",
      "614/614 [==============================] - 20s 33ms/step - loss: 0.1279 - val_loss: 0.1166\n",
      "Epoch 5/20\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.1156\n",
      "Epoch 5: val_loss improved from 0.10169 to 0.10125, saving model to models/ann-tensao_24.h5\n",
      "614/614 [==============================] - 24s 38ms/step - loss: 0.1156 - val_loss: 0.1013\n",
      "Epoch 6/20\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.1131\n",
      "Epoch 6: val_loss did not improve from 0.10125\n",
      "614/614 [==============================] - 23s 37ms/step - loss: 0.1131 - val_loss: 0.1091\n",
      "Epoch 7/20\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.1107\n",
      "Epoch 7: val_loss improved from 0.10125 to 0.07981, saving model to models/ann-tensao_24.h5\n",
      "614/614 [==============================] - 21s 35ms/step - loss: 0.1107 - val_loss: 0.0798\n",
      "Epoch 8/20\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.1052\n",
      "Epoch 8: val_loss did not improve from 0.07981\n",
      "614/614 [==============================] - 21s 34ms/step - loss: 0.1052 - val_loss: 0.1009\n",
      "Epoch 9/20\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.0958\n",
      "Epoch 9: val_loss improved from 0.07981 to 0.07771, saving model to models/ann-tensao_24.h5\n",
      "614/614 [==============================] - 23s 38ms/step - loss: 0.0958 - val_loss: 0.0777\n",
      "Epoch 10/20\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.0975\n",
      "Epoch 10: val_loss improved from 0.07771 to 0.07067, saving model to models/ann-tensao_24.h5\n",
      "614/614 [==============================] - 25s 41ms/step - loss: 0.0975 - val_loss: 0.0707\n",
      "Epoch 11/20\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0991\n",
      "Epoch 11: val_loss did not improve from 0.07067\n",
      "614/614 [==============================] - 21s 34ms/step - loss: 0.0992 - val_loss: 0.1126\n",
      "Epoch 12/20\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.0924\n",
      "Epoch 12: val_loss did not improve from 0.07067\n",
      "614/614 [==============================] - 18s 30ms/step - loss: 0.0924 - val_loss: 0.0965\n",
      "Epoch 13/20\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.0907\n",
      "Epoch 13: val_loss did not improve from 0.07067\n",
      "614/614 [==============================] - 19s 30ms/step - loss: 0.0907 - val_loss: 0.0862\n",
      "Epoch 14/20\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0969\n",
      "Epoch 14: val_loss improved from 0.07067 to 0.06387, saving model to models/ann-tensao_24.h5\n",
      "614/614 [==============================] - 19s 31ms/step - loss: 0.0970 - val_loss: 0.0639\n",
      "Epoch 15/20\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.0842\n",
      "Epoch 15: val_loss did not improve from 0.06387\n",
      "614/614 [==============================] - 19s 30ms/step - loss: 0.0842 - val_loss: 0.0640\n",
      "Epoch 16/20\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.0804\n",
      "Epoch 16: val_loss improved from 0.06387 to 0.06229, saving model to models/ann-tensao_24.h5\n",
      "614/614 [==============================] - 19s 31ms/step - loss: 0.0804 - val_loss: 0.0623\n",
      "Epoch 17/20\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0821\n",
      "Epoch 17: val_loss did not improve from 0.06229\n",
      "614/614 [==============================] - 18s 30ms/step - loss: 0.0821 - val_loss: 0.0839\n",
      "Epoch 18/20\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0779\n",
      "Epoch 18: val_loss did not improve from 0.06229\n",
      "614/614 [==============================] - 19s 30ms/step - loss: 0.0779 - val_loss: 0.0918\n",
      "Epoch 19/20\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0831\n",
      "Epoch 19: val_loss did not improve from 0.06229\n",
      "614/614 [==============================] - 19s 30ms/step - loss: 0.0831 - val_loss: 0.0708\n",
      "Epoch 20/20\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.0806\n",
      "Epoch 20: val_loss did not improve from 0.06229\n",
      "614/614 [==============================] - 18s 30ms/step - loss: 0.0806 - val_loss: 0.0727\n",
      "83/83 [==============================] - 0s 5ms/step\n",
      "RMSE: 0.0012612803884356001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66249/2835460861.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_for_testing[cols_pred[0]] = predictions[:,-1]\n"
     ]
    }
   ],
   "source": [
    "cols = ['carga_subrede_138kv',\n",
    "        'pot_eolica_subrede_138kv',\n",
    "        'pot_solar_subrede_138kv',\n",
    "        'carga_subrede_230kv',\n",
    "        'pot_eolica_subrede_230kv',\n",
    "        'pot_solar_subrede_230kv']\n",
    "\n",
    "cols_pred = ['tensao_barramento12']\n",
    "model_id = 'tensao_12'\n",
    "tensao_12_df = run(df, cols, cols_pred, model_id, update_test=True)\n",
    "\n",
    "cols_pred = ['tensao_barramento11']\n",
    "model_id = 'tensao_11'\n",
    "tensao_11_df = run(df, cols, cols_pred, model_id, update_test=True)\n",
    "\n",
    "cols_pred = ['tensao_barramento24']\n",
    "model_id = 'tensao_24'\n",
    "tensao_24_df = run(df, cols, cols_pred, model_id, update_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "399f2b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tensao_barramento11'] = tensao_11_df['tensao_barramento11']\n",
    "df['tensao_barramento12'] = tensao_12_df['tensao_barramento12']\n",
    "df['tensao_barramento24'] = tensao_24_df['tensao_barramento24']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "148a9587",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['carga_subrede_138kv',\n",
    "        'pot_eolica_subrede_138kv',\n",
    "        'pot_solar_subrede_138kv',\n",
    "        'carga_subrede_230kv',\n",
    "        'pot_eolica_subrede_230kv',\n",
    "        'pot_solar_subrede_230kv',\n",
    "        'tensao_barramento11',\n",
    "        'tensao_barramento12',\n",
    "         'tensao_barramento24'\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74147472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ========== MODEL pot_ativa_inj_barramento11 ============\n",
      "Epoch 1/20\n",
      "600/614 [============================>.] - ETA: 0s - loss: 0.0813\n",
      "Epoch 1: val_loss improved from inf to 0.00606, saving model to models-new/ann-pot_ativa_inj_barramento11.h5\n",
      "614/614 [==============================] - 3s 4ms/step - loss: 0.0807 - val_loss: 0.0061\n",
      "Epoch 2/20\n",
      "603/614 [============================>.] - ETA: 0s - loss: 0.0442\n",
      "Epoch 2: val_loss improved from 0.00606 to 0.00562, saving model to models-new/ann-pot_ativa_inj_barramento11.h5\n",
      "614/614 [==============================] - 2s 4ms/step - loss: 0.0441 - val_loss: 0.0056\n",
      "Epoch 3/20\n",
      "600/614 [============================>.] - ETA: 0s - loss: 0.0447\n",
      "Epoch 3: val_loss improved from 0.00562 to 0.00510, saving model to models-new/ann-pot_ativa_inj_barramento11.h5\n",
      "614/614 [==============================] - 2s 4ms/step - loss: 0.0446 - val_loss: 0.0051\n",
      "Epoch 4/20\n",
      "608/614 [============================>.] - ETA: 0s - loss: 0.0421\n",
      "Epoch 4: val_loss did not improve from 0.00510\n",
      "614/614 [==============================] - 2s 4ms/step - loss: 0.0423 - val_loss: 0.0055\n",
      "Epoch 5/20\n",
      "600/614 [============================>.] - ETA: 0s - loss: 0.0418\n",
      "Epoch 5: val_loss did not improve from 0.00510\n",
      "614/614 [==============================] - 2s 4ms/step - loss: 0.0419 - val_loss: 0.0061\n",
      "Epoch 6/20\n",
      "597/614 [============================>.] - ETA: 0s - loss: 0.0387\n",
      "Epoch 6: val_loss did not improve from 0.00510\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0389 - val_loss: 0.0069\n",
      "Epoch 7/20\n",
      "603/614 [============================>.] - ETA: 0s - loss: 0.0403\n",
      "Epoch 7: val_loss did not improve from 0.00510\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0401 - val_loss: 0.0099\n",
      "Epoch 8/20\n",
      "608/614 [============================>.] - ETA: 0s - loss: 0.0359\n",
      "Epoch 8: val_loss improved from 0.00510 to 0.00322, saving model to models-new/ann-pot_ativa_inj_barramento11.h5\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0357 - val_loss: 0.0032\n",
      "Epoch 9/20\n",
      "599/614 [============================>.] - ETA: 0s - loss: 0.0355\n",
      "Epoch 9: val_loss improved from 0.00322 to 0.00259, saving model to models-new/ann-pot_ativa_inj_barramento11.h5\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0354 - val_loss: 0.0026\n",
      "Epoch 10/20\n",
      "596/614 [============================>.] - ETA: 0s - loss: 0.0385\n",
      "Epoch 10: val_loss did not improve from 0.00259\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0383 - val_loss: 0.0203\n",
      "Epoch 11/20\n",
      "602/614 [============================>.] - ETA: 0s - loss: 0.0381\n",
      "Epoch 11: val_loss did not improve from 0.00259\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0380 - val_loss: 0.0053\n",
      "Epoch 12/20\n",
      "605/614 [============================>.] - ETA: 0s - loss: 0.0356\n",
      "Epoch 12: val_loss did not improve from 0.00259\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0357 - val_loss: 0.0048\n",
      "Epoch 13/20\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0369\n",
      "Epoch 13: val_loss did not improve from 0.00259\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0369 - val_loss: 0.0118\n",
      "Epoch 14/20\n",
      "596/614 [============================>.] - ETA: 0s - loss: 0.0364\n",
      "Epoch 14: val_loss did not improve from 0.00259\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0364 - val_loss: 0.0036\n",
      "Epoch 15/20\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.0360\n",
      "Epoch 15: val_loss did not improve from 0.00259\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0360 - val_loss: 0.0111\n",
      "Epoch 16/20\n",
      "598/614 [============================>.] - ETA: 0s - loss: 0.0348\n",
      "Epoch 16: val_loss did not improve from 0.00259\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0350 - val_loss: 0.0053\n",
      "Epoch 17/20\n",
      "597/614 [============================>.] - ETA: 0s - loss: 0.0396\n",
      "Epoch 17: val_loss did not improve from 0.00259\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0395 - val_loss: 0.0088\n",
      "Epoch 18/20\n",
      "596/614 [============================>.] - ETA: 0s - loss: 0.0362\n",
      "Epoch 18: val_loss did not improve from 0.00259\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0362 - val_loss: 0.0037\n",
      "Epoch 19/20\n",
      "604/614 [============================>.] - ETA: 0s - loss: 0.0366\n",
      "Epoch 19: val_loss did not improve from 0.00259\n",
      "614/614 [==============================] - 3s 4ms/step - loss: 0.0367 - val_loss: 0.0036\n",
      "Epoch 19: early stopping\n",
      "83/83 [==============================] - 0s 2ms/step\n",
      "RMSE: 0.28640980048844894\n"
     ]
    }
   ],
   "source": [
    "cols_pred = ['pot_ativa_inj_barramento11']\n",
    "model_id = 'pot_ativa_inj_barramento11'\n",
    "pot_ativa_inj_barramento11_df = run(df, cols, cols_pred, model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00c48bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ========== MODEL pot_ativa_inj_barramento12 ============\n",
      "Epoch 1/20\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.0757\n",
      "Epoch 1: val_loss improved from inf to 0.02582, saving model to models-new/ann-pot_ativa_inj_barramento12.h5\n",
      "614/614 [==============================] - 3s 4ms/step - loss: 0.0757 - val_loss: 0.0258\n",
      "Epoch 2/20\n",
      "601/614 [============================>.] - ETA: 0s - loss: 0.0488\n",
      "Epoch 2: val_loss improved from 0.02582 to 0.02114, saving model to models-new/ann-pot_ativa_inj_barramento12.h5\n",
      "614/614 [==============================] - 2s 4ms/step - loss: 0.0488 - val_loss: 0.0211\n",
      "Epoch 3/20\n",
      "608/614 [============================>.] - ETA: 0s - loss: 0.0455\n",
      "Epoch 3: val_loss improved from 0.02114 to 0.01111, saving model to models-new/ann-pot_ativa_inj_barramento12.h5\n",
      "614/614 [==============================] - 2s 4ms/step - loss: 0.0454 - val_loss: 0.0111\n",
      "Epoch 4/20\n",
      "609/614 [============================>.] - ETA: 0s - loss: 0.0453\n",
      "Epoch 4: val_loss improved from 0.01111 to 0.00419, saving model to models-new/ann-pot_ativa_inj_barramento12.h5\n",
      "614/614 [==============================] - 3s 4ms/step - loss: 0.0454 - val_loss: 0.0042\n",
      "Epoch 5/20\n",
      "611/614 [============================>.] - ETA: 0s - loss: 0.0452\n",
      "Epoch 5: val_loss did not improve from 0.00419\n",
      "614/614 [==============================] - 3s 4ms/step - loss: 0.0451 - val_loss: 0.0099\n",
      "Epoch 6/20\n",
      "612/614 [============================>.] - ETA: 0s - loss: 0.0440\n",
      "Epoch 6: val_loss did not improve from 0.00419\n",
      "614/614 [==============================] - 4s 7ms/step - loss: 0.0441 - val_loss: 0.0050\n",
      "Epoch 7/20\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.0412\n",
      "Epoch 7: val_loss did not improve from 0.00419\n",
      "614/614 [==============================] - 3s 6ms/step - loss: 0.0412 - val_loss: 0.0090\n",
      "Epoch 8/20\n",
      "607/614 [============================>.] - ETA: 0s - loss: 0.0410\n",
      "Epoch 8: val_loss improved from 0.00419 to 0.00249, saving model to models-new/ann-pot_ativa_inj_barramento12.h5\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0414 - val_loss: 0.0025\n",
      "Epoch 9/20\n",
      "606/614 [============================>.] - ETA: 0s - loss: 0.0420\n",
      "Epoch 9: val_loss did not improve from 0.00249\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0420 - val_loss: 0.0241\n",
      "Epoch 10/20\n",
      "607/614 [============================>.] - ETA: 0s - loss: 0.0387\n",
      "Epoch 10: val_loss did not improve from 0.00249\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0386 - val_loss: 0.0106\n",
      "Epoch 11/20\n",
      "595/614 [============================>.] - ETA: 0s - loss: 0.0417\n",
      "Epoch 11: val_loss did not improve from 0.00249\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0421 - val_loss: 0.0058\n",
      "Epoch 12/20\n",
      "604/614 [============================>.] - ETA: 0s - loss: 0.0419\n",
      "Epoch 12: val_loss did not improve from 0.00249\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0417 - val_loss: 0.0124\n",
      "Epoch 13/20\n",
      "603/614 [============================>.] - ETA: 0s - loss: 0.0415\n",
      "Epoch 13: val_loss did not improve from 0.00249\n",
      "614/614 [==============================] - 2s 2ms/step - loss: 0.0413 - val_loss: 0.0050\n",
      "Epoch 14/20\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.0424\n",
      "Epoch 14: val_loss did not improve from 0.00249\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0424 - val_loss: 0.0223\n",
      "Epoch 15/20\n",
      "610/614 [============================>.] - ETA: 0s - loss: 0.0407\n",
      "Epoch 15: val_loss did not improve from 0.00249\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0406 - val_loss: 0.0264\n",
      "Epoch 16/20\n",
      "606/614 [============================>.] - ETA: 0s - loss: 0.0396\n",
      "Epoch 16: val_loss did not improve from 0.00249\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0399 - val_loss: 0.0048\n",
      "Epoch 17/20\n",
      "611/614 [============================>.] - ETA: 0s - loss: 0.0390\n",
      "Epoch 17: val_loss did not improve from 0.00249\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0389 - val_loss: 0.0070\n",
      "Epoch 18/20\n",
      "605/614 [============================>.] - ETA: 0s - loss: 0.0418\n",
      "Epoch 18: val_loss did not improve from 0.00249\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0419 - val_loss: 0.0055\n",
      "Epoch 18: early stopping\n",
      "83/83 [==============================] - 0s 909us/step\n",
      "RMSE: 0.5085183182930977\n"
     ]
    }
   ],
   "source": [
    "cols_pred = ['pot_ativa_inj_barramento12']\n",
    "model_id = 'pot_ativa_inj_barramento12'\n",
    "pot_ativa_inj_barramento12_df = run(df, cols, cols_pred, model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "733d653e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ========== MODEL pot_ativa_inj_barramento24 ============\n",
      "Epoch 1/20\n",
      "606/614 [============================>.] - ETA: 0s - loss: 0.0685\n",
      "Epoch 1: val_loss improved from inf to 0.01302, saving model to models-new/ann-pot_ativa_inj_barramento24.h5\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0682 - val_loss: 0.0130\n",
      "Epoch 2/20\n",
      "593/614 [===========================>..] - ETA: 0s - loss: 0.0459\n",
      "Epoch 2: val_loss improved from 0.01302 to 0.00820, saving model to models-new/ann-pot_ativa_inj_barramento24.h5\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0456 - val_loss: 0.0082\n",
      "Epoch 3/20\n",
      "585/614 [===========================>..] - ETA: 0s - loss: 0.0407\n",
      "Epoch 3: val_loss did not improve from 0.00820\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0409 - val_loss: 0.0248\n",
      "Epoch 4/20\n",
      "603/614 [============================>.] - ETA: 0s - loss: 0.0387\n",
      "Epoch 4: val_loss did not improve from 0.00820\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0384 - val_loss: 0.0096\n",
      "Epoch 5/20\n",
      "606/614 [============================>.] - ETA: 0s - loss: 0.0395\n",
      "Epoch 5: val_loss did not improve from 0.00820\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0394 - val_loss: 0.0147\n",
      "Epoch 6/20\n",
      "599/614 [============================>.] - ETA: 0s - loss: 0.0378\n",
      "Epoch 6: val_loss improved from 0.00820 to 0.00650, saving model to models-new/ann-pot_ativa_inj_barramento24.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0380 - val_loss: 0.0065\n",
      "Epoch 7/20\n",
      "604/614 [============================>.] - ETA: 0s - loss: 0.0378\n",
      "Epoch 7: val_loss did not improve from 0.00650\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0378 - val_loss: 0.0068\n",
      "Epoch 8/20\n",
      "595/614 [============================>.] - ETA: 0s - loss: 0.0358\n",
      "Epoch 8: val_loss improved from 0.00650 to 0.00571, saving model to models-new/ann-pot_ativa_inj_barramento24.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0357 - val_loss: 0.0057\n",
      "Epoch 9/20\n",
      "611/614 [============================>.] - ETA: 0s - loss: 0.0366\n",
      "Epoch 9: val_loss did not improve from 0.00571\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0365 - val_loss: 0.0146\n",
      "Epoch 10/20\n",
      "602/614 [============================>.] - ETA: 0s - loss: 0.0394\n",
      "Epoch 10: val_loss did not improve from 0.00571\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0395 - val_loss: 0.0127\n",
      "Epoch 11/20\n",
      "591/614 [===========================>..] - ETA: 0s - loss: 0.0364\n",
      "Epoch 11: val_loss did not improve from 0.00571\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0363 - val_loss: 0.0064\n",
      "Epoch 12/20\n",
      "587/614 [===========================>..] - ETA: 0s - loss: 0.0373\n",
      "Epoch 12: val_loss did not improve from 0.00571\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0370 - val_loss: 0.0156\n",
      "Epoch 13/20\n",
      "607/614 [============================>.] - ETA: 0s - loss: 0.0381\n",
      "Epoch 13: val_loss did not improve from 0.00571\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0380 - val_loss: 0.0099\n",
      "Epoch 14/20\n",
      "606/614 [============================>.] - ETA: 0s - loss: 0.0400\n",
      "Epoch 14: val_loss did not improve from 0.00571\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0399 - val_loss: 0.0060\n",
      "Epoch 15/20\n",
      "603/614 [============================>.] - ETA: 0s - loss: 0.0358\n",
      "Epoch 15: val_loss improved from 0.00571 to 0.00364, saving model to models-new/ann-pot_ativa_inj_barramento24.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0356 - val_loss: 0.0036\n",
      "Epoch 16/20\n",
      "608/614 [============================>.] - ETA: 0s - loss: 0.0353\n",
      "Epoch 16: val_loss did not improve from 0.00364\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0353 - val_loss: 0.0056\n",
      "Epoch 17/20\n",
      "612/614 [============================>.] - ETA: 0s - loss: 0.0362\n",
      "Epoch 17: val_loss did not improve from 0.00364\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0361 - val_loss: 0.0044\n",
      "Epoch 18/20\n",
      "594/614 [============================>.] - ETA: 0s - loss: 0.0351\n",
      "Epoch 18: val_loss did not improve from 0.00364\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0350 - val_loss: 0.0053\n",
      "Epoch 19/20\n",
      "600/614 [============================>.] - ETA: 0s - loss: 0.0344\n",
      "Epoch 19: val_loss did not improve from 0.00364\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0342 - val_loss: 0.0124\n",
      "Epoch 20/20\n",
      "599/614 [============================>.] - ETA: 0s - loss: 0.0345\n",
      "Epoch 20: val_loss did not improve from 0.00364\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0349 - val_loss: 0.0130\n",
      "83/83 [==============================] - 0s 1ms/step\n",
      "RMSE: 0.8986328469304873\n"
     ]
    }
   ],
   "source": [
    "cols_pred = ['pot_ativa_inj_barramento24']\n",
    "model_id = 'pot_ativa_inj_barramento24'\n",
    "pot_ativa_inj_barramento24_df = run(df, cols, cols_pred, model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8e59f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ========== MODEL pot_reativa_inj_barramento11 ============\n",
      "Epoch 1/20\n",
      "610/614 [============================>.] - ETA: 0s - loss: 0.2023\n",
      "Epoch 1: val_loss improved from inf to 0.19655, saving model to models-new/ann-pot_reativa_inj_barramento11.h5\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.2023 - val_loss: 0.1966\n",
      "Epoch 2/20\n",
      "606/614 [============================>.] - ETA: 0s - loss: 0.1286\n",
      "Epoch 2: val_loss improved from 0.19655 to 0.09788, saving model to models-new/ann-pot_reativa_inj_barramento11.h5\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.1293 - val_loss: 0.0979\n",
      "Epoch 3/20\n",
      "606/614 [============================>.] - ETA: 0s - loss: 0.1089\n",
      "Epoch 3: val_loss did not improve from 0.09788\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.1087 - val_loss: 0.1276\n",
      "Epoch 4/20\n",
      "606/614 [============================>.] - ETA: 0s - loss: 0.1030\n",
      "Epoch 4: val_loss did not improve from 0.09788\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.1032 - val_loss: 0.1328\n",
      "Epoch 5/20\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0933\n",
      "Epoch 5: val_loss improved from 0.09788 to 0.09601, saving model to models-new/ann-pot_reativa_inj_barramento11.h5\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0933 - val_loss: 0.0960\n",
      "Epoch 6/20\n",
      "608/614 [============================>.] - ETA: 0s - loss: 0.0870\n",
      "Epoch 6: val_loss did not improve from 0.09601\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0870 - val_loss: 0.1024\n",
      "Epoch 7/20\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.0865\n",
      "Epoch 7: val_loss did not improve from 0.09601\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0865 - val_loss: 0.1375\n",
      "Epoch 8/20\n",
      "598/614 [============================>.] - ETA: 0s - loss: 0.0765\n",
      "Epoch 8: val_loss did not improve from 0.09601\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0769 - val_loss: 0.1084\n",
      "Epoch 9/20\n",
      "608/614 [============================>.] - ETA: 0s - loss: 0.0836\n",
      "Epoch 9: val_loss did not improve from 0.09601\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0835 - val_loss: 0.1018\n",
      "Epoch 10/20\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.0812\n",
      "Epoch 10: val_loss did not improve from 0.09601\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0812 - val_loss: 0.1100\n",
      "Epoch 11/20\n",
      "612/614 [============================>.] - ETA: 0s - loss: 0.0790\n",
      "Epoch 11: val_loss did not improve from 0.09601\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0789 - val_loss: 0.1159\n",
      "Epoch 12/20\n",
      "608/614 [============================>.] - ETA: 0s - loss: 0.0761\n",
      "Epoch 12: val_loss did not improve from 0.09601\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0758 - val_loss: 0.1044\n",
      "Epoch 13/20\n",
      "611/614 [============================>.] - ETA: 0s - loss: 0.0735\n",
      "Epoch 13: val_loss did not improve from 0.09601\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0735 - val_loss: 0.1043\n",
      "Epoch 14/20\n",
      "609/614 [============================>.] - ETA: 0s - loss: 0.0713\n",
      "Epoch 14: val_loss did not improve from 0.09601\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0714 - val_loss: 0.1087\n",
      "Epoch 15/20\n",
      "605/614 [============================>.] - ETA: 0s - loss: 0.0736\n",
      "Epoch 15: val_loss did not improve from 0.09601\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0735 - val_loss: 0.1194\n",
      "Epoch 15: early stopping\n",
      "83/83 [==============================] - 0s 1ms/step\n",
      "RMSE: 0.5589597127153223\n"
     ]
    }
   ],
   "source": [
    "cols_pred = ['pot_reativa_inj_barramento11']\n",
    "model_id = 'pot_reativa_inj_barramento11'\n",
    "pot_reativa_inj_barramento11_df = run(df, cols, cols_pred, model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "898e0857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ========== MODEL pot_reativa_inj_barramento11 ============\n",
      "Epoch 1/20\n",
      "600/614 [============================>.] - ETA: 0s - loss: 0.2048\n",
      "Epoch 1: val_loss improved from inf to 0.13581, saving model to models-new/ann-pot_reativa_inj_barramento11.h5\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.2047 - val_loss: 0.1358\n",
      "Epoch 2/20\n",
      "598/614 [============================>.] - ETA: 0s - loss: 0.1121\n",
      "Epoch 2: val_loss improved from 0.13581 to 0.12272, saving model to models-new/ann-pot_reativa_inj_barramento11.h5\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.1119 - val_loss: 0.1227\n",
      "Epoch 3/20\n",
      "610/614 [============================>.] - ETA: 0s - loss: 0.0978\n",
      "Epoch 3: val_loss did not improve from 0.12272\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0975 - val_loss: 0.1228\n",
      "Epoch 4/20\n",
      "598/614 [============================>.] - ETA: 0s - loss: 0.0958\n",
      "Epoch 4: val_loss did not improve from 0.12272\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0957 - val_loss: 0.1239\n",
      "Epoch 5/20\n",
      "601/614 [============================>.] - ETA: 0s - loss: 0.0822\n",
      "Epoch 5: val_loss improved from 0.12272 to 0.11811, saving model to models-new/ann-pot_reativa_inj_barramento11.h5\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0822 - val_loss: 0.1181\n",
      "Epoch 6/20\n",
      "612/614 [============================>.] - ETA: 0s - loss: 0.0872\n",
      "Epoch 6: val_loss improved from 0.11811 to 0.08887, saving model to models-new/ann-pot_reativa_inj_barramento11.h5\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0873 - val_loss: 0.0889\n",
      "Epoch 7/20\n",
      "595/614 [============================>.] - ETA: 0s - loss: 0.0779\n",
      "Epoch 7: val_loss did not improve from 0.08887\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0780 - val_loss: 0.1501\n",
      "Epoch 8/20\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0763\n",
      "Epoch 8: val_loss did not improve from 0.08887\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0763 - val_loss: 0.1366\n",
      "Epoch 9/20\n",
      "603/614 [============================>.] - ETA: 0s - loss: 0.0732\n",
      "Epoch 9: val_loss did not improve from 0.08887\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0735 - val_loss: 0.1235\n",
      "Epoch 10/20\n",
      "611/614 [============================>.] - ETA: 0s - loss: 0.0713\n",
      "Epoch 10: val_loss did not improve from 0.08887\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0717 - val_loss: 0.1217\n",
      "Epoch 11/20\n",
      "612/614 [============================>.] - ETA: 0s - loss: 0.0681\n",
      "Epoch 11: val_loss did not improve from 0.08887\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0680 - val_loss: 0.1082\n",
      "Epoch 12/20\n",
      "611/614 [============================>.] - ETA: 0s - loss: 0.0673\n",
      "Epoch 12: val_loss did not improve from 0.08887\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0674 - val_loss: 0.1029\n",
      "Epoch 13/20\n",
      "601/614 [============================>.] - ETA: 0s - loss: 0.0680\n",
      "Epoch 13: val_loss did not improve from 0.08887\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0675 - val_loss: 0.1231\n",
      "Epoch 14/20\n",
      "603/614 [============================>.] - ETA: 0s - loss: 0.0658\n",
      "Epoch 14: val_loss did not improve from 0.08887\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0660 - val_loss: 0.1196\n",
      "Epoch 15/20\n",
      "598/614 [============================>.] - ETA: 0s - loss: 0.0654\n",
      "Epoch 15: val_loss did not improve from 0.08887\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0654 - val_loss: 0.1300\n",
      "Epoch 16/20\n",
      "600/614 [============================>.] - ETA: 0s - loss: 0.0662\n",
      "Epoch 16: val_loss did not improve from 0.08887\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0663 - val_loss: 0.1106\n",
      "Epoch 16: early stopping\n",
      "83/83 [==============================] - 0s 1ms/step\n",
      "RMSE: 0.5380176025356653\n"
     ]
    }
   ],
   "source": [
    "cols_pred = ['pot_reativa_inj_barramento11']\n",
    "model_id = 'pot_reativa_inj_barramento11'\n",
    "pot_reativa_inj_barramento11_mae_df = run(df, cols, cols_pred, model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ef1b705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ========== MODEL pot_reativa_inj_barramento12 ============\n",
      "Epoch 1/20\n",
      "612/614 [============================>.] - ETA: 0s - loss: 0.1855\n",
      "Epoch 1: val_loss improved from inf to 0.10488, saving model to models-new/ann-pot_reativa_inj_barramento12.h5\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.1853 - val_loss: 0.1049\n",
      "Epoch 2/20\n",
      "602/614 [============================>.] - ETA: 0s - loss: 0.1194\n",
      "Epoch 2: val_loss did not improve from 0.10488\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.1197 - val_loss: 0.1082\n",
      "Epoch 3/20\n",
      "605/614 [============================>.] - ETA: 0s - loss: 0.1025\n",
      "Epoch 3: val_loss did not improve from 0.10488\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.1030 - val_loss: 0.1082\n",
      "Epoch 4/20\n",
      "604/614 [============================>.] - ETA: 0s - loss: 0.0893\n",
      "Epoch 4: val_loss improved from 0.10488 to 0.08110, saving model to models-new/ann-pot_reativa_inj_barramento12.h5\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0893 - val_loss: 0.0811\n",
      "Epoch 5/20\n",
      "607/614 [============================>.] - ETA: 0s - loss: 0.0853\n",
      "Epoch 5: val_loss improved from 0.08110 to 0.06849, saving model to models-new/ann-pot_reativa_inj_barramento12.h5\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0851 - val_loss: 0.0685\n",
      "Epoch 6/20\n",
      "605/614 [============================>.] - ETA: 0s - loss: 0.0780\n",
      "Epoch 6: val_loss improved from 0.06849 to 0.06791, saving model to models-new/ann-pot_reativa_inj_barramento12.h5\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0777 - val_loss: 0.0679\n",
      "Epoch 7/20\n",
      "604/614 [============================>.] - ETA: 0s - loss: 0.0713\n",
      "Epoch 7: val_loss did not improve from 0.06791\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0714 - val_loss: 0.0726\n",
      "Epoch 8/20\n",
      "603/614 [============================>.] - ETA: 0s - loss: 0.0717\n",
      "Epoch 8: val_loss improved from 0.06791 to 0.06708, saving model to models-new/ann-pot_reativa_inj_barramento12.h5\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0718 - val_loss: 0.0671\n",
      "Epoch 9/20\n",
      "596/614 [============================>.] - ETA: 0s - loss: 0.0702\n",
      "Epoch 9: val_loss did not improve from 0.06708\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0699 - val_loss: 0.0730\n",
      "Epoch 10/20\n",
      "601/614 [============================>.] - ETA: 0s - loss: 0.0698\n",
      "Epoch 10: val_loss did not improve from 0.06708\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0696 - val_loss: 0.0718\n",
      "Epoch 11/20\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.0637\n",
      "Epoch 11: val_loss improved from 0.06708 to 0.06269, saving model to models-new/ann-pot_reativa_inj_barramento12.h5\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0637 - val_loss: 0.0627\n",
      "Epoch 12/20\n",
      "605/614 [============================>.] - ETA: 0s - loss: 0.0616\n",
      "Epoch 12: val_loss did not improve from 0.06269\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0616 - val_loss: 0.0736\n",
      "Epoch 13/20\n",
      "601/614 [============================>.] - ETA: 0s - loss: 0.0588\n",
      "Epoch 13: val_loss did not improve from 0.06269\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0592 - val_loss: 0.0648\n",
      "Epoch 14/20\n",
      "612/614 [============================>.] - ETA: 0s - loss: 0.0574\n",
      "Epoch 14: val_loss did not improve from 0.06269\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0573 - val_loss: 0.0786\n",
      "Epoch 15/20\n",
      "602/614 [============================>.] - ETA: 0s - loss: 0.0574\n",
      "Epoch 15: val_loss did not improve from 0.06269\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0574 - val_loss: 0.0893\n",
      "Epoch 16/20\n",
      "596/614 [============================>.] - ETA: 0s - loss: 0.0590\n",
      "Epoch 16: val_loss did not improve from 0.06269\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0588 - val_loss: 0.0963\n",
      "Epoch 17/20\n",
      "596/614 [============================>.] - ETA: 0s - loss: 0.0613\n",
      "Epoch 17: val_loss did not improve from 0.06269\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0615 - val_loss: 0.0720\n",
      "Epoch 18/20\n",
      "595/614 [============================>.] - ETA: 0s - loss: 0.0553\n",
      "Epoch 18: val_loss did not improve from 0.06269\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0551 - val_loss: 0.0891\n",
      "Epoch 19/20\n",
      "607/614 [============================>.] - ETA: 0s - loss: 0.0561\n",
      "Epoch 19: val_loss did not improve from 0.06269\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0562 - val_loss: 0.0871\n",
      "Epoch 20/20\n",
      "607/614 [============================>.] - ETA: 0s - loss: 0.0558\n",
      "Epoch 20: val_loss did not improve from 0.06269\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0559 - val_loss: 0.0728\n",
      "83/83 [==============================] - 0s 1ms/step\n",
      "RMSE: 0.6336776473871777\n"
     ]
    }
   ],
   "source": [
    "cols_pred = ['pot_reativa_inj_barramento12']\n",
    "model_id = 'pot_reativa_inj_barramento12'\n",
    "pot_reativa_inj_barramento12_mae_df = run(df, cols, cols_pred, model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e8e4ff93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ========== MODEL pot_reativa_inj_barramento24 ============\n",
      "Epoch 1/20\n",
      "601/614 [============================>.] - ETA: 0s - loss: 0.2615\n",
      "Epoch 1: val_loss improved from inf to 0.12107, saving model to models-new/ann-pot_reativa_inj_barramento24.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.2598 - val_loss: 0.1211\n",
      "Epoch 2/20\n",
      "571/614 [==========================>...] - ETA: 0s - loss: 0.1734\n",
      "Epoch 2: val_loss did not improve from 0.12107\n",
      "614/614 [==============================] - 1s 1ms/step - loss: 0.1723 - val_loss: 0.1283\n",
      "Epoch 3/20\n",
      "592/614 [===========================>..] - ETA: 0s - loss: 0.1554\n",
      "Epoch 3: val_loss improved from 0.12107 to 0.11244, saving model to models-new/ann-pot_reativa_inj_barramento24.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1555 - val_loss: 0.1124\n",
      "Epoch 4/20\n",
      "584/614 [===========================>..] - ETA: 0s - loss: 0.1465\n",
      "Epoch 4: val_loss improved from 0.11244 to 0.08104, saving model to models-new/ann-pot_reativa_inj_barramento24.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1478 - val_loss: 0.0810\n",
      "Epoch 5/20\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.1375\n",
      "Epoch 5: val_loss improved from 0.08104 to 0.07966, saving model to models-new/ann-pot_reativa_inj_barramento24.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1374 - val_loss: 0.0797\n",
      "Epoch 6/20\n",
      "612/614 [============================>.] - ETA: 0s - loss: 0.1348\n",
      "Epoch 6: val_loss did not improve from 0.07966\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1349 - val_loss: 0.0855\n",
      "Epoch 7/20\n",
      "598/614 [============================>.] - ETA: 0s - loss: 0.1262\n",
      "Epoch 7: val_loss improved from 0.07966 to 0.07354, saving model to models-new/ann-pot_reativa_inj_barramento24.h5\n",
      "614/614 [==============================] - 1s 1ms/step - loss: 0.1262 - val_loss: 0.0735\n",
      "Epoch 8/20\n",
      "591/614 [===========================>..] - ETA: 0s - loss: 0.1296\n",
      "Epoch 8: val_loss improved from 0.07354 to 0.07069, saving model to models-new/ann-pot_reativa_inj_barramento24.h5\n",
      "614/614 [==============================] - 1s 1ms/step - loss: 0.1293 - val_loss: 0.0707\n",
      "Epoch 9/20\n",
      "588/614 [===========================>..] - ETA: 0s - loss: 0.1273\n",
      "Epoch 9: val_loss did not improve from 0.07069\n",
      "614/614 [==============================] - 1s 1ms/step - loss: 0.1266 - val_loss: 0.0888\n",
      "Epoch 10/20\n",
      "587/614 [===========================>..] - ETA: 0s - loss: 0.1172\n",
      "Epoch 10: val_loss improved from 0.07069 to 0.06631, saving model to models-new/ann-pot_reativa_inj_barramento24.h5\n",
      "614/614 [==============================] - 1s 1ms/step - loss: 0.1172 - val_loss: 0.0663\n",
      "Epoch 11/20\n",
      "608/614 [============================>.] - ETA: 0s - loss: 0.1185\n",
      "Epoch 11: val_loss did not improve from 0.06631\n",
      "614/614 [==============================] - 1s 1ms/step - loss: 0.1189 - val_loss: 0.0680\n",
      "Epoch 12/20\n",
      "577/614 [===========================>..] - ETA: 0s - loss: 0.1206\n",
      "Epoch 12: val_loss improved from 0.06631 to 0.06270, saving model to models-new/ann-pot_reativa_inj_barramento24.h5\n",
      "614/614 [==============================] - 1s 1ms/step - loss: 0.1201 - val_loss: 0.0627\n",
      "Epoch 13/20\n",
      "579/614 [===========================>..] - ETA: 0s - loss: 0.1117\n",
      "Epoch 13: val_loss improved from 0.06270 to 0.06247, saving model to models-new/ann-pot_reativa_inj_barramento24.h5\n",
      "614/614 [==============================] - 1s 1ms/step - loss: 0.1125 - val_loss: 0.0625\n",
      "Epoch 14/20\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.1079\n",
      "Epoch 14: val_loss improved from 0.06247 to 0.06086, saving model to models-new/ann-pot_reativa_inj_barramento24.h5\n",
      "614/614 [==============================] - 1s 1ms/step - loss: 0.1079 - val_loss: 0.0609\n",
      "Epoch 15/20\n",
      "575/614 [===========================>..] - ETA: 0s - loss: 0.1063\n",
      "Epoch 15: val_loss improved from 0.06086 to 0.05618, saving model to models-new/ann-pot_reativa_inj_barramento24.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1068 - val_loss: 0.0562\n",
      "Epoch 16/20\n",
      "602/614 [============================>.] - ETA: 0s - loss: 0.1074\n",
      "Epoch 16: val_loss did not improve from 0.05618\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1068 - val_loss: 0.0608\n",
      "Epoch 17/20\n",
      "609/614 [============================>.] - ETA: 0s - loss: 0.1016\n",
      "Epoch 17: val_loss improved from 0.05618 to 0.05037, saving model to models-new/ann-pot_reativa_inj_barramento24.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1013 - val_loss: 0.0504\n",
      "Epoch 18/20\n",
      "577/614 [===========================>..] - ETA: 0s - loss: 0.1010\n",
      "Epoch 18: val_loss did not improve from 0.05037\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1012 - val_loss: 0.0626\n",
      "Epoch 19/20\n",
      "582/614 [===========================>..] - ETA: 0s - loss: 0.0920\n",
      "Epoch 19: val_loss did not improve from 0.05037\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0950 - val_loss: 0.0712\n",
      "Epoch 20/20\n",
      "598/614 [============================>.] - ETA: 0s - loss: 0.1013\n",
      "Epoch 20: val_loss did not improve from 0.05037\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1008 - val_loss: 0.0552\n",
      "83/83 [==============================] - 0s 1ms/step\n",
      "RMSE: 0.5389674758584244\n"
     ]
    }
   ],
   "source": [
    "cols_pred = ['pot_reativa_inj_barramento24']\n",
    "model_id = 'pot_reativa_inj_barramento24'\n",
    "pot_reativa_inj_barramento24_mae_df = run(df, cols, cols_pred, model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5224c88b",
   "metadata": {},
   "source": [
    "# Without residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f442b8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ========== MODEL pot_ativa_inj_barramento11_no_residual ============\n",
      "Epoch 1/20\n",
      "604/614 [============================>.] - ETA: 0s - loss: 0.0891\n",
      "Epoch 1: val_loss improved from inf to 0.00814, saving model to models-new/ann-pot_ativa_inj_barramento11_no_residual.h5\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0885 - val_loss: 0.0081\n",
      "Epoch 2/20\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.0498\n",
      "Epoch 2: val_loss did not improve from 0.00814\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0498 - val_loss: 0.0130\n",
      "Epoch 3/20\n",
      "600/614 [============================>.] - ETA: 0s - loss: 0.0481\n",
      "Epoch 3: val_loss did not improve from 0.00814\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0480 - val_loss: 0.0099\n",
      "Epoch 4/20\n",
      "610/614 [============================>.] - ETA: 0s - loss: 0.0453\n",
      "Epoch 4: val_loss improved from 0.00814 to 0.00547, saving model to models-new/ann-pot_ativa_inj_barramento11_no_residual.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0453 - val_loss: 0.0055\n",
      "Epoch 5/20\n",
      "592/614 [===========================>..] - ETA: 0s - loss: 0.0433\n",
      "Epoch 5: val_loss did not improve from 0.00547\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0431 - val_loss: 0.0061\n",
      "Epoch 6/20\n",
      "608/614 [============================>.] - ETA: 0s - loss: 0.0406\n",
      "Epoch 6: val_loss did not improve from 0.00547\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0405 - val_loss: 0.0130\n",
      "Epoch 7/20\n",
      "576/614 [===========================>..] - ETA: 0s - loss: 0.0403\n",
      "Epoch 7: val_loss improved from 0.00547 to 0.00510, saving model to models-new/ann-pot_ativa_inj_barramento11_no_residual.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0400 - val_loss: 0.0051\n",
      "Epoch 8/20\n",
      "584/614 [===========================>..] - ETA: 0s - loss: 0.0374\n",
      "Epoch 8: val_loss did not improve from 0.00510\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0373 - val_loss: 0.0072\n",
      "Epoch 9/20\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.0375\n",
      "Epoch 9: val_loss improved from 0.00510 to 0.00427, saving model to models-new/ann-pot_ativa_inj_barramento11_no_residual.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0375 - val_loss: 0.0043\n",
      "Epoch 10/20\n",
      "588/614 [===========================>..] - ETA: 0s - loss: 0.0379\n",
      "Epoch 10: val_loss improved from 0.00427 to 0.00337, saving model to models-new/ann-pot_ativa_inj_barramento11_no_residual.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0379 - val_loss: 0.0034\n",
      "Epoch 11/20\n",
      "601/614 [============================>.] - ETA: 0s - loss: 0.0367\n",
      "Epoch 11: val_loss did not improve from 0.00337\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0367 - val_loss: 0.0052\n",
      "Epoch 12/20\n",
      "590/614 [===========================>..] - ETA: 0s - loss: 0.0422\n",
      "Epoch 12: val_loss did not improve from 0.00337\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0420 - val_loss: 0.0076\n",
      "Epoch 13/20\n",
      "610/614 [============================>.] - ETA: 0s - loss: 0.0381\n",
      "Epoch 13: val_loss did not improve from 0.00337\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0380 - val_loss: 0.0112\n",
      "Epoch 14/20\n",
      "595/614 [============================>.] - ETA: 0s - loss: 0.0364\n",
      "Epoch 14: val_loss did not improve from 0.00337\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0365 - val_loss: 0.0044\n",
      "Epoch 15/20\n",
      "581/614 [===========================>..] - ETA: 0s - loss: 0.0386\n",
      "Epoch 15: val_loss did not improve from 0.00337\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0389 - val_loss: 0.0046\n",
      "Epoch 16/20\n",
      "595/614 [============================>.] - ETA: 0s - loss: 0.0387\n",
      "Epoch 16: val_loss did not improve from 0.00337\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0383 - val_loss: 0.0061\n",
      "Epoch 17/20\n",
      "583/614 [===========================>..] - ETA: 0s - loss: 0.0371\n",
      "Epoch 17: val_loss did not improve from 0.00337\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0371 - val_loss: 0.0058\n",
      "Epoch 18/20\n",
      "585/614 [===========================>..] - ETA: 0s - loss: 0.0357\n",
      "Epoch 18: val_loss did not improve from 0.00337\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0357 - val_loss: 0.0053\n",
      "Epoch 19/20\n",
      "611/614 [============================>.] - ETA: 0s - loss: 0.0363\n",
      "Epoch 19: val_loss did not improve from 0.00337\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0363 - val_loss: 0.0040\n",
      "Epoch 20/20\n",
      "592/614 [===========================>..] - ETA: 0s - loss: 0.0378\n",
      "Epoch 20: val_loss did not improve from 0.00337\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0375 - val_loss: 0.0067\n",
      "Epoch 20: early stopping\n",
      "83/83 [==============================] - 0s 954us/step\n",
      "RMSE: 0.5622663371840348\n"
     ]
    }
   ],
   "source": [
    "cols_pred = ['pot_ativa_inj_barramento11']\n",
    "model_id = 'pot_ativa_inj_barramento11_no_residual'\n",
    "pot_reativa_inj_barramento11_mse_df = run(df, cols, cols_pred, model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf43534c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ========== MODEL pot_ativa_inj_barramento12_no_residual ============\n",
      "Epoch 1/20\n",
      "606/614 [============================>.] - ETA: 0s - loss: 0.0850\n",
      "Epoch 1: val_loss improved from inf to 0.01769, saving model to models-new/ann-pot_ativa_inj_barramento12_no_residual.h5\n",
      "614/614 [==============================] - 2s 2ms/step - loss: 0.0848 - val_loss: 0.0177\n",
      "Epoch 2/20\n",
      "604/614 [============================>.] - ETA: 0s - loss: 0.0508\n",
      "Epoch 2: val_loss improved from 0.01769 to 0.00485, saving model to models-new/ann-pot_ativa_inj_barramento12_no_residual.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0509 - val_loss: 0.0048\n",
      "Epoch 3/20\n",
      "584/614 [===========================>..] - ETA: 0s - loss: 0.0448\n",
      "Epoch 3: val_loss did not improve from 0.00485\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0447 - val_loss: 0.0108\n",
      "Epoch 4/20\n",
      "590/614 [===========================>..] - ETA: 0s - loss: 0.0421\n",
      "Epoch 4: val_loss did not improve from 0.00485\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0420 - val_loss: 0.0074\n",
      "Epoch 5/20\n",
      "592/614 [===========================>..] - ETA: 0s - loss: 0.0413\n",
      "Epoch 5: val_loss improved from 0.00485 to 0.00266, saving model to models-new/ann-pot_ativa_inj_barramento12_no_residual.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0415 - val_loss: 0.0027\n",
      "Epoch 6/20\n",
      "588/614 [===========================>..] - ETA: 0s - loss: 0.0382\n",
      "Epoch 6: val_loss did not improve from 0.00266\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0378 - val_loss: 0.0116\n",
      "Epoch 7/20\n",
      "601/614 [============================>.] - ETA: 0s - loss: 0.0366\n",
      "Epoch 7: val_loss did not improve from 0.00266\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0365 - val_loss: 0.0050\n",
      "Epoch 8/20\n",
      "586/614 [===========================>..] - ETA: 0s - loss: 0.0355\n",
      "Epoch 8: val_loss did not improve from 0.00266\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0358 - val_loss: 0.0094\n",
      "Epoch 9/20\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0375\n",
      "Epoch 9: val_loss did not improve from 0.00266\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0374 - val_loss: 0.0046\n",
      "Epoch 10/20\n",
      "584/614 [===========================>..] - ETA: 0s - loss: 0.0390\n",
      "Epoch 10: val_loss did not improve from 0.00266\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0389 - val_loss: 0.0031\n",
      "Epoch 11/20\n",
      "587/614 [===========================>..] - ETA: 0s - loss: 0.0356\n",
      "Epoch 11: val_loss did not improve from 0.00266\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0358 - val_loss: 0.0067\n",
      "Epoch 12/20\n",
      "586/614 [===========================>..] - ETA: 0s - loss: 0.0354\n",
      "Epoch 12: val_loss did not improve from 0.00266\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0357 - val_loss: 0.0118\n",
      "Epoch 13/20\n",
      "591/614 [===========================>..] - ETA: 0s - loss: 0.0370\n",
      "Epoch 13: val_loss improved from 0.00266 to 0.00244, saving model to models-new/ann-pot_ativa_inj_barramento12_no_residual.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0369 - val_loss: 0.0024\n",
      "Epoch 14/20\n",
      "587/614 [===========================>..] - ETA: 0s - loss: 0.0363\n",
      "Epoch 14: val_loss did not improve from 0.00244\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0360 - val_loss: 0.0026\n",
      "Epoch 15/20\n",
      "585/614 [===========================>..] - ETA: 0s - loss: 0.0378\n",
      "Epoch 15: val_loss did not improve from 0.00244\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0375 - val_loss: 0.0040\n",
      "Epoch 16/20\n",
      "599/614 [============================>.] - ETA: 0s - loss: 0.0349\n",
      "Epoch 16: val_loss did not improve from 0.00244\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0346 - val_loss: 0.0031\n",
      "Epoch 17/20\n",
      "594/614 [============================>.] - ETA: 0s - loss: 0.0353\n",
      "Epoch 17: val_loss did not improve from 0.00244\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0354 - val_loss: 0.0038\n",
      "Epoch 18/20\n",
      "585/614 [===========================>..] - ETA: 0s - loss: 0.0362\n",
      "Epoch 18: val_loss did not improve from 0.00244\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0361 - val_loss: 0.0091\n",
      "Epoch 19/20\n",
      "584/614 [===========================>..] - ETA: 0s - loss: 0.0337\n",
      "Epoch 19: val_loss did not improve from 0.00244\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0340 - val_loss: 0.0031\n",
      "Epoch 20/20\n",
      "576/614 [===========================>..] - ETA: 0s - loss: 0.0359\n",
      "Epoch 20: val_loss did not improve from 0.00244\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0359 - val_loss: 0.0058\n",
      "83/83 [==============================] - 0s 1ms/step\n",
      "RMSE: 0.7562754367674954\n"
     ]
    }
   ],
   "source": [
    "cols_pred = ['pot_ativa_inj_barramento12']\n",
    "model_id = 'pot_ativa_inj_barramento12_no_residual'\n",
    "pot_reativa_inj_barramento11_mse_df = run(df, cols, cols_pred, model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d25cb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ========== MODEL pot_ativa_inj_barramento24_no_residual ============\n",
      "Epoch 1/20\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.1073\n",
      "Epoch 1: val_loss improved from inf to 0.01462, saving model to models-new/ann-pot_ativa_inj_barramento24_no_residual.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1073 - val_loss: 0.0146\n",
      "Epoch 2/20\n",
      "608/614 [============================>.] - ETA: 0s - loss: 0.0580\n",
      "Epoch 2: val_loss did not improve from 0.01462\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0581 - val_loss: 0.0201\n",
      "Epoch 3/20\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0523\n",
      "Epoch 3: val_loss improved from 0.01462 to 0.01147, saving model to models-new/ann-pot_ativa_inj_barramento24_no_residual.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0523 - val_loss: 0.0115\n",
      "Epoch 4/20\n",
      "603/614 [============================>.] - ETA: 0s - loss: 0.0476\n",
      "Epoch 4: val_loss improved from 0.01147 to 0.00560, saving model to models-new/ann-pot_ativa_inj_barramento24_no_residual.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0475 - val_loss: 0.0056\n",
      "Epoch 5/20\n",
      "576/614 [===========================>..] - ETA: 0s - loss: 0.0425\n",
      "Epoch 5: val_loss did not improve from 0.00560\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0430 - val_loss: 0.0077\n",
      "Epoch 6/20\n",
      "583/614 [===========================>..] - ETA: 0s - loss: 0.0384\n",
      "Epoch 6: val_loss did not improve from 0.00560\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0385 - val_loss: 0.0087\n",
      "Epoch 7/20\n",
      "590/614 [===========================>..] - ETA: 0s - loss: 0.0424\n",
      "Epoch 7: val_loss did not improve from 0.00560\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0423 - val_loss: 0.0102\n",
      "Epoch 8/20\n",
      "575/614 [===========================>..] - ETA: 0s - loss: 0.0394\n",
      "Epoch 8: val_loss improved from 0.00560 to 0.00518, saving model to models-new/ann-pot_ativa_inj_barramento24_no_residual.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0392 - val_loss: 0.0052\n",
      "Epoch 9/20\n",
      "611/614 [============================>.] - ETA: 0s - loss: 0.0412\n",
      "Epoch 9: val_loss did not improve from 0.00518\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0412 - val_loss: 0.0060\n",
      "Epoch 10/20\n",
      "605/614 [============================>.] - ETA: 0s - loss: 0.0384\n",
      "Epoch 10: val_loss did not improve from 0.00518\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0382 - val_loss: 0.0112\n",
      "Epoch 11/20\n",
      "590/614 [===========================>..] - ETA: 0s - loss: 0.0381\n",
      "Epoch 11: val_loss did not improve from 0.00518\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0383 - val_loss: 0.0058\n",
      "Epoch 12/20\n",
      "598/614 [============================>.] - ETA: 0s - loss: 0.0389\n",
      "Epoch 12: val_loss did not improve from 0.00518\n",
      "614/614 [==============================] - 2s 3ms/step - loss: 0.0388 - val_loss: 0.0060\n",
      "Epoch 13/20\n",
      "594/614 [============================>.] - ETA: 0s - loss: 0.0401\n",
      "Epoch 13: val_loss did not improve from 0.00518\n",
      "614/614 [==============================] - 2s 2ms/step - loss: 0.0401 - val_loss: 0.0062\n",
      "Epoch 14/20\n",
      "604/614 [============================>.] - ETA: 0s - loss: 0.0372\n",
      "Epoch 14: val_loss did not improve from 0.00518\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0371 - val_loss: 0.0068\n",
      "Epoch 15/20\n",
      "606/614 [============================>.] - ETA: 0s - loss: 0.0367\n",
      "Epoch 15: val_loss improved from 0.00518 to 0.00356, saving model to models-new/ann-pot_ativa_inj_barramento24_no_residual.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0367 - val_loss: 0.0036\n",
      "Epoch 16/20\n",
      "598/614 [============================>.] - ETA: 0s - loss: 0.0362\n",
      "Epoch 16: val_loss did not improve from 0.00356\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0359 - val_loss: 0.0087\n",
      "Epoch 17/20\n",
      "596/614 [============================>.] - ETA: 0s - loss: 0.0372\n",
      "Epoch 17: val_loss did not improve from 0.00356\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0373 - val_loss: 0.0060\n",
      "Epoch 18/20\n",
      "605/614 [============================>.] - ETA: 0s - loss: 0.0366\n",
      "Epoch 18: val_loss did not improve from 0.00356\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0365 - val_loss: 0.0058\n",
      "Epoch 19/20\n",
      "606/614 [============================>.] - ETA: 0s - loss: 0.0351\n",
      "Epoch 19: val_loss did not improve from 0.00356\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0350 - val_loss: 0.0049\n",
      "Epoch 20/20\n",
      "594/614 [============================>.] - ETA: 0s - loss: 0.0371\n",
      "Epoch 20: val_loss did not improve from 0.00356\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0369 - val_loss: 0.0078\n",
      "83/83 [==============================] - 0s 1ms/step\n",
      "RMSE: 1.007234773786532\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carga_subrede_138kv</th>\n",
       "      <th>pot_eolica_subrede_138kv</th>\n",
       "      <th>pot_solar_subrede_138kv</th>\n",
       "      <th>carga_subrede_230kv</th>\n",
       "      <th>pot_eolica_subrede_230kv</th>\n",
       "      <th>pot_solar_subrede_230kv</th>\n",
       "      <th>carga_subrede_138kv_pot_eolica_subrede_138kv</th>\n",
       "      <th>carga_subrede_138kv_pot_solar_subrede_138kv</th>\n",
       "      <th>carga_subrede_138kv_carga_subrede_230kv</th>\n",
       "      <th>carga_subrede_138kv_pot_eolica_subrede_230kv</th>\n",
       "      <th>...</th>\n",
       "      <th>pot_eolica_subrede_138kv_carga_subrede_230kv</th>\n",
       "      <th>pot_eolica_subrede_138kv_pot_eolica_subrede_230kv</th>\n",
       "      <th>pot_eolica_subrede_138kv_pot_solar_subrede_230kv</th>\n",
       "      <th>pot_solar_subrede_138kv_carga_subrede_230kv</th>\n",
       "      <th>pot_solar_subrede_138kv_pot_eolica_subrede_230kv</th>\n",
       "      <th>pot_solar_subrede_138kv_pot_solar_subrede_230kv</th>\n",
       "      <th>carga_subrede_230kv_pot_eolica_subrede_230kv</th>\n",
       "      <th>carga_subrede_230kv_pot_solar_subrede_230kv</th>\n",
       "      <th>pot_eolica_subrede_230kv_pot_solar_subrede_230kv</th>\n",
       "      <th>pot_ativa_inj_barramento24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1005.652996</td>\n",
       "      <td>359.159986</td>\n",
       "      <td>283.635482</td>\n",
       "      <td>1283.451268</td>\n",
       "      <td>8.607487</td>\n",
       "      <td>39.255017</td>\n",
       "      <td>361190.316109</td>\n",
       "      <td>285238.872660</td>\n",
       "      <td>1.290707e+06</td>\n",
       "      <td>8656.144796</td>\n",
       "      <td>...</td>\n",
       "      <td>460964.339560</td>\n",
       "      <td>3091.464805</td>\n",
       "      <td>14098.831457</td>\n",
       "      <td>364032.319496</td>\n",
       "      <td>2441.388643</td>\n",
       "      <td>11134.115759</td>\n",
       "      <td>11047.289728</td>\n",
       "      <td>50381.901710</td>\n",
       "      <td>337.887039</td>\n",
       "      <td>84.847859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>617.833860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>87.547694</td>\n",
       "      <td>792.515072</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.650222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54089.929850</td>\n",
       "      <td>4.896426e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>69382.867211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1195.045419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10818.006276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>86.258469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1141.981073</td>\n",
       "      <td>407.379918</td>\n",
       "      <td>258.826331</td>\n",
       "      <td>1332.578952</td>\n",
       "      <td>184.762495</td>\n",
       "      <td>256.556631</td>\n",
       "      <td>465220.155617</td>\n",
       "      <td>295574.771421</td>\n",
       "      <td>1.521780e+06</td>\n",
       "      <td>210995.272171</td>\n",
       "      <td>...</td>\n",
       "      <td>542865.903805</td>\n",
       "      <td>75268.529960</td>\n",
       "      <td>104516.019178</td>\n",
       "      <td>344906.521122</td>\n",
       "      <td>47821.398685</td>\n",
       "      <td>66403.611506</td>\n",
       "      <td>246210.611778</td>\n",
       "      <td>341881.966288</td>\n",
       "      <td>47402.043197</td>\n",
       "      <td>99.973801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>868.235542</td>\n",
       "      <td>388.488818</td>\n",
       "      <td>437.258938</td>\n",
       "      <td>1251.923255</td>\n",
       "      <td>78.887444</td>\n",
       "      <td>215.605867</td>\n",
       "      <td>337299.799305</td>\n",
       "      <td>379643.750832</td>\n",
       "      <td>1.086964e+06</td>\n",
       "      <td>68492.882962</td>\n",
       "      <td>...</td>\n",
       "      <td>486358.185442</td>\n",
       "      <td>30646.889977</td>\n",
       "      <td>83760.468460</td>\n",
       "      <td>547414.632768</td>\n",
       "      <td>34494.240098</td>\n",
       "      <td>94275.592464</td>\n",
       "      <td>98761.026072</td>\n",
       "      <td>269921.999114</td>\n",
       "      <td>17008.595839</td>\n",
       "      <td>-13.398338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>965.812828</td>\n",
       "      <td>340.724995</td>\n",
       "      <td>288.883583</td>\n",
       "      <td>1146.930810</td>\n",
       "      <td>9.182495</td>\n",
       "      <td>47.733434</td>\n",
       "      <td>329076.570789</td>\n",
       "      <td>279007.470097</td>\n",
       "      <td>1.107720e+06</td>\n",
       "      <td>8868.571411</td>\n",
       "      <td>...</td>\n",
       "      <td>390787.993959</td>\n",
       "      <td>3128.705540</td>\n",
       "      <td>16263.973951</td>\n",
       "      <td>331329.481395</td>\n",
       "      <td>2652.672037</td>\n",
       "      <td>13789.405350</td>\n",
       "      <td>10531.686357</td>\n",
       "      <td>54746.945788</td>\n",
       "      <td>438.312014</td>\n",
       "      <td>68.359353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8755</th>\n",
       "      <td>1047.049421</td>\n",
       "      <td>382.453688</td>\n",
       "      <td>145.038167</td>\n",
       "      <td>1320.391653</td>\n",
       "      <td>129.959999</td>\n",
       "      <td>22.976486</td>\n",
       "      <td>400447.913005</td>\n",
       "      <td>151862.128799</td>\n",
       "      <td>1.382515e+06</td>\n",
       "      <td>136074.541582</td>\n",
       "      <td>...</td>\n",
       "      <td>504988.657574</td>\n",
       "      <td>49703.680904</td>\n",
       "      <td>8787.441645</td>\n",
       "      <td>191507.184999</td>\n",
       "      <td>18849.160018</td>\n",
       "      <td>3332.467348</td>\n",
       "      <td>171598.097660</td>\n",
       "      <td>30337.959726</td>\n",
       "      <td>2986.024036</td>\n",
       "      <td>128.618697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8756</th>\n",
       "      <td>883.798108</td>\n",
       "      <td>345.058580</td>\n",
       "      <td>379.021118</td>\n",
       "      <td>1115.364948</td>\n",
       "      <td>154.097891</td>\n",
       "      <td>119.051114</td>\n",
       "      <td>304962.119740</td>\n",
       "      <td>334978.147292</td>\n",
       "      <td>9.857574e+05</td>\n",
       "      <td>136191.424584</td>\n",
       "      <td>...</td>\n",
       "      <td>384866.244783</td>\n",
       "      <td>53172.799420</td>\n",
       "      <td>41079.608253</td>\n",
       "      <td>422746.870145</td>\n",
       "      <td>58406.355030</td>\n",
       "      <td>45122.886331</td>\n",
       "      <td>171875.386346</td>\n",
       "      <td>132785.439482</td>\n",
       "      <td>18345.525582</td>\n",
       "      <td>16.233429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8757</th>\n",
       "      <td>927.840168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>147.900760</td>\n",
       "      <td>1000.380433</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46.292106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>137228.266198</td>\n",
       "      <td>9.281931e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>147957.026485</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6846.637731</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46309.717488</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>172.367601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8758</th>\n",
       "      <td>1117.080968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>74.904579</td>\n",
       "      <td>1103.291195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>204.838344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>83674.479764</td>\n",
       "      <td>1.232466e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>82641.562680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15343.329969</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>225996.341616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>227.546462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8759</th>\n",
       "      <td>819.524711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.370209</td>\n",
       "      <td>942.093350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>314.294575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36362.482761</td>\n",
       "      <td>7.720688e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41800.878896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13945.316007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>296094.829132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>139.277805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8760 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      carga_subrede_138kv  pot_eolica_subrede_138kv  pot_solar_subrede_138kv  \\\n",
       "0             1005.652996                359.159986               283.635482   \n",
       "1              617.833860                  0.000000                87.547694   \n",
       "2             1141.981073                407.379918               258.826331   \n",
       "3              868.235542                388.488818               437.258938   \n",
       "4              965.812828                340.724995               288.883583   \n",
       "...                   ...                       ...                      ...   \n",
       "8755          1047.049421                382.453688               145.038167   \n",
       "8756           883.798108                345.058580               379.021118   \n",
       "8757           927.840168                  0.000000               147.900760   \n",
       "8758          1117.080968                  0.000000                74.904579   \n",
       "8759           819.524711                  0.000000                44.370209   \n",
       "\n",
       "      carga_subrede_230kv  pot_eolica_subrede_230kv  pot_solar_subrede_230kv  \\\n",
       "0             1283.451268                  8.607487                39.255017   \n",
       "1              792.515072                  0.000000                13.650222   \n",
       "2             1332.578952                184.762495               256.556631   \n",
       "3             1251.923255                 78.887444               215.605867   \n",
       "4             1146.930810                  9.182495                47.733434   \n",
       "...                   ...                       ...                      ...   \n",
       "8755          1320.391653                129.959999                22.976486   \n",
       "8756          1115.364948                154.097891               119.051114   \n",
       "8757          1000.380433                  0.000000                46.292106   \n",
       "8758          1103.291195                  0.000000               204.838344   \n",
       "8759           942.093350                  0.000000               314.294575   \n",
       "\n",
       "      carga_subrede_138kv_pot_eolica_subrede_138kv  \\\n",
       "0                                    361190.316109   \n",
       "1                                         0.000000   \n",
       "2                                    465220.155617   \n",
       "3                                    337299.799305   \n",
       "4                                    329076.570789   \n",
       "...                                            ...   \n",
       "8755                                 400447.913005   \n",
       "8756                                 304962.119740   \n",
       "8757                                      0.000000   \n",
       "8758                                      0.000000   \n",
       "8759                                      0.000000   \n",
       "\n",
       "      carga_subrede_138kv_pot_solar_subrede_138kv  \\\n",
       "0                                   285238.872660   \n",
       "1                                    54089.929850   \n",
       "2                                   295574.771421   \n",
       "3                                   379643.750832   \n",
       "4                                   279007.470097   \n",
       "...                                           ...   \n",
       "8755                                151862.128799   \n",
       "8756                                334978.147292   \n",
       "8757                                137228.266198   \n",
       "8758                                 83674.479764   \n",
       "8759                                 36362.482761   \n",
       "\n",
       "      carga_subrede_138kv_carga_subrede_230kv  \\\n",
       "0                                1.290707e+06   \n",
       "1                                4.896426e+05   \n",
       "2                                1.521780e+06   \n",
       "3                                1.086964e+06   \n",
       "4                                1.107720e+06   \n",
       "...                                       ...   \n",
       "8755                             1.382515e+06   \n",
       "8756                             9.857574e+05   \n",
       "8757                             9.281931e+05   \n",
       "8758                             1.232466e+06   \n",
       "8759                             7.720688e+05   \n",
       "\n",
       "      carga_subrede_138kv_pot_eolica_subrede_230kv  ...  \\\n",
       "0                                      8656.144796  ...   \n",
       "1                                         0.000000  ...   \n",
       "2                                    210995.272171  ...   \n",
       "3                                     68492.882962  ...   \n",
       "4                                      8868.571411  ...   \n",
       "...                                            ...  ...   \n",
       "8755                                 136074.541582  ...   \n",
       "8756                                 136191.424584  ...   \n",
       "8757                                      0.000000  ...   \n",
       "8758                                      0.000000  ...   \n",
       "8759                                      0.000000  ...   \n",
       "\n",
       "      pot_eolica_subrede_138kv_carga_subrede_230kv  \\\n",
       "0                                    460964.339560   \n",
       "1                                         0.000000   \n",
       "2                                    542865.903805   \n",
       "3                                    486358.185442   \n",
       "4                                    390787.993959   \n",
       "...                                            ...   \n",
       "8755                                 504988.657574   \n",
       "8756                                 384866.244783   \n",
       "8757                                      0.000000   \n",
       "8758                                      0.000000   \n",
       "8759                                      0.000000   \n",
       "\n",
       "      pot_eolica_subrede_138kv_pot_eolica_subrede_230kv  \\\n",
       "0                                           3091.464805   \n",
       "1                                              0.000000   \n",
       "2                                          75268.529960   \n",
       "3                                          30646.889977   \n",
       "4                                           3128.705540   \n",
       "...                                                 ...   \n",
       "8755                                       49703.680904   \n",
       "8756                                       53172.799420   \n",
       "8757                                           0.000000   \n",
       "8758                                           0.000000   \n",
       "8759                                           0.000000   \n",
       "\n",
       "      pot_eolica_subrede_138kv_pot_solar_subrede_230kv  \\\n",
       "0                                         14098.831457   \n",
       "1                                             0.000000   \n",
       "2                                        104516.019178   \n",
       "3                                         83760.468460   \n",
       "4                                         16263.973951   \n",
       "...                                                ...   \n",
       "8755                                       8787.441645   \n",
       "8756                                      41079.608253   \n",
       "8757                                          0.000000   \n",
       "8758                                          0.000000   \n",
       "8759                                          0.000000   \n",
       "\n",
       "      pot_solar_subrede_138kv_carga_subrede_230kv  \\\n",
       "0                                   364032.319496   \n",
       "1                                    69382.867211   \n",
       "2                                   344906.521122   \n",
       "3                                   547414.632768   \n",
       "4                                   331329.481395   \n",
       "...                                           ...   \n",
       "8755                                191507.184999   \n",
       "8756                                422746.870145   \n",
       "8757                                147957.026485   \n",
       "8758                                 82641.562680   \n",
       "8759                                 41800.878896   \n",
       "\n",
       "      pot_solar_subrede_138kv_pot_eolica_subrede_230kv  \\\n",
       "0                                          2441.388643   \n",
       "1                                             0.000000   \n",
       "2                                         47821.398685   \n",
       "3                                         34494.240098   \n",
       "4                                          2652.672037   \n",
       "...                                                ...   \n",
       "8755                                      18849.160018   \n",
       "8756                                      58406.355030   \n",
       "8757                                          0.000000   \n",
       "8758                                          0.000000   \n",
       "8759                                          0.000000   \n",
       "\n",
       "      pot_solar_subrede_138kv_pot_solar_subrede_230kv  \\\n",
       "0                                        11134.115759   \n",
       "1                                         1195.045419   \n",
       "2                                        66403.611506   \n",
       "3                                        94275.592464   \n",
       "4                                        13789.405350   \n",
       "...                                               ...   \n",
       "8755                                      3332.467348   \n",
       "8756                                     45122.886331   \n",
       "8757                                      6846.637731   \n",
       "8758                                     15343.329969   \n",
       "8759                                     13945.316007   \n",
       "\n",
       "      carga_subrede_230kv_pot_eolica_subrede_230kv  \\\n",
       "0                                     11047.289728   \n",
       "1                                         0.000000   \n",
       "2                                    246210.611778   \n",
       "3                                     98761.026072   \n",
       "4                                     10531.686357   \n",
       "...                                            ...   \n",
       "8755                                 171598.097660   \n",
       "8756                                 171875.386346   \n",
       "8757                                      0.000000   \n",
       "8758                                      0.000000   \n",
       "8759                                      0.000000   \n",
       "\n",
       "      carga_subrede_230kv_pot_solar_subrede_230kv  \\\n",
       "0                                    50381.901710   \n",
       "1                                    10818.006276   \n",
       "2                                   341881.966288   \n",
       "3                                   269921.999114   \n",
       "4                                    54746.945788   \n",
       "...                                           ...   \n",
       "8755                                 30337.959726   \n",
       "8756                                132785.439482   \n",
       "8757                                 46309.717488   \n",
       "8758                                225996.341616   \n",
       "8759                                296094.829132   \n",
       "\n",
       "      pot_eolica_subrede_230kv_pot_solar_subrede_230kv  \\\n",
       "0                                           337.887039   \n",
       "1                                             0.000000   \n",
       "2                                         47402.043197   \n",
       "3                                         17008.595839   \n",
       "4                                           438.312014   \n",
       "...                                                ...   \n",
       "8755                                       2986.024036   \n",
       "8756                                      18345.525582   \n",
       "8757                                          0.000000   \n",
       "8758                                          0.000000   \n",
       "8759                                          0.000000   \n",
       "\n",
       "      pot_ativa_inj_barramento24  \n",
       "0                      84.847859  \n",
       "1                      86.258469  \n",
       "2                      99.973801  \n",
       "3                     -13.398338  \n",
       "4                      68.359353  \n",
       "...                          ...  \n",
       "8755                  128.618697  \n",
       "8756                   16.233429  \n",
       "8757                  172.367601  \n",
       "8758                  227.546462  \n",
       "8759                  139.277805  \n",
       "\n",
       "[8760 rows x 22 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_pred = ['pot_ativa_inj_barramento24']\n",
    "model_id = 'pot_ativa_inj_barramento24_no_residual'\n",
    "run(df, cols, cols_pred, model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b9041fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ========== MODEL pot_reativa_inj_barramento11_no_residual ============\n",
      "Epoch 1/20\n",
      "596/614 [============================>.] - ETA: 0s - loss: 0.3662\n",
      "Epoch 1: val_loss improved from inf to 0.22400, saving model to models-new/ann-pot_reativa_inj_barramento11_no_residual.h5\n",
      "614/614 [==============================] - 2s 2ms/step - loss: 0.3668 - val_loss: 0.2240\n",
      "Epoch 2/20\n",
      "589/614 [===========================>..] - ETA: 0s - loss: 0.2650\n",
      "Epoch 2: val_loss improved from 0.22400 to 0.20258, saving model to models-new/ann-pot_reativa_inj_barramento11_no_residual.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.2652 - val_loss: 0.2026\n",
      "Epoch 3/20\n",
      "589/614 [===========================>..] - ETA: 0s - loss: 0.2423\n",
      "Epoch 3: val_loss improved from 0.20258 to 0.18426, saving model to models-new/ann-pot_reativa_inj_barramento11_no_residual.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.2431 - val_loss: 0.1843\n",
      "Epoch 4/20\n",
      "582/614 [===========================>..] - ETA: 0s - loss: 0.2229\n",
      "Epoch 4: val_loss improved from 0.18426 to 0.13362, saving model to models-new/ann-pot_reativa_inj_barramento11_no_residual.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.2216 - val_loss: 0.1336\n",
      "Epoch 5/20\n",
      "591/614 [===========================>..] - ETA: 0s - loss: 0.1968\n",
      "Epoch 5: val_loss did not improve from 0.13362\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1978 - val_loss: 0.1510\n",
      "Epoch 6/20\n",
      "595/614 [============================>.] - ETA: 0s - loss: 0.1923\n",
      "Epoch 6: val_loss did not improve from 0.13362\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1933 - val_loss: 0.1470\n",
      "Epoch 7/20\n",
      "610/614 [============================>.] - ETA: 0s - loss: 0.1888\n",
      "Epoch 7: val_loss did not improve from 0.13362\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1895 - val_loss: 0.1551\n",
      "Epoch 8/20\n",
      "587/614 [===========================>..] - ETA: 0s - loss: 0.1776\n",
      "Epoch 8: val_loss improved from 0.13362 to 0.12417, saving model to models-new/ann-pot_reativa_inj_barramento11_no_residual.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1784 - val_loss: 0.1242\n",
      "Epoch 9/20\n",
      "609/614 [============================>.] - ETA: 0s - loss: 0.1772\n",
      "Epoch 9: val_loss improved from 0.12417 to 0.11841, saving model to models-new/ann-pot_reativa_inj_barramento11_no_residual.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1769 - val_loss: 0.1184\n",
      "Epoch 10/20\n",
      "597/614 [============================>.] - ETA: 0s - loss: 0.1767\n",
      "Epoch 10: val_loss improved from 0.11841 to 0.10844, saving model to models-new/ann-pot_reativa_inj_barramento11_no_residual.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1762 - val_loss: 0.1084\n",
      "Epoch 11/20\n",
      "580/614 [===========================>..] - ETA: 0s - loss: 0.1601\n",
      "Epoch 11: val_loss did not improve from 0.10844\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1645 - val_loss: 0.1177\n",
      "Epoch 12/20\n",
      "600/614 [============================>.] - ETA: 0s - loss: 0.1609\n",
      "Epoch 12: val_loss improved from 0.10844 to 0.10840, saving model to models-new/ann-pot_reativa_inj_barramento11_no_residual.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1619 - val_loss: 0.1084\n",
      "Epoch 13/20\n",
      "594/614 [============================>.] - ETA: 0s - loss: 0.1654\n",
      "Epoch 13: val_loss did not improve from 0.10840\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1660 - val_loss: 0.1285\n",
      "Epoch 14/20\n",
      "601/614 [============================>.] - ETA: 0s - loss: 0.1627\n",
      "Epoch 14: val_loss improved from 0.10840 to 0.10454, saving model to models-new/ann-pot_reativa_inj_barramento11_no_residual.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1631 - val_loss: 0.1045\n",
      "Epoch 15/20\n",
      "595/614 [============================>.] - ETA: 0s - loss: 0.1541\n",
      "Epoch 15: val_loss did not improve from 0.10454\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1553 - val_loss: 0.1065\n",
      "Epoch 16/20\n",
      "605/614 [============================>.] - ETA: 0s - loss: 0.1549\n",
      "Epoch 16: val_loss did not improve from 0.10454\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1554 - val_loss: 0.1091\n",
      "Epoch 17/20\n",
      "587/614 [===========================>..] - ETA: 0s - loss: 0.1586\n",
      "Epoch 17: val_loss improved from 0.10454 to 0.09621, saving model to models-new/ann-pot_reativa_inj_barramento11_no_residual.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1577 - val_loss: 0.0962\n",
      "Epoch 18/20\n",
      "583/614 [===========================>..] - ETA: 0s - loss: 0.1468\n",
      "Epoch 18: val_loss did not improve from 0.09621\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1465 - val_loss: 0.0991\n",
      "Epoch 19/20\n",
      "597/614 [============================>.] - ETA: 0s - loss: 0.1446\n",
      "Epoch 19: val_loss did not improve from 0.09621\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1450 - val_loss: 0.1129\n",
      "Epoch 20/20\n",
      "586/614 [===========================>..] - ETA: 0s - loss: 0.1479\n",
      "Epoch 20: val_loss did not improve from 0.09621\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1500 - val_loss: 0.0977\n",
      "83/83 [==============================] - 0s 1ms/step\n",
      "RMSE: 0.7310492623403839\n"
     ]
    }
   ],
   "source": [
    "cols_pred = ['pot_reativa_inj_barramento11']\n",
    "model_id = 'pot_reativa_inj_barramento11_no_residual'\n",
    "pot_reativa_inj_barramento12_mse_df = run(df, cols, cols_pred, model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b4106f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ========== MODEL pot_reativa_inj_barramento12_no_residual ============\n",
      "Epoch 1/20\n",
      "595/614 [============================>.] - ETA: 0s - loss: 0.2291\n",
      "Epoch 1: val_loss improved from inf to 0.16610, saving model to models-new/ann-pot_reativa_inj_barramento12_no_residual.h5\n",
      "614/614 [==============================] - 2s 2ms/step - loss: 0.2289 - val_loss: 0.1661\n",
      "Epoch 2/20\n",
      "597/614 [============================>.] - ETA: 0s - loss: 0.1644\n",
      "Epoch 2: val_loss improved from 0.16610 to 0.10952, saving model to models-new/ann-pot_reativa_inj_barramento12_no_residual.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1649 - val_loss: 0.1095\n",
      "Epoch 3/20\n",
      "591/614 [===========================>..] - ETA: 0s - loss: 0.1458\n",
      "Epoch 3: val_loss did not improve from 0.10952\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1460 - val_loss: 0.1126\n",
      "Epoch 4/20\n",
      "609/614 [============================>.] - ETA: 0s - loss: 0.1328\n",
      "Epoch 4: val_loss improved from 0.10952 to 0.10302, saving model to models-new/ann-pot_reativa_inj_barramento12_no_residual.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1325 - val_loss: 0.1030\n",
      "Epoch 5/20\n",
      "582/614 [===========================>..] - ETA: 0s - loss: 0.1337\n",
      "Epoch 5: val_loss improved from 0.10302 to 0.09221, saving model to models-new/ann-pot_reativa_inj_barramento12_no_residual.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1334 - val_loss: 0.0922\n",
      "Epoch 6/20\n",
      "607/614 [============================>.] - ETA: 0s - loss: 0.1204\n",
      "Epoch 6: val_loss improved from 0.09221 to 0.09079, saving model to models-new/ann-pot_reativa_inj_barramento12_no_residual.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1205 - val_loss: 0.0908\n",
      "Epoch 7/20\n",
      "607/614 [============================>.] - ETA: 0s - loss: 0.1181\n",
      "Epoch 7: val_loss improved from 0.09079 to 0.07929, saving model to models-new/ann-pot_reativa_inj_barramento12_no_residual.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1177 - val_loss: 0.0793\n",
      "Epoch 8/20\n",
      "612/614 [============================>.] - ETA: 0s - loss: 0.1164\n",
      "Epoch 8: val_loss did not improve from 0.07929\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1162 - val_loss: 0.0806\n",
      "Epoch 9/20\n",
      "582/614 [===========================>..] - ETA: 0s - loss: 0.1110\n",
      "Epoch 9: val_loss improved from 0.07929 to 0.07193, saving model to models-new/ann-pot_reativa_inj_barramento12_no_residual.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1116 - val_loss: 0.0719\n",
      "Epoch 10/20\n",
      "595/614 [============================>.] - ETA: 0s - loss: 0.1147\n",
      "Epoch 10: val_loss did not improve from 0.07193\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1153 - val_loss: 0.0740\n",
      "Epoch 11/20\n",
      "592/614 [===========================>..] - ETA: 0s - loss: 0.1063\n",
      "Epoch 11: val_loss did not improve from 0.07193\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1068 - val_loss: 0.0831\n",
      "Epoch 12/20\n",
      "587/614 [===========================>..] - ETA: 0s - loss: 0.1047\n",
      "Epoch 12: val_loss improved from 0.07193 to 0.06723, saving model to models-new/ann-pot_reativa_inj_barramento12_no_residual.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1047 - val_loss: 0.0672\n",
      "Epoch 13/20\n",
      "596/614 [============================>.] - ETA: 0s - loss: 0.1047\n",
      "Epoch 13: val_loss did not improve from 0.06723\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1043 - val_loss: 0.0684\n",
      "Epoch 14/20\n",
      "580/614 [===========================>..] - ETA: 0s - loss: 0.1059\n",
      "Epoch 14: val_loss did not improve from 0.06723\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1060 - val_loss: 0.0948\n",
      "Epoch 15/20\n",
      "582/614 [===========================>..] - ETA: 0s - loss: 0.0991\n",
      "Epoch 15: val_loss did not improve from 0.06723\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0991 - val_loss: 0.0730\n",
      "Epoch 16/20\n",
      "582/614 [===========================>..] - ETA: 0s - loss: 0.0992\n",
      "Epoch 16: val_loss improved from 0.06723 to 0.06393, saving model to models-new/ann-pot_reativa_inj_barramento12_no_residual.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0994 - val_loss: 0.0639\n",
      "Epoch 17/20\n",
      "597/614 [============================>.] - ETA: 0s - loss: 0.1008\n",
      "Epoch 17: val_loss did not improve from 0.06393\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1004 - val_loss: 0.0696\n",
      "Epoch 18/20\n",
      "611/614 [============================>.] - ETA: 0s - loss: 0.0931\n",
      "Epoch 18: val_loss improved from 0.06393 to 0.05863, saving model to models-new/ann-pot_reativa_inj_barramento12_no_residual.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0932 - val_loss: 0.0586\n",
      "Epoch 19/20\n",
      "582/614 [===========================>..] - ETA: 0s - loss: 0.0941\n",
      "Epoch 19: val_loss did not improve from 0.05863\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0940 - val_loss: 0.0693\n",
      "Epoch 20/20\n",
      "612/614 [============================>.] - ETA: 0s - loss: 0.0938\n",
      "Epoch 20: val_loss did not improve from 0.05863\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0938 - val_loss: 0.0688\n",
      "83/83 [==============================] - 0s 940us/step\n",
      "RMSE: 0.8910796964291661\n"
     ]
    }
   ],
   "source": [
    "cols_pred = ['pot_reativa_inj_barramento12']\n",
    "model_id = 'pot_reativa_inj_barramento12_no_residual'\n",
    "pot_reativa_inj_barramento12_mse_df = run(df, cols, cols_pred, model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "095cf91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ========== MODEL pot_reativa_inj_barramento24_no_residual ============\n",
      "Epoch 1/20\n",
      "607/614 [============================>.] - ETA: 0s - loss: 0.2344\n",
      "Epoch 1: val_loss improved from inf to 0.11330, saving model to models-new/ann-pot_reativa_inj_barramento24_no_residual.h5\n",
      "614/614 [==============================] - 2s 2ms/step - loss: 0.2331 - val_loss: 0.1133\n",
      "Epoch 2/20\n",
      "607/614 [============================>.] - ETA: 0s - loss: 0.1616\n",
      "Epoch 2: val_loss improved from 0.11330 to 0.10030, saving model to models-new/ann-pot_reativa_inj_barramento24_no_residual.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1615 - val_loss: 0.1003\n",
      "Epoch 3/20\n",
      "576/614 [===========================>..] - ETA: 0s - loss: 0.1442\n",
      "Epoch 3: val_loss improved from 0.10030 to 0.09136, saving model to models-new/ann-pot_reativa_inj_barramento24_no_residual.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1453 - val_loss: 0.0914\n",
      "Epoch 4/20\n",
      "608/614 [============================>.] - ETA: 0s - loss: 0.1342\n",
      "Epoch 4: val_loss improved from 0.09136 to 0.08075, saving model to models-new/ann-pot_reativa_inj_barramento24_no_residual.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1342 - val_loss: 0.0807\n",
      "Epoch 5/20\n",
      "592/614 [===========================>..] - ETA: 0s - loss: 0.1222\n",
      "Epoch 5: val_loss did not improve from 0.08075\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1224 - val_loss: 0.0837\n",
      "Epoch 6/20\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.1180\n",
      "Epoch 6: val_loss improved from 0.08075 to 0.07247, saving model to models-new/ann-pot_reativa_inj_barramento24_no_residual.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1180 - val_loss: 0.0725\n",
      "Epoch 7/20\n",
      "601/614 [============================>.] - ETA: 0s - loss: 0.1119\n",
      "Epoch 7: val_loss did not improve from 0.07247\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1125 - val_loss: 0.1035\n",
      "Epoch 8/20\n",
      "600/614 [============================>.] - ETA: 0s - loss: 0.1133\n",
      "Epoch 8: val_loss did not improve from 0.07247\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1137 - val_loss: 0.0750\n",
      "Epoch 9/20\n",
      "581/614 [===========================>..] - ETA: 0s - loss: 0.1062\n",
      "Epoch 9: val_loss improved from 0.07247 to 0.06256, saving model to models-new/ann-pot_reativa_inj_barramento24_no_residual.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1049 - val_loss: 0.0626\n",
      "Epoch 10/20\n",
      "582/614 [===========================>..] - ETA: 0s - loss: 0.1038\n",
      "Epoch 10: val_loss did not improve from 0.06256\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1044 - val_loss: 0.0842\n",
      "Epoch 11/20\n",
      "596/614 [============================>.] - ETA: 0s - loss: 0.1032\n",
      "Epoch 11: val_loss improved from 0.06256 to 0.06005, saving model to models-new/ann-pot_reativa_inj_barramento24_no_residual.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1039 - val_loss: 0.0601\n",
      "Epoch 12/20\n",
      "596/614 [============================>.] - ETA: 0s - loss: 0.1016\n",
      "Epoch 12: val_loss improved from 0.06005 to 0.05719, saving model to models-new/ann-pot_reativa_inj_barramento24_no_residual.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.1016 - val_loss: 0.0572\n",
      "Epoch 13/20\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0992\n",
      "Epoch 13: val_loss did not improve from 0.05719\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0991 - val_loss: 0.0895\n",
      "Epoch 14/20\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0985\n",
      "Epoch 14: val_loss improved from 0.05719 to 0.05514, saving model to models-new/ann-pot_reativa_inj_barramento24_no_residual.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0985 - val_loss: 0.0551\n",
      "Epoch 15/20\n",
      "611/614 [============================>.] - ETA: 0s - loss: 0.0994\n",
      "Epoch 15: val_loss did not improve from 0.05514\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0993 - val_loss: 0.0691\n",
      "Epoch 16/20\n",
      "583/614 [===========================>..] - ETA: 0s - loss: 0.0956\n",
      "Epoch 16: val_loss did not improve from 0.05514\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0955 - val_loss: 0.0621\n",
      "Epoch 17/20\n",
      "604/614 [============================>.] - ETA: 0s - loss: 0.0979\n",
      "Epoch 17: val_loss did not improve from 0.05514\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0975 - val_loss: 0.0709\n",
      "Epoch 18/20\n",
      "578/614 [===========================>..] - ETA: 0s - loss: 0.0959\n",
      "Epoch 18: val_loss did not improve from 0.05514\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0949 - val_loss: 0.0558\n",
      "Epoch 19/20\n",
      "605/614 [============================>.] - ETA: 0s - loss: 0.0929\n",
      "Epoch 19: val_loss improved from 0.05514 to 0.05486, saving model to models-new/ann-pot_reativa_inj_barramento24_no_residual.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0925 - val_loss: 0.0549\n",
      "Epoch 20/20\n",
      "582/614 [===========================>..] - ETA: 0s - loss: 0.0954\n",
      "Epoch 20: val_loss improved from 0.05486 to 0.05449, saving model to models-new/ann-pot_reativa_inj_barramento24_no_residual.h5\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0949 - val_loss: 0.0545\n",
      "83/83 [==============================] - 0s 905us/step\n",
      "RMSE: 0.5356561157386422\n"
     ]
    }
   ],
   "source": [
    "cols_pred = ['pot_reativa_inj_barramento24']\n",
    "model_id = 'pot_reativa_inj_barramento24_no_residual'\n",
    "pot_reativa_inj_barramento12_mse_df = run(df, cols, cols_pred, model_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
